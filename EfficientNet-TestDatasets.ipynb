{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EfficientNet-TestDatasets.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"P_FwoC8GviT1","colab_type":"text"},"source":["# WEIGHT ESTIMATION - TEST EFFICIENT NET Research Project"]},{"cell_type":"code","metadata":{"id":"ZxOZswaXv8Pl","colab_type":"code","outputId":"f566799e-dfdd-4266-e4d8-4fbbcf416a07","executionInfo":{"status":"ok","timestamp":1590853974785,"user_tz":-120,"elapsed":22471,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qeD00JVfe22S","colab_type":"code","colab":{}},"source":["# import libraries\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import numpy as np\n","from torchvision import datasets\n","from skimage import io, transform\n","from torch.utils.data import DataLoader\n","import time\n","import os\n","from PIL import Image\n","from torchvision import transforms\n","import logging\n","from datetime import datetime\n","import copy\n","import time\n","from sklearn.model_selection import KFold\n","from tqdm import tqdm\n","import random\n","import os\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUa0-vIv7oET","colab_type":"code","outputId":"178e7936-ab48-4cbc-a8db-661f17a3ff27","executionInfo":{"status":"ok","timestamp":1590853980958,"user_tz":-120,"elapsed":6158,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Get the seconds since epoch\n","secondsSinceEpoch = time.time()\n","# Convert seconds since epoch to struct_time\n","timeObj = time.localtime(secondsSinceEpoch)\n","\n","time = str(timeObj.tm_mday)+ '-' + str(timeObj.tm_mon) +'-'+ str(timeObj.tm_year)+'-'+str(timeObj.tm_hour)+'_'+str(timeObj.tm_min)\n","print(time)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["30-5-2020-15_53\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nfO7vaDhwEPk","colab_type":"code","outputId":"e3e842bf-7c4e-4de3-be14-2b44a68a5941","executionInfo":{"status":"ok","timestamp":1590853983180,"user_tz":-120,"elapsed":8370,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Path of Folders\n","content = '/content/drive/My Drive/datasets/DepthData/images/'\n","labels_csv = '/content/drive/My Drive/datasets/DepthData/labels.csv'\n","labels_train_csv = '/content/drive/My Drive/datasets/DepthData/labels.train.csv'\n","labels_test_csv = '/content/drive/My Drive/datasets/DepthData/labels.test.csv'\n","file_test_labels = '/content/drive/My Drive/risultati-datasets/result-b5-DepthData_PAPER_statistics.csv'\n","net_name = 'efficientnet-b5'\n","\n","weights=pd.read_csv(labels_csv)\n","weights = weights['WEIGHT'].values\n","\n","print('Start initialization logging file')\n","logging.basicConfig(filename='app_' + str(time) + '.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s')\n","logging.warning('Initialized File')\n","\n","# Instantiate visualizer\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# default `log_dir` is \"runs\" - we'll be more specific here\n","writer = SummaryWriter('runs/Efficient-Net')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Start initialization logging file\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nbGPbiyrzChA","colab_type":"text"},"source":["## Efficient Net\n"]},{"cell_type":"code","metadata":{"id":"Gfzu6JmWRnAl","colab_type":"code","colab":{}},"source":["# Source: https://github.com/lukemelas/EfficientNet-PyTorch\n","# Version: 0.4.0\n","\"\"\"\n","This file contains helper functions for building the model and for loading model parameters.\n","These helper functions are built to mirror those in the official TensorFlow implementation.\n","\"\"\"\n","\n","import re\n","import math\n","import collections\n","from functools import partial\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils import model_zoo\n","\n","\n","########################################################################\n","############### HELPERS FUNCTIONS FOR MODEL ARCHITECTURE ###############\n","########################################################################\n","\n","\n","# Parameters for the entire model (stem, all blocks, and head)\n","GlobalParams = collections.namedtuple('GlobalParams', [\n","    'batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate',\n","    'num_classes', 'width_coefficient', 'depth_coefficient',\n","    'depth_divisor', 'min_depth', 'drop_connect_rate', 'image_size'])\n","\n","\n","# Parameters for an individual model block\n","BlockArgs = collections.namedtuple('BlockArgs', [\n","    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n","    'expand_ratio', 'id_skip', 'stride', 'se_ratio'])\n","\n","\n","# Change namedtuple defaults\n","GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n","BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n","\n","\n","def relu_fn(x):\n","    \"\"\" Swish activation function \"\"\"\n","    return x * torch.sigmoid(x)\n","\n","\n","def round_filters(filters, global_params):\n","    \"\"\" Calculate and round number of filters based on depth multiplier. \"\"\"\n","    multiplier = global_params.width_coefficient\n","    if not multiplier:\n","        return filters\n","    divisor = global_params.depth_divisor\n","    min_depth = global_params.min_depth\n","    filters *= multiplier\n","    min_depth = min_depth or divisor\n","    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n","    if new_filters < 0.9 * filters:  # prevent rounding by more than 10%\n","        new_filters += divisor\n","    return int(new_filters)\n","\n","\n","def round_repeats(repeats, global_params):\n","    \"\"\" Round number of filters based on depth multiplier. \"\"\"\n","    multiplier = global_params.depth_coefficient\n","    if not multiplier:\n","        return repeats\n","    return int(math.ceil(multiplier * repeats))\n","\n","\n","def drop_connect(inputs, p, training):\n","    \"\"\" Drop connect. \"\"\"\n","    if not training: return inputs\n","    batch_size = inputs.shape[0]\n","    keep_prob = 1 - p\n","    random_tensor = keep_prob\n","    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype, device=inputs.device)\n","    binary_tensor = torch.floor(random_tensor)\n","    output = inputs / keep_prob * binary_tensor\n","    return output\n","\n","\n","def get_same_padding_conv2d(image_size=None):\n","    \"\"\" Chooses static padding if you have specified an image size, and dynamic padding otherwise.\n","        Static padding is necessary for ONNX exporting of models. \"\"\"\n","    if image_size is None:\n","        return Conv2dDynamicSamePadding\n","    else:\n","        return partial(Conv2dStaticSamePadding, image_size=image_size)\n","\n","class Conv2dDynamicSamePadding(nn.Conv2d):\n","    \"\"\" 2D Convolutions like TensorFlow, for a dynamic image size \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n","        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n","        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]]*2\n","\n","    def forward(self, x):\n","        ih, iw = x.size()[-2:]\n","        kh, kw = self.weight.size()[-2:]\n","        sh, sw = self.stride\n","        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n","        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n","        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n","        if pad_h > 0 or pad_w > 0:\n","            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n","        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n","\n","\n","class Conv2dStaticSamePadding(nn.Conv2d):\n","    \"\"\" 2D Convolutions like TensorFlow, for a fixed image size\"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, image_size=None, **kwargs):\n","        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n","        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n","\n","        # Calculate padding based on image size and save it\n","        assert image_size is not None\n","        ih, iw = image_size if type(image_size) == list else [image_size, image_size]\n","        kh, kw = self.weight.size()[-2:]\n","        sh, sw = self.stride\n","        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n","        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n","        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n","        if pad_h > 0 or pad_w > 0:\n","            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))\n","        else:\n","            self.static_padding = Identity()\n","\n","    def forward(self, x):\n","        x = self.static_padding(x)\n","        x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n","        return x\n","\n","\n","class Identity(nn.Module):\n","    def __init__(self,):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, input):\n","        return input\n","\n","\n","########################################################################\n","############## HELPERS FUNCTIONS FOR LOADING MODEL PARAMS ##############\n","########################################################################\n","\n","\n","def efficientnet_params(model_name):\n","    \"\"\" Map EfficientNet model name to parameter coefficients. \"\"\"\n","    params_dict = {\n","        # Coefficients:   width,depth,res,dropout\n","        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n","        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n","        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n","        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n","        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n","        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n","        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n","        'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n","    }\n","    return params_dict[model_name]\n","\n","\n","class BlockDecoder(object):\n","    \"\"\" Block Decoder for readability, straight from the official TensorFlow repository \"\"\"\n","\n","    @staticmethod\n","    def _decode_block_string(block_string):\n","        \"\"\" Gets a block through a string notation of arguments. \"\"\"\n","        assert isinstance(block_string, str)\n","\n","        ops = block_string.split('_')\n","        options = {}\n","        for op in ops:\n","            splits = re.split(r'(\\d.*)', op)\n","            if len(splits) >= 2:\n","                key, value = splits[:2]\n","                options[key] = value\n","\n","        # Check stride\n","        assert (('s' in options and len(options['s']) == 1) or\n","                (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\n","\n","        return BlockArgs(\n","            kernel_size=int(options['k']),\n","            num_repeat=int(options['r']),\n","            input_filters=int(options['i']),\n","            output_filters=int(options['o']),\n","            expand_ratio=int(options['e']),\n","            id_skip=('noskip' not in block_string),\n","            se_ratio=float(options['se']) if 'se' in options else None,\n","            stride=[int(options['s'][0])])\n","\n","    @staticmethod\n","    def _encode_block_string(block):\n","        \"\"\"Encodes a block to a string.\"\"\"\n","        args = [\n","            'r%d' % block.num_repeat,\n","            'k%d' % block.kernel_size,\n","            's%d%d' % (block.strides[0], block.strides[1]),\n","            'e%s' % block.expand_ratio,\n","            'i%d' % block.input_filters,\n","            'o%d' % block.output_filters\n","        ]\n","        if 0 < block.se_ratio <= 1:\n","            args.append('se%s' % block.se_ratio)\n","        if block.id_skip is False:\n","            args.append('noskip')\n","        return '_'.join(args)\n","\n","    @staticmethod\n","    def decode(string_list):\n","        \"\"\"\n","        Decodes a list of string notations to specify blocks inside the network.\n","\n","        :param string_list: a list of strings, each string is a notation of block\n","        :return: a list of BlockArgs namedtuples of block args\n","        \"\"\"\n","        assert isinstance(string_list, list)\n","        blocks_args = []\n","        for block_string in string_list:\n","            blocks_args.append(BlockDecoder._decode_block_string(block_string))\n","        return blocks_args\n","\n","    @staticmethod\n","    def encode(blocks_args):\n","        \"\"\"\n","        Encodes a list of BlockArgs to a list of strings.\n","\n","        :param blocks_args: a list of BlockArgs namedtuples of block args\n","        :return: a list of strings, each string is a notation of block\n","        \"\"\"\n","        block_strings = []\n","        for block in blocks_args:\n","            block_strings.append(BlockDecoder._encode_block_string(block))\n","        return block_strings\n","\n","\n","def efficientnet(width_coefficient=None, depth_coefficient=None, dropout_rate=0.2,\n","                 drop_connect_rate=0.2, image_size=None, num_classes=1000):\n","    \"\"\" Creates a efficientnet model. \"\"\"\n","\n","    blocks_args = [\n","        'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n","        'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n","        'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n","        'r1_k3_s11_e6_i192_o320_se0.25',\n","    ]\n","    blocks_args = BlockDecoder.decode(blocks_args)\n","\n","    global_params = GlobalParams(\n","        batch_norm_momentum=0.99,\n","        batch_norm_epsilon=1e-3,\n","        dropout_rate=dropout_rate,\n","        drop_connect_rate=drop_connect_rate,\n","        # data_format='channels_last',  # removed, this is always true in PyTorch\n","        num_classes=num_classes,\n","        width_coefficient=width_coefficient,\n","        depth_coefficient=depth_coefficient,\n","        depth_divisor=8,\n","        min_depth=None,\n","        image_size=image_size,\n","    )\n","\n","    return blocks_args, global_params\n","\n","\n","def get_model_params(model_name, override_params):\n","    \"\"\" Get the block args and global params for a given model \"\"\"\n","    if model_name.startswith('efficientnet'):\n","        w, d, s, p = efficientnet_params(model_name)\n","        # note: all models have drop connect rate = 0.2\n","        blocks_args, global_params = efficientnet(\n","            width_coefficient=w, depth_coefficient=d, dropout_rate=p, image_size=s)\n","    else:\n","        raise NotImplementedError('model name is not pre-defined: %s' % model_name)\n","    if override_params:\n","        # ValueError will be raised here if override_params has fields not included in global_params.\n","        global_params = global_params._replace(**override_params)\n","    return blocks_args, global_params\n","\n","\n","# url_map = {\n","#     'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b0-355c32eb.pth',\n","#     'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b1-f1951068.pth',\n","#     'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b2-8bb594d6.pth',\n","#     'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth',\n","#     'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b4-6ed6700e.pth',\n","#     'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b5-b6417697.pth',\n","#     'efficientnet-b6': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b6-c76e70fd.pth',\n","#     'efficientnet-b7': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b7-dcc49843.pth',\n","# }\n","\n","url_map = {\n","    'efficientnet-b0': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth',\n","    'efficientnet-b1': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth',\n","    'efficientnet-b2': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth',\n","    'efficientnet-b3': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth',\n","    'efficientnet-b4': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth',\n","    'efficientnet-b5': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth',\n","    'efficientnet-b6': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b6-c76e70fd.pth',\n","    'efficientnet-b7': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth',\n","}\n","\n","def load_pretrained_weights(model, model_name, load_fc=True):\n","    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n","    state_dict = model_zoo.load_url(url_map[model_name])\n","    if load_fc:\n","        model.load_state_dict(state_dict)\n","    else:\n","        state_dict.pop('_fc.weight')\n","        state_dict.pop('_fc.bias')\n","        res = model.load_state_dict(state_dict, strict=False)\n","        assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n","    print('Loaded pretrained weights for {}'.format(model_name))\n","\n","class MBConvBlock(nn.Module):\n","    \"\"\"\n","    Mobile Inverted Residual Bottleneck Block\n","\n","    Args:\n","        block_args (namedtuple): BlockArgs, see above\n","        global_params (namedtuple): GlobalParam, see above\n","\n","    Attributes:\n","        has_se (bool): Whether the block contains a Squeeze and Excitation layer.\n","    \"\"\"\n","\n","    def __init__(self, block_args, global_params):\n","        super().__init__()\n","        self._block_args = block_args\n","        self._bn_mom = 1 - global_params.batch_norm_momentum\n","        self._bn_eps = global_params.batch_norm_epsilon\n","        self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)\n","        self.id_skip = block_args.id_skip  # skip connection and drop connect\n","\n","        # Get static or dynamic convolution depending on image size\n","        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n","\n","        # Expansion phase\n","        inp = self._block_args.input_filters  # number of input channels\n","        oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels\n","        if self._block_args.expand_ratio != 1:\n","            self._expand_conv = Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n","            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n","\n","        # Depthwise convolution phase\n","        k = self._block_args.kernel_size\n","        s = self._block_args.stride\n","        self._depthwise_conv = Conv2d(\n","            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise\n","            kernel_size=k, stride=s, bias=False)\n","        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n","\n","        # Squeeze and Excitation layer, if desired\n","        if self.has_se:\n","            num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))\n","            self._se_reduce = Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n","            self._se_expand = Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n","\n","        # Output phase\n","        final_oup = self._block_args.output_filters\n","        self._project_conv = Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n","        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n","\n","    def forward(self, inputs, drop_connect_rate=None):\n","        \"\"\"\n","        :param inputs: input tensor\n","        :param drop_connect_rate: drop connect rate (float, between 0 and 1)\n","        :return: output of block\n","        \"\"\"\n","\n","        # Expansion and Depthwise Convolution\n","        x = inputs\n","        if self._block_args.expand_ratio != 1:\n","            x = relu_fn(self._bn0(self._expand_conv(inputs)))\n","        x = relu_fn(self._bn1(self._depthwise_conv(x)))\n","\n","        # Squeeze and Excitation\n","        if self.has_se:\n","            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n","            x_squeezed = self._se_expand(relu_fn(self._se_reduce(x_squeezed)))\n","            x = torch.sigmoid(x_squeezed) * x\n","\n","        x = self._bn2(self._project_conv(x))\n","\n","        # Skip connection and drop connect\n","        input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\n","        if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n","            if drop_connect_rate:\n","                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n","            x = x + inputs  # skip connection\n","        return x\n","\n","\n","class EfficientNet(nn.Module):\n","    \"\"\"\n","    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n","\n","    Args:\n","        blocks_args (list): A list of BlockArgs to construct blocks\n","        global_params (namedtuple): A set of GlobalParams shared between blocks\n","\n","    Example:\n","        model = EfficientNet.from_pretrained('efficientnet-b0')\n","\n","    \"\"\"\n","\n","    def __init__(self, blocks_args=None, global_params=None):\n","        super().__init__()\n","        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n","        assert len(blocks_args) > 0, 'block args must be greater than 0'\n","        self._global_params = global_params\n","        self._blocks_args = blocks_args\n","\n","        # Get static or dynamic convolution depending on image size\n","        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n","\n","        # Batch norm parameters\n","        bn_mom = 1 - self._global_params.batch_norm_momentum\n","        bn_eps = self._global_params.batch_norm_epsilon\n","\n","        # Stem\n","        in_channels = 3  # rgb\n","        out_channels = round_filters(32, self._global_params)  # number of output channels\n","        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n","        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n","\n","        # Build blocks\n","        self._blocks = nn.ModuleList([])\n","        for block_args in self._blocks_args:\n","\n","            # Update block input and output filters based on depth multiplier.\n","            block_args = block_args._replace(\n","                input_filters=round_filters(block_args.input_filters, self._global_params),\n","                output_filters=round_filters(block_args.output_filters, self._global_params),\n","                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n","            )\n","\n","            # The first block needs to take care of stride and filter size increase.\n","            self._blocks.append(MBConvBlock(block_args, self._global_params))\n","            if block_args.num_repeat > 1:\n","                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n","            for _ in range(block_args.num_repeat - 1):\n","                self._blocks.append(MBConvBlock(block_args, self._global_params))\n","\n","        # Head\n","        in_channels = block_args.output_filters  # output of final block\n","        out_channels = round_filters(1280, self._global_params)\n","        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n","        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n","\n","        # Final linear layer\n","        self._dropout = self._global_params.dropout_rate\n","        self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n","\n","    def extract_features(self, inputs):\n","        \"\"\" Returns output of the final convolution layer \"\"\"\n","\n","        # Stem\n","        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n","\n","        # Blocks\n","        for idx, block in enumerate(self._blocks):\n","            drop_connect_rate = self._global_params.drop_connect_rate\n","            if drop_connect_rate:\n","                drop_connect_rate *= float(idx) / len(self._blocks)\n","            x = block(x, drop_connect_rate=drop_connect_rate)\n","\n","        # Head\n","        x = relu_fn(self._bn1(self._conv_head(x)))\n","\n","        return x\n","\n","    def forward(self, inputs):\n","        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n","\n","        # Convolution layers\n","        x = self.extract_features(inputs)\n","\n","        # Pooling and final linear layer\n","        x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n","        if self._dropout:\n","            x = F.dropout(x, p=self._dropout, training=self.training)\n","        x = self._fc(x)\n","        return x\n","\n","    @classmethod\n","    def from_name(cls, model_name, override_params=None):\n","        cls._check_model_name_is_valid(model_name)\n","        blocks_args, global_params = get_model_params(model_name, override_params)\n","        return EfficientNet(blocks_args, global_params)\n","\n","    @classmethod\n","    def from_pretrained(cls, model_name, num_classes=1000):\n","        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n","        load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000))\n","        return model\n","\n","    @classmethod\n","    def get_image_size(cls, model_name):\n","        cls._check_model_name_is_valid(model_name)\n","        _, _, res, _ = efficientnet_params(model_name)\n","        return res\n","\n","    @classmethod\n","    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n","        \"\"\" Validates model name. None that pretrained weights are only available for\n","        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n","        num_models = 4 if also_need_pretrained_weights else 8\n","        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n","        if model_name.replace('-','_') not in valid_models:\n","            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MAx0lsewycv1","colab_type":"text"},"source":["## Optimizer and Cost Function\n","Declaration of the optimizer and of the cost function."]},{"cell_type":"code","metadata":{"id":"31jAoGYg3hjK","colab_type":"code","colab":{}},"source":["def get_optimizer(net, lr):\n","  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","  return optimizer\n","\n","def get_cost_function():\n","  cost_function = torch.nn.MSELoss()\n","  return cost_function"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y4ksS3d6_GS9","colab_type":"text"},"source":["## New KFold Cross Validation\n","This is an improvement of the section before since this one creates dinamically the minibatch for the computatation of a single fold\n"]},{"cell_type":"code","metadata":{"id":"GBnEJt1XDwCx","colab_type":"code","outputId":"19db55ad-38e1-40bb-e72f-ef2a2416cce3","executionInfo":{"status":"ok","timestamp":1590853989038,"user_tz":-120,"elapsed":2244,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["weights=pd.read_csv(labels_csv)\n","#train_IDs, test_IDs = train_test_split(weights, test_size=0.1, random_state=42)\n","train_IDs = pd.read_csv(labels_train_csv)\n","test_IDs = pd.read_csv(labels_test_csv)\n","# Check len of IDs\n","print('Train:', len(train_IDs))\n","print('Test:', len(test_IDs))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Train: 94\n","Test: 9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"icvCSDSHDLUl","colab_type":"code","colab":{}},"source":["def generateDatasetIDS(list, root_folder = \"/content/drive/My Drive/datasets/DepthData/images\"):\n","  \"\"\"\n","  Return a list with all the image paths relative to those IDs\n","  \"\"\"\n","  test_list = []\n","  for id in list:\n","    #print(\"Id:\", id)\n","    for root, dirs, files in os.walk(root_folder + str(id) ):\n","        for filename in files:\n","            #print(\"\\t\", str(id) + \"/\" + filename)\n","            if('.png' in filename):\n","              add_file = str(id) + \"/\" + filename\n","              test_list.append(add_file)\n","  return test_list\n","\n","class CustomListDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, images_list, df_weights, root_dir,transform = None):\n","        \"\"\"\n","        Args:\n","            images_list(list): list with IDs into the dataset\n","            root_dir(string): directory with all the images\n","            df_weights(pd_dataframe): dataframe with all the weights of the people\n","            transform: trasform operation for images\n","        \"\"\"\n","        self.images_list = images_list\n","        self.root_dir = root_dir\n","        self.df_weights = df_weights\n","        self.df_weights = self.df_weights['WEIGHT'].values\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images_list)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.root_dir, self.images_list[idx])\n","        image = Image.open(img_name)\n","        image = image.convert(mode='RGB')\n","        if(self.transform is not None):\n","            image = self.transform(image)\n","        frame_name = self.images_list[idx].split(\"/\")\n","        id = int(frame_name[0]) \n","        labels = self.df_weights[id]\n","        labels = np.float(labels)\n","        return image, torch.as_tensor(labels)\n","\n","transform = transforms.Compose([\n","    # you can add other transformations in this list\n","    #transforms.Resize((299,299), interpolation=2),\n","    #transforms.RandomHorizontalFlip(),\n","    #transforms.RandomRotation(20),\n","    transforms.ToTensor()\n","])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUul2Fts-U2W","colab_type":"code","colab":{}},"source":["# save checkpoint function\n","def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n","    torch.save(state, filename)\n","    if is_best:\n","        shutil.copyfile(filename, filename + \"best\")\n","\n","def adjust_learning_rate(optimizer, epoch, learning_rate):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 100 epochs\"\"\"\n","    lr = learning_rate * (0.1 ** (epoch // 50))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","    return lr\n","\n","def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UgrUvQGv_Xew","colab_type":"code","outputId":"3d45328f-3e31-405c-feb9-4f45c6c5b90e","executionInfo":{"status":"ok","timestamp":1590831527827,"user_tz":-120,"elapsed":5895805,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import time\n","seed_torch(11)\n","device='cuda:0'\n","learning_rate = 0.01\n","momentum_ = 0.9\n","weight_decay = 1e-4\n","\n","num_epochs = 100\n","splits = 3\n","batch_size = 32\n","\n","model = EfficientNet.from_pretrained(net_name)\n","model._fc = nn.Linear(2048, 1)\n","print(model)\n","\n","\n","optimizer = get_optimizer(model, learning_rate)\n","# optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n","#                                 momentum=momentum_,\n","#                                 weight_decay=weight_decay)\n","\n","loss_fn = get_cost_function()\n","\n","kf = KFold(n_splits=splits, shuffle=True)\n","fold = 1\n","\n","# best accuracy to be stored\n","best_acc1 = 0\n","\n","\"\"\"# Add values to plots\n","tb.save_value('Loss/train_loss', visualization_name, 0, train_loss)\n","tb.save_value('Loss/test_loss', visualization_name, 0, test_loss)\n","\n","# Update plots \n","tb.flush_line(visualization_name)\n","\"\"\"\n","global_epoch = 0\n","\n","for train_index, test_index in kf.split(train_IDs):\n","  #print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n","  model.cuda()\n","  train_images_list = generateDatasetIDS(train_index, content)\n","  train = CustomListDataset(images_list = train_images_list, df_weights = weights, root_dir=content, transform = transform)\n","  trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\n","\n","  test_images_list = generateDatasetIDS(test_index, content)\n","  test = CustomListDataset(images_list = test_images_list, df_weights = weights, root_dir=content, transform = transform)\n","  validationloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n","\n","  print(f'Len Train (in batch): {len(trainloader)}')\n","  print(f'Len validation (in batch): {len(validationloader)}')\n","\n","  print(f'Fold {fold}')\n","  fold += 1\n","  \n","  for epoch in range(num_epochs):\n","      start_time = time.time()\n","      \n","      # adjust learning rate\n","      curr_learnig = adjust_learning_rate(optimizer, global_epoch, learning_rate)\n","      global_epoch += 1\n","\n","      model.train()\n","      avg_loss = 0.\n","      cumulative_loss = 0.\n","      samples = 0\n","      for i, (x_batch, y_batch) in enumerate(trainloader):\n","          x_batch = x_batch.to(device)\n","          y_batch = y_batch.to(device)\n","          y_batch = y_batch.view(-1,1)\n","          y_pred = model(x_batch)\n","          loss = loss_fn(y_pred, y_batch)\n","          \n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          \n","          samples+=x_batch.shape[0]\n","          cumulative_loss += loss.item()\n","      avg_loss = cumulative_loss / samples\n","      \n","      model.eval()\n","      avg_val_loss = 0.\n","      cumulative_val_loss = 0.\n","      val_samples = 0\n","      with torch.no_grad():\n","        for i, (x_batch, y_batch) in enumerate(validationloader):\n","            x_batch = x_batch.to(device)\n","            y_batch = y_batch.to(device)\n","            y_batch = y_batch.view(-1,1)\n","            y_pred = model(x_batch)\n","            cumulative_val_loss += loss_fn(y_pred, y_batch).item()\n","            val_samples += x_batch.shape[0]\n","        avg_val_loss = cumulative_val_loss / val_samples\n","          #valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n","\n","      elapsed_time = time.time() - start_time \n","\n","      writer.add_scalar('training loss',\n","                            avg_loss,\n","                            global_epoch)\n","      \n","      writer.add_scalar('validation loss',\n","                            avg_val_loss,\n","                            global_epoch)\n","\n","      acc1 = avg_val_loss\n","\n","      # remember best acc@1 and save checkpoint\n","      is_best = acc1 > best_acc1\n","      best_acc1 = max(acc1, best_acc1)\n","\n","      print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s , lr={:.4f}'.format(\n","          epoch + 1, num_epochs, avg_loss, avg_val_loss, elapsed_time, curr_learnig))\n","      \n","      torch.save(model.state_dict(), \"/content/drive/My Drive/model/efficientnet-b5_100_fold\" + str(fold) + \".pt\") \n","\n","      \n","      # save every 20 epoches\n","      # if epoch%20:\n","      #   save_checkpoint({\n","      #       'epoch': epoch + 1,\n","      #       'fold': fold,\n","      #       'state_dict': model.state_dict(),\n","      #       'best_acc1': best_acc1,\n","      #       'optimizer' : optimizer.state_dict(),\n","      #   }, is_best, \"/content/drive/My Drive/model/effic_lr01_200epoch-fold\" + str(fold) + \"epochnum\" + str(epoch+1)+ \".pth.tar\")\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b5\n","EfficientNet(\n","  (_conv_stem): Conv2dStaticSamePadding(\n","    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n","    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n","  )\n","  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_blocks): ModuleList(\n","    (0): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        48, 12, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        12, 48, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (1): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        24, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 24, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (2): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        24, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 24, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (3): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n","        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        144, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 144, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (4): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (5): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (6): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (7): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (8): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (9): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (10): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (11): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (12): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (13): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(3, 3), stride=[2, 2], groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (14): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (15): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (16): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (17): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (18): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (19): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (20): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(5, 5), stride=[1, 1], groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (21): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (22): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (23): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (24): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (25): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (26): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (27): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=[2, 2], groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (28): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (29): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (30): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (31): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (32): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (33): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (34): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (35): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (36): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(3, 3), stride=[1, 1], groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (37): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (38): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (_conv_head): Conv2dStaticSamePadding(\n","    512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","    (static_padding): Identity()\n","  )\n","  (_bn1): BatchNorm2d(2048, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_fc): Linear(in_features=2048, out_features=1, bias=True)\n",")\n","Len Train (in batch): 38\n","Len validation (in batch): 22\n","Fold 1\n","Epoch 1/100 \t loss=32.0519 \t val_loss=5746768491196218.0000 \t time=764.54s , lr=0.0100\n","Epoch 2/100 \t loss=1.7721 \t val_loss=40.8998 \t time=16.08s , lr=0.0100\n","Epoch 3/100 \t loss=1.8320 \t val_loss=55.6996 \t time=16.09s , lr=0.0100\n","Epoch 4/100 \t loss=1.6027 \t val_loss=17.6722 \t time=16.13s , lr=0.0100\n","Epoch 5/100 \t loss=1.2792 \t val_loss=34.9161 \t time=16.09s , lr=0.0100\n","Epoch 6/100 \t loss=1.0004 \t val_loss=45.4619 \t time=15.98s , lr=0.0100\n","Epoch 7/100 \t loss=0.8173 \t val_loss=16.1245 \t time=16.06s , lr=0.0100\n","Epoch 8/100 \t loss=0.7638 \t val_loss=14.2111 \t time=16.11s , lr=0.0100\n","Epoch 9/100 \t loss=0.8558 \t val_loss=9.2217 \t time=16.21s , lr=0.0100\n","Epoch 10/100 \t loss=0.9408 \t val_loss=38.1614 \t time=15.99s , lr=0.0100\n","Epoch 11/100 \t loss=0.6164 \t val_loss=7.1224 \t time=16.04s , lr=0.0100\n","Epoch 12/100 \t loss=0.5455 \t val_loss=39.4123 \t time=16.06s , lr=0.0100\n","Epoch 13/100 \t loss=0.5027 \t val_loss=6.5370 \t time=15.98s , lr=0.0100\n","Epoch 14/100 \t loss=0.5411 \t val_loss=2.1732 \t time=15.96s , lr=0.0100\n","Epoch 15/100 \t loss=0.6241 \t val_loss=39.7571 \t time=16.07s , lr=0.0100\n","Epoch 16/100 \t loss=0.6884 \t val_loss=6.5368 \t time=16.25s , lr=0.0100\n","Epoch 17/100 \t loss=0.6753 \t val_loss=63.9556 \t time=15.98s , lr=0.0100\n","Epoch 18/100 \t loss=0.6542 \t val_loss=18.7893 \t time=16.18s , lr=0.0100\n","Epoch 19/100 \t loss=0.8391 \t val_loss=46.5172 \t time=16.10s , lr=0.0100\n","Epoch 20/100 \t loss=0.8535 \t val_loss=33.3908 \t time=16.12s , lr=0.0100\n","Epoch 21/100 \t loss=0.6462 \t val_loss=4.9284 \t time=16.26s , lr=0.0100\n","Epoch 22/100 \t loss=0.6348 \t val_loss=5.9596 \t time=16.03s , lr=0.0100\n","Epoch 23/100 \t loss=0.5807 \t val_loss=6.2217 \t time=16.10s , lr=0.0100\n","Epoch 24/100 \t loss=0.5486 \t val_loss=3.7488 \t time=16.12s , lr=0.0100\n","Epoch 25/100 \t loss=0.4436 \t val_loss=1.7731 \t time=15.98s , lr=0.0100\n","Epoch 26/100 \t loss=0.4339 \t val_loss=2.0691 \t time=16.08s , lr=0.0100\n","Epoch 27/100 \t loss=0.4997 \t val_loss=1.7785 \t time=16.19s , lr=0.0100\n","Epoch 28/100 \t loss=0.4319 \t val_loss=9.0731 \t time=16.13s , lr=0.0100\n","Epoch 29/100 \t loss=0.4088 \t val_loss=2.8028 \t time=16.17s , lr=0.0100\n","Epoch 30/100 \t loss=0.3407 \t val_loss=5.3264 \t time=16.27s , lr=0.0100\n","Epoch 31/100 \t loss=0.4529 \t val_loss=1.8846 \t time=16.17s , lr=0.0100\n","Epoch 32/100 \t loss=0.6193 \t val_loss=1.8507 \t time=16.14s , lr=0.0100\n","Epoch 33/100 \t loss=0.5445 \t val_loss=2.2940 \t time=16.07s , lr=0.0100\n","Epoch 34/100 \t loss=0.3502 \t val_loss=2.0143 \t time=16.32s , lr=0.0100\n","Epoch 35/100 \t loss=0.3005 \t val_loss=2.4086 \t time=16.12s , lr=0.0100\n","Epoch 36/100 \t loss=0.3360 \t val_loss=2.3960 \t time=16.15s , lr=0.0100\n","Epoch 37/100 \t loss=0.3811 \t val_loss=13.3154 \t time=16.13s , lr=0.0100\n","Epoch 38/100 \t loss=0.4394 \t val_loss=2.3202 \t time=16.23s , lr=0.0100\n","Epoch 39/100 \t loss=0.4524 \t val_loss=29.4818 \t time=16.28s , lr=0.0100\n","Epoch 40/100 \t loss=0.3740 \t val_loss=3.9068 \t time=16.24s , lr=0.0100\n","Epoch 41/100 \t loss=0.4025 \t val_loss=2.4170 \t time=16.25s , lr=0.0100\n","Epoch 42/100 \t loss=0.3737 \t val_loss=3.0918 \t time=16.25s , lr=0.0100\n","Epoch 43/100 \t loss=0.4478 \t val_loss=3.8839 \t time=16.18s , lr=0.0100\n","Epoch 44/100 \t loss=0.4985 \t val_loss=4.5551 \t time=16.11s , lr=0.0100\n","Epoch 45/100 \t loss=0.6418 \t val_loss=10.2904 \t time=16.26s , lr=0.0100\n","Epoch 46/100 \t loss=0.4711 \t val_loss=7.4126 \t time=16.23s , lr=0.0100\n","Epoch 47/100 \t loss=0.3002 \t val_loss=2.4172 \t time=16.06s , lr=0.0100\n","Epoch 48/100 \t loss=0.3628 \t val_loss=11.0540 \t time=16.10s , lr=0.0100\n","Epoch 49/100 \t loss=0.6243 \t val_loss=14.7670 \t time=16.17s , lr=0.0100\n","Epoch 50/100 \t loss=1.2894 \t val_loss=39.2643 \t time=16.31s , lr=0.0100\n","Epoch 51/100 \t loss=0.4495 \t val_loss=14.7429 \t time=16.08s , lr=0.0010\n","Epoch 52/100 \t loss=0.3923 \t val_loss=4.7310 \t time=16.27s , lr=0.0010\n","Epoch 53/100 \t loss=0.3010 \t val_loss=2.5580 \t time=16.06s , lr=0.0010\n","Epoch 54/100 \t loss=0.3713 \t val_loss=1.9399 \t time=16.18s , lr=0.0010\n","Epoch 55/100 \t loss=0.2981 \t val_loss=1.7429 \t time=16.09s , lr=0.0010\n","Epoch 56/100 \t loss=0.2408 \t val_loss=1.8786 \t time=16.06s , lr=0.0010\n","Epoch 57/100 \t loss=0.2567 \t val_loss=2.1179 \t time=16.15s , lr=0.0010\n","Epoch 58/100 \t loss=0.2418 \t val_loss=1.8591 \t time=16.13s , lr=0.0010\n","Epoch 59/100 \t loss=0.1912 \t val_loss=1.9546 \t time=16.10s , lr=0.0010\n","Epoch 60/100 \t loss=0.3931 \t val_loss=1.7996 \t time=16.05s , lr=0.0010\n","Epoch 61/100 \t loss=0.2281 \t val_loss=1.9548 \t time=15.96s , lr=0.0010\n","Epoch 62/100 \t loss=0.1790 \t val_loss=2.0345 \t time=16.04s , lr=0.0010\n","Epoch 63/100 \t loss=0.2944 \t val_loss=2.2665 \t time=16.12s , lr=0.0010\n","Epoch 64/100 \t loss=0.2289 \t val_loss=2.2860 \t time=15.95s , lr=0.0010\n","Epoch 65/100 \t loss=0.3576 \t val_loss=1.7959 \t time=16.19s , lr=0.0010\n","Epoch 66/100 \t loss=0.3192 \t val_loss=2.4310 \t time=15.99s , lr=0.0010\n","Epoch 67/100 \t loss=0.2092 \t val_loss=2.1366 \t time=16.09s , lr=0.0010\n","Epoch 68/100 \t loss=0.3067 \t val_loss=1.8378 \t time=15.92s , lr=0.0010\n","Epoch 69/100 \t loss=0.2196 \t val_loss=2.1860 \t time=15.93s , lr=0.0010\n","Epoch 70/100 \t loss=0.1793 \t val_loss=2.3066 \t time=15.99s , lr=0.0010\n","Epoch 71/100 \t loss=0.1841 \t val_loss=2.5764 \t time=16.01s , lr=0.0010\n","Epoch 72/100 \t loss=0.1821 \t val_loss=2.0493 \t time=16.08s , lr=0.0010\n","Epoch 73/100 \t loss=0.1993 \t val_loss=1.9304 \t time=16.08s , lr=0.0010\n","Epoch 74/100 \t loss=0.1519 \t val_loss=2.1225 \t time=16.04s , lr=0.0010\n","Epoch 75/100 \t loss=0.1419 \t val_loss=2.3189 \t time=16.14s , lr=0.0010\n","Epoch 76/100 \t loss=0.1463 \t val_loss=2.3105 \t time=16.09s , lr=0.0010\n","Epoch 77/100 \t loss=0.1513 \t val_loss=1.9655 \t time=15.98s , lr=0.0010\n","Epoch 78/100 \t loss=0.1693 \t val_loss=2.0913 \t time=15.95s , lr=0.0010\n","Epoch 79/100 \t loss=0.1638 \t val_loss=1.8365 \t time=15.99s , lr=0.0010\n","Epoch 80/100 \t loss=0.1561 \t val_loss=1.7824 \t time=16.01s , lr=0.0010\n","Epoch 81/100 \t loss=0.1652 \t val_loss=2.0227 \t time=16.03s , lr=0.0010\n","Epoch 82/100 \t loss=0.3215 \t val_loss=1.8281 \t time=16.01s , lr=0.0010\n","Epoch 83/100 \t loss=0.1946 \t val_loss=1.9716 \t time=16.05s , lr=0.0010\n","Epoch 84/100 \t loss=0.1872 \t val_loss=1.8712 \t time=16.14s , lr=0.0010\n","Epoch 85/100 \t loss=0.1450 \t val_loss=1.7915 \t time=16.10s , lr=0.0010\n","Epoch 86/100 \t loss=0.1400 \t val_loss=1.7381 \t time=16.12s , lr=0.0010\n","Epoch 87/100 \t loss=0.1334 \t val_loss=1.7504 \t time=16.41s , lr=0.0010\n","Epoch 88/100 \t loss=0.1312 \t val_loss=1.9629 \t time=16.09s , lr=0.0010\n","Epoch 89/100 \t loss=0.1310 \t val_loss=2.0689 \t time=16.02s , lr=0.0010\n","Epoch 90/100 \t loss=0.1671 \t val_loss=1.9047 \t time=16.11s , lr=0.0010\n","Epoch 91/100 \t loss=0.1314 \t val_loss=1.8101 \t time=16.05s , lr=0.0010\n","Epoch 92/100 \t loss=0.1370 \t val_loss=1.9475 \t time=16.15s , lr=0.0010\n","Epoch 93/100 \t loss=0.1246 \t val_loss=1.8913 \t time=16.17s , lr=0.0010\n","Epoch 94/100 \t loss=0.1867 \t val_loss=1.7941 \t time=16.02s , lr=0.0010\n","Epoch 95/100 \t loss=0.1567 \t val_loss=1.8129 \t time=16.11s , lr=0.0010\n","Epoch 96/100 \t loss=0.1384 \t val_loss=1.8910 \t time=15.96s , lr=0.0010\n","Epoch 97/100 \t loss=0.1345 \t val_loss=1.7570 \t time=16.02s , lr=0.0010\n","Epoch 98/100 \t loss=0.1209 \t val_loss=2.0634 \t time=15.99s , lr=0.0010\n","Epoch 99/100 \t loss=0.1135 \t val_loss=1.9333 \t time=16.14s , lr=0.0010\n","Epoch 100/100 \t loss=0.1195 \t val_loss=1.8237 \t time=16.18s , lr=0.0010\n","Len Train (in batch): 40\n","Len validation (in batch): 19\n","Fold 2\n","Epoch 1/100 \t loss=0.9596 \t val_loss=0.1062 \t time=16.56s , lr=0.0001\n","Epoch 2/100 \t loss=0.7578 \t val_loss=0.2267 \t time=16.65s , lr=0.0001\n","Epoch 3/100 \t loss=0.6764 \t val_loss=0.1411 \t time=16.66s , lr=0.0001\n","Epoch 4/100 \t loss=0.6256 \t val_loss=0.1340 \t time=16.50s , lr=0.0001\n","Epoch 5/100 \t loss=0.5802 \t val_loss=0.1166 \t time=16.90s , lr=0.0001\n","Epoch 6/100 \t loss=0.5424 \t val_loss=0.1399 \t time=16.64s , lr=0.0001\n","Epoch 7/100 \t loss=0.5015 \t val_loss=0.1217 \t time=16.63s , lr=0.0001\n","Epoch 8/100 \t loss=0.4787 \t val_loss=0.1732 \t time=16.64s , lr=0.0001\n","Epoch 9/100 \t loss=0.4512 \t val_loss=0.1176 \t time=16.64s , lr=0.0001\n","Epoch 10/100 \t loss=0.4168 \t val_loss=0.1120 \t time=16.63s , lr=0.0001\n","Epoch 11/100 \t loss=0.4114 \t val_loss=0.1198 \t time=16.50s , lr=0.0001\n","Epoch 12/100 \t loss=0.4052 \t val_loss=0.1122 \t time=16.53s , lr=0.0001\n","Epoch 13/100 \t loss=0.3430 \t val_loss=0.1407 \t time=16.70s , lr=0.0001\n","Epoch 14/100 \t loss=0.3402 \t val_loss=0.1423 \t time=16.62s , lr=0.0001\n","Epoch 15/100 \t loss=0.3353 \t val_loss=0.1259 \t time=16.49s , lr=0.0001\n","Epoch 16/100 \t loss=0.3258 \t val_loss=0.1506 \t time=16.44s , lr=0.0001\n","Epoch 17/100 \t loss=0.3076 \t val_loss=0.1369 \t time=16.73s , lr=0.0001\n","Epoch 18/100 \t loss=0.3093 \t val_loss=0.1796 \t time=16.60s , lr=0.0001\n","Epoch 19/100 \t loss=0.2803 \t val_loss=0.1593 \t time=16.47s , lr=0.0001\n","Epoch 20/100 \t loss=0.2795 \t val_loss=0.1710 \t time=16.66s , lr=0.0001\n","Epoch 21/100 \t loss=0.2567 \t val_loss=0.1830 \t time=16.61s , lr=0.0001\n","Epoch 22/100 \t loss=0.2570 \t val_loss=0.1720 \t time=16.47s , lr=0.0001\n","Epoch 23/100 \t loss=0.2374 \t val_loss=0.1844 \t time=16.60s , lr=0.0001\n","Epoch 24/100 \t loss=0.2315 \t val_loss=0.2039 \t time=16.59s , lr=0.0001\n","Epoch 25/100 \t loss=0.2200 \t val_loss=0.2105 \t time=16.51s , lr=0.0001\n","Epoch 26/100 \t loss=0.2278 \t val_loss=0.1938 \t time=16.53s , lr=0.0001\n","Epoch 27/100 \t loss=0.2150 \t val_loss=0.1836 \t time=16.55s , lr=0.0001\n","Epoch 28/100 \t loss=0.1936 \t val_loss=0.2118 \t time=16.51s , lr=0.0001\n","Epoch 29/100 \t loss=0.2065 \t val_loss=0.1908 \t time=16.71s , lr=0.0001\n","Epoch 30/100 \t loss=0.2136 \t val_loss=0.1799 \t time=16.48s , lr=0.0001\n","Epoch 31/100 \t loss=0.1983 \t val_loss=0.2302 \t time=16.59s , lr=0.0001\n","Epoch 32/100 \t loss=0.1868 \t val_loss=0.2209 \t time=16.76s , lr=0.0001\n","Epoch 33/100 \t loss=0.2023 \t val_loss=0.2236 \t time=16.63s , lr=0.0001\n","Epoch 34/100 \t loss=0.1753 \t val_loss=0.2039 \t time=16.98s , lr=0.0001\n","Epoch 35/100 \t loss=0.1828 \t val_loss=0.1909 \t time=16.65s , lr=0.0001\n","Epoch 36/100 \t loss=0.1702 \t val_loss=0.1995 \t time=16.52s , lr=0.0001\n","Epoch 37/100 \t loss=0.1749 \t val_loss=0.2045 \t time=16.48s , lr=0.0001\n","Epoch 38/100 \t loss=0.1775 \t val_loss=0.1988 \t time=16.61s , lr=0.0001\n","Epoch 39/100 \t loss=0.1684 \t val_loss=0.2068 \t time=16.63s , lr=0.0001\n","Epoch 40/100 \t loss=0.1583 \t val_loss=0.2008 \t time=16.42s , lr=0.0001\n","Epoch 41/100 \t loss=0.1725 \t val_loss=0.2391 \t time=16.51s , lr=0.0001\n","Epoch 42/100 \t loss=0.1583 \t val_loss=0.2129 \t time=16.39s , lr=0.0001\n","Epoch 43/100 \t loss=0.1536 \t val_loss=0.2043 \t time=16.41s , lr=0.0001\n","Epoch 44/100 \t loss=0.1532 \t val_loss=0.1928 \t time=16.54s , lr=0.0001\n","Epoch 45/100 \t loss=0.1538 \t val_loss=0.2293 \t time=16.53s , lr=0.0001\n","Epoch 46/100 \t loss=0.1528 \t val_loss=0.2233 \t time=16.54s , lr=0.0001\n","Epoch 47/100 \t loss=0.1387 \t val_loss=0.2009 \t time=16.52s , lr=0.0001\n","Epoch 48/100 \t loss=0.1488 \t val_loss=0.2154 \t time=16.51s , lr=0.0001\n","Epoch 49/100 \t loss=0.1344 \t val_loss=0.2101 \t time=16.42s , lr=0.0001\n","Epoch 50/100 \t loss=0.1446 \t val_loss=0.2017 \t time=16.44s , lr=0.0001\n","Epoch 51/100 \t loss=0.1520 \t val_loss=0.2068 \t time=16.44s , lr=0.0000\n","Epoch 52/100 \t loss=0.1334 \t val_loss=0.2098 \t time=16.46s , lr=0.0000\n","Epoch 53/100 \t loss=0.1385 \t val_loss=0.2134 \t time=16.50s , lr=0.0000\n","Epoch 54/100 \t loss=0.1387 \t val_loss=0.2183 \t time=16.56s , lr=0.0000\n","Epoch 55/100 \t loss=0.1409 \t val_loss=0.2147 \t time=16.40s , lr=0.0000\n","Epoch 56/100 \t loss=0.1368 \t val_loss=0.2145 \t time=16.54s , lr=0.0000\n","Epoch 57/100 \t loss=0.1370 \t val_loss=0.2195 \t time=16.40s , lr=0.0000\n","Epoch 58/100 \t loss=0.1485 \t val_loss=0.2153 \t time=16.45s , lr=0.0000\n","Epoch 59/100 \t loss=0.1376 \t val_loss=0.2163 \t time=16.46s , lr=0.0000\n","Epoch 60/100 \t loss=0.1408 \t val_loss=0.2150 \t time=16.52s , lr=0.0000\n","Epoch 61/100 \t loss=0.1370 \t val_loss=0.2126 \t time=16.42s , lr=0.0000\n","Epoch 62/100 \t loss=0.1355 \t val_loss=0.2116 \t time=16.47s , lr=0.0000\n","Epoch 63/100 \t loss=0.1345 \t val_loss=0.2134 \t time=16.76s , lr=0.0000\n","Epoch 64/100 \t loss=0.1273 \t val_loss=0.2130 \t time=16.51s , lr=0.0000\n","Epoch 65/100 \t loss=0.1322 \t val_loss=0.2141 \t time=16.46s , lr=0.0000\n","Epoch 66/100 \t loss=0.1371 \t val_loss=0.2153 \t time=16.43s , lr=0.0000\n","Epoch 67/100 \t loss=0.1405 \t val_loss=0.2159 \t time=16.46s , lr=0.0000\n","Epoch 68/100 \t loss=0.1293 \t val_loss=0.2153 \t time=16.50s , lr=0.0000\n","Epoch 69/100 \t loss=0.1328 \t val_loss=0.2149 \t time=16.52s , lr=0.0000\n","Epoch 70/100 \t loss=0.1252 \t val_loss=0.2151 \t time=16.35s , lr=0.0000\n","Epoch 71/100 \t loss=0.1444 \t val_loss=0.2156 \t time=16.51s , lr=0.0000\n","Epoch 72/100 \t loss=0.1461 \t val_loss=0.2126 \t time=16.37s , lr=0.0000\n","Epoch 73/100 \t loss=0.1293 \t val_loss=0.2174 \t time=16.33s , lr=0.0000\n","Epoch 74/100 \t loss=0.1303 \t val_loss=0.2133 \t time=16.46s , lr=0.0000\n","Epoch 75/100 \t loss=0.1320 \t val_loss=0.2159 \t time=16.47s , lr=0.0000\n","Epoch 76/100 \t loss=0.1282 \t val_loss=0.2160 \t time=16.48s , lr=0.0000\n","Epoch 77/100 \t loss=0.1291 \t val_loss=0.2192 \t time=16.52s , lr=0.0000\n","Epoch 78/100 \t loss=0.1330 \t val_loss=0.2119 \t time=16.24s , lr=0.0000\n","Epoch 79/100 \t loss=0.1341 \t val_loss=0.2152 \t time=16.29s , lr=0.0000\n","Epoch 80/100 \t loss=0.1246 \t val_loss=0.2157 \t time=16.44s , lr=0.0000\n","Epoch 81/100 \t loss=0.1370 \t val_loss=0.2151 \t time=16.40s , lr=0.0000\n","Epoch 82/100 \t loss=0.1350 \t val_loss=0.2158 \t time=16.57s , lr=0.0000\n","Epoch 83/100 \t loss=0.1389 \t val_loss=0.2164 \t time=16.43s , lr=0.0000\n","Epoch 84/100 \t loss=0.1351 \t val_loss=0.2144 \t time=16.45s , lr=0.0000\n","Epoch 85/100 \t loss=0.1233 \t val_loss=0.2100 \t time=16.48s , lr=0.0000\n","Epoch 86/100 \t loss=0.1336 \t val_loss=0.2130 \t time=16.61s , lr=0.0000\n","Epoch 87/100 \t loss=0.1358 \t val_loss=0.2183 \t time=16.50s , lr=0.0000\n","Epoch 88/100 \t loss=0.1339 \t val_loss=0.2173 \t time=16.48s , lr=0.0000\n","Epoch 89/100 \t loss=0.1306 \t val_loss=0.2219 \t time=16.51s , lr=0.0000\n","Epoch 90/100 \t loss=0.1307 \t val_loss=0.2166 \t time=16.44s , lr=0.0000\n","Epoch 91/100 \t loss=0.1201 \t val_loss=0.2186 \t time=16.52s , lr=0.0000\n","Epoch 92/100 \t loss=0.1339 \t val_loss=0.2191 \t time=16.84s , lr=0.0000\n","Epoch 93/100 \t loss=0.1368 \t val_loss=0.2138 \t time=16.50s , lr=0.0000\n","Epoch 94/100 \t loss=0.1297 \t val_loss=0.2145 \t time=16.50s , lr=0.0000\n","Epoch 95/100 \t loss=0.1400 \t val_loss=0.2139 \t time=16.43s , lr=0.0000\n","Epoch 96/100 \t loss=0.1312 \t val_loss=0.2171 \t time=16.60s , lr=0.0000\n","Epoch 97/100 \t loss=0.1331 \t val_loss=0.2182 \t time=16.57s , lr=0.0000\n","Epoch 98/100 \t loss=0.1329 \t val_loss=0.2193 \t time=16.47s , lr=0.0000\n","Epoch 99/100 \t loss=0.1296 \t val_loss=0.2234 \t time=16.50s , lr=0.0000\n","Epoch 100/100 \t loss=0.1233 \t val_loss=0.2169 \t time=16.58s , lr=0.0000\n","Len Train (in batch): 41\n","Len validation (in batch): 19\n","Fold 3\n","Epoch 1/100 \t loss=0.2141 \t val_loss=0.0255 \t time=16.87s , lr=0.0000\n","Epoch 2/100 \t loss=0.2158 \t val_loss=0.0247 \t time=16.85s , lr=0.0000\n","Epoch 3/100 \t loss=0.2207 \t val_loss=0.0245 \t time=16.74s , lr=0.0000\n","Epoch 4/100 \t loss=0.2249 \t val_loss=0.0245 \t time=16.79s , lr=0.0000\n","Epoch 5/100 \t loss=0.2174 \t val_loss=0.0243 \t time=16.75s , lr=0.0000\n","Epoch 6/100 \t loss=0.2125 \t val_loss=0.0248 \t time=16.85s , lr=0.0000\n","Epoch 7/100 \t loss=0.2101 \t val_loss=0.0245 \t time=16.73s , lr=0.0000\n","Epoch 8/100 \t loss=0.2232 \t val_loss=0.0246 \t time=16.80s , lr=0.0000\n","Epoch 9/100 \t loss=0.2126 \t val_loss=0.0240 \t time=16.87s , lr=0.0000\n","Epoch 10/100 \t loss=0.2170 \t val_loss=0.0241 \t time=16.78s , lr=0.0000\n","Epoch 11/100 \t loss=0.2195 \t val_loss=0.0241 \t time=16.84s , lr=0.0000\n","Epoch 12/100 \t loss=0.2141 \t val_loss=0.0245 \t time=16.91s , lr=0.0000\n","Epoch 13/100 \t loss=0.2115 \t val_loss=0.0239 \t time=16.83s , lr=0.0000\n","Epoch 14/100 \t loss=0.2099 \t val_loss=0.0237 \t time=16.90s , lr=0.0000\n","Epoch 15/100 \t loss=0.2154 \t val_loss=0.0240 \t time=16.83s , lr=0.0000\n","Epoch 16/100 \t loss=0.2070 \t val_loss=0.0238 \t time=16.99s , lr=0.0000\n","Epoch 17/100 \t loss=0.2002 \t val_loss=0.0241 \t time=16.93s , lr=0.0000\n","Epoch 18/100 \t loss=0.2098 \t val_loss=0.0240 \t time=16.90s , lr=0.0000\n","Epoch 19/100 \t loss=0.1965 \t val_loss=0.0242 \t time=16.89s , lr=0.0000\n","Epoch 20/100 \t loss=0.2155 \t val_loss=0.0241 \t time=16.94s , lr=0.0000\n","Epoch 21/100 \t loss=0.2077 \t val_loss=0.0241 \t time=17.17s , lr=0.0000\n","Epoch 22/100 \t loss=0.1916 \t val_loss=0.0234 \t time=16.91s , lr=0.0000\n","Epoch 23/100 \t loss=0.2165 \t val_loss=0.0239 \t time=16.99s , lr=0.0000\n","Epoch 24/100 \t loss=0.2005 \t val_loss=0.0238 \t time=16.83s , lr=0.0000\n","Epoch 25/100 \t loss=0.1936 \t val_loss=0.0239 \t time=16.83s , lr=0.0000\n","Epoch 26/100 \t loss=0.1961 \t val_loss=0.0238 \t time=17.04s , lr=0.0000\n","Epoch 27/100 \t loss=0.2177 \t val_loss=0.0231 \t time=16.85s , lr=0.0000\n","Epoch 28/100 \t loss=0.2008 \t val_loss=0.0229 \t time=16.94s , lr=0.0000\n","Epoch 29/100 \t loss=0.1964 \t val_loss=0.0229 \t time=16.97s , lr=0.0000\n","Epoch 30/100 \t loss=0.2149 \t val_loss=0.0232 \t time=16.86s , lr=0.0000\n","Epoch 31/100 \t loss=0.2078 \t val_loss=0.0232 \t time=16.85s , lr=0.0000\n","Epoch 32/100 \t loss=0.2087 \t val_loss=0.0232 \t time=16.90s , lr=0.0000\n","Epoch 33/100 \t loss=0.1983 \t val_loss=0.0233 \t time=16.85s , lr=0.0000\n","Epoch 34/100 \t loss=0.1937 \t val_loss=0.0233 \t time=16.78s , lr=0.0000\n","Epoch 35/100 \t loss=0.2120 \t val_loss=0.0229 \t time=16.87s , lr=0.0000\n","Epoch 36/100 \t loss=0.2131 \t val_loss=0.0223 \t time=16.70s , lr=0.0000\n","Epoch 37/100 \t loss=0.1828 \t val_loss=0.0226 \t time=16.94s , lr=0.0000\n","Epoch 38/100 \t loss=0.1899 \t val_loss=0.0228 \t time=16.84s , lr=0.0000\n","Epoch 39/100 \t loss=0.1988 \t val_loss=0.0229 \t time=16.85s , lr=0.0000\n","Epoch 40/100 \t loss=0.2000 \t val_loss=0.0232 \t time=16.92s , lr=0.0000\n","Epoch 41/100 \t loss=0.1951 \t val_loss=0.0233 \t time=16.94s , lr=0.0000\n","Epoch 42/100 \t loss=0.1896 \t val_loss=0.0235 \t time=16.98s , lr=0.0000\n","Epoch 43/100 \t loss=0.1955 \t val_loss=0.0236 \t time=16.92s , lr=0.0000\n","Epoch 44/100 \t loss=0.1849 \t val_loss=0.0231 \t time=16.82s , lr=0.0000\n","Epoch 45/100 \t loss=0.1883 \t val_loss=0.0231 \t time=16.95s , lr=0.0000\n","Epoch 46/100 \t loss=0.1962 \t val_loss=0.0231 \t time=16.94s , lr=0.0000\n","Epoch 47/100 \t loss=0.1844 \t val_loss=0.0230 \t time=17.01s , lr=0.0000\n","Epoch 48/100 \t loss=0.1976 \t val_loss=0.0231 \t time=16.88s , lr=0.0000\n","Epoch 49/100 \t loss=0.2063 \t val_loss=0.0232 \t time=16.93s , lr=0.0000\n","Epoch 50/100 \t loss=0.1968 \t val_loss=0.0232 \t time=16.80s , lr=0.0000\n","Epoch 51/100 \t loss=0.1904 \t val_loss=0.0235 \t time=16.77s , lr=0.0000\n","Epoch 52/100 \t loss=0.1859 \t val_loss=0.0235 \t time=16.76s , lr=0.0000\n","Epoch 53/100 \t loss=0.2126 \t val_loss=0.0236 \t time=16.94s , lr=0.0000\n","Epoch 54/100 \t loss=0.1875 \t val_loss=0.0233 \t time=16.89s , lr=0.0000\n","Epoch 55/100 \t loss=0.1879 \t val_loss=0.0236 \t time=16.78s , lr=0.0000\n","Epoch 56/100 \t loss=0.1949 \t val_loss=0.0241 \t time=16.68s , lr=0.0000\n","Epoch 57/100 \t loss=0.1939 \t val_loss=0.0239 \t time=16.90s , lr=0.0000\n","Epoch 58/100 \t loss=0.1953 \t val_loss=0.0239 \t time=16.87s , lr=0.0000\n","Epoch 59/100 \t loss=0.1941 \t val_loss=0.0237 \t time=16.82s , lr=0.0000\n","Epoch 60/100 \t loss=0.1957 \t val_loss=0.0240 \t time=16.73s , lr=0.0000\n","Epoch 61/100 \t loss=0.2111 \t val_loss=0.0234 \t time=16.70s , lr=0.0000\n","Epoch 62/100 \t loss=0.1898 \t val_loss=0.0233 \t time=16.87s , lr=0.0000\n","Epoch 63/100 \t loss=0.1969 \t val_loss=0.0237 \t time=16.80s , lr=0.0000\n","Epoch 64/100 \t loss=0.1904 \t val_loss=0.0237 \t time=16.78s , lr=0.0000\n","Epoch 65/100 \t loss=0.1963 \t val_loss=0.0235 \t time=16.77s , lr=0.0000\n","Epoch 66/100 \t loss=0.1933 \t val_loss=0.0233 \t time=16.86s , lr=0.0000\n","Epoch 67/100 \t loss=0.1974 \t val_loss=0.0234 \t time=16.79s , lr=0.0000\n","Epoch 68/100 \t loss=0.1776 \t val_loss=0.0231 \t time=16.81s , lr=0.0000\n","Epoch 69/100 \t loss=0.1966 \t val_loss=0.0233 \t time=16.87s , lr=0.0000\n","Epoch 70/100 \t loss=0.1903 \t val_loss=0.0234 \t time=16.87s , lr=0.0000\n","Epoch 71/100 \t loss=0.2045 \t val_loss=0.0235 \t time=16.81s , lr=0.0000\n","Epoch 72/100 \t loss=0.2011 \t val_loss=0.0236 \t time=16.87s , lr=0.0000\n","Epoch 73/100 \t loss=0.1869 \t val_loss=0.0233 \t time=16.84s , lr=0.0000\n","Epoch 74/100 \t loss=0.1983 \t val_loss=0.0233 \t time=16.71s , lr=0.0000\n","Epoch 75/100 \t loss=0.1892 \t val_loss=0.0232 \t time=16.62s , lr=0.0000\n","Epoch 76/100 \t loss=0.2010 \t val_loss=0.0232 \t time=16.67s , lr=0.0000\n","Epoch 77/100 \t loss=0.1918 \t val_loss=0.0234 \t time=16.71s , lr=0.0000\n","Epoch 78/100 \t loss=0.2114 \t val_loss=0.0237 \t time=16.71s , lr=0.0000\n","Epoch 79/100 \t loss=0.1959 \t val_loss=0.0239 \t time=16.84s , lr=0.0000\n","Epoch 80/100 \t loss=0.1939 \t val_loss=0.0236 \t time=16.98s , lr=0.0000\n","Epoch 81/100 \t loss=0.1921 \t val_loss=0.0235 \t time=16.92s , lr=0.0000\n","Epoch 82/100 \t loss=0.1890 \t val_loss=0.0233 \t time=16.93s , lr=0.0000\n","Epoch 83/100 \t loss=0.1855 \t val_loss=0.0234 \t time=16.73s , lr=0.0000\n","Epoch 84/100 \t loss=0.1848 \t val_loss=0.0229 \t time=16.72s , lr=0.0000\n","Epoch 85/100 \t loss=0.2141 \t val_loss=0.0232 \t time=16.76s , lr=0.0000\n","Epoch 86/100 \t loss=0.1813 \t val_loss=0.0230 \t time=16.66s , lr=0.0000\n","Epoch 87/100 \t loss=0.1935 \t val_loss=0.0232 \t time=16.80s , lr=0.0000\n","Epoch 88/100 \t loss=0.1915 \t val_loss=0.0234 \t time=16.76s , lr=0.0000\n","Epoch 89/100 \t loss=0.1962 \t val_loss=0.0235 \t time=16.84s , lr=0.0000\n","Epoch 90/100 \t loss=0.1956 \t val_loss=0.0232 \t time=16.90s , lr=0.0000\n","Epoch 91/100 \t loss=0.1835 \t val_loss=0.0232 \t time=16.99s , lr=0.0000\n","Epoch 92/100 \t loss=0.2009 \t val_loss=0.0232 \t time=16.64s , lr=0.0000\n","Epoch 93/100 \t loss=0.1943 \t val_loss=0.0233 \t time=16.76s , lr=0.0000\n","Epoch 94/100 \t loss=0.1947 \t val_loss=0.0237 \t time=16.96s , lr=0.0000\n","Epoch 95/100 \t loss=0.1881 \t val_loss=0.0237 \t time=16.69s , lr=0.0000\n","Epoch 96/100 \t loss=0.1968 \t val_loss=0.0235 \t time=16.77s , lr=0.0000\n","Epoch 97/100 \t loss=0.2028 \t val_loss=0.0238 \t time=17.03s , lr=0.0000\n","Epoch 98/100 \t loss=0.1848 \t val_loss=0.0240 \t time=16.77s , lr=0.0000\n","Epoch 99/100 \t loss=0.2009 \t val_loss=0.0240 \t time=16.85s , lr=0.0000\n","Epoch 100/100 \t loss=0.1852 \t val_loss=0.0239 \t time=16.91s , lr=0.0000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zML7-wribUM1","colab_type":"text"},"source":["*Test* the final Results:\n"]},{"cell_type":"code","metadata":{"id":"nVTqTCmYcSlb","colab_type":"code","colab":{}},"source":["# Save the network parameters\n","torch.save(model.state_dict(), \"/content/drive/My Drive/model/efficientnet-b7_100_3fold.pt\") \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XZyM1crONQc_","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"J6Mq82xrVl3b","colab_type":"code","colab":{}},"source":["test_list = generateDatasetIDS(test_IDs.ID, content)\n","print(len(test_list))\n","test_custom = CustomListDataset(images_list = test_list, df_weights = weights, root_dir=content, transform = transform)\n","test_final_loader = torch.utils.data.DataLoader(test_custom, batch_size=64, shuffle=False, num_workers=2)\n","\n","print(len(test_final_loader))\n","print(len(test_final_loader.dataset))\n","\n","predicted_label = list()\n","real_label = list()\n","\n","#Set the network in eval mode\n","model.eval()\n","with torch.no_grad():\n","  # Loop over the dataset\n","  for batch_idx, (inputs, targets) in enumerate(test_final_loader):\n","    # Load data into GPU\n","    inputs = inputs.to(device)\n","    #print('inputs', inputs.shape)\n","\n","    targets = targets.to(device)\n","    #print('targets', targets.shape)\n","\n","    # Forward pass\n","    outputs = model.forward(inputs)\n","    \n","    #print('Out:',outputs.shape)\n","    \n","    arr1 = outputs.data.cpu().numpy()\n","    arr2 = targets.data.cpu().numpy()\n","\n","    predicted_label.extend(arr1)\n","    real_label.extend(arr2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzKmppbOVpsl","colab_type":"code","colab":{}},"source":["#print (predicted_label)\n","\n","import numpy as np\n","predicted_label = np.array(predicted_label,dtype=float)\n","real_label = np.array(real_label, dtype=int)\n","#print(predicted_label)\n","\n","pred_label_list = list()\n","for x in np.nditer(predicted_label):\n","  #print(x)\n","  pred_label_list.append(x)\n","\n","real_label_list = list()\n","for x in np.nditer(real_label):\n","  real_label_list.append(x)\n","\n","print(len(pred_label_list))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DSTeHo56Vvz7","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","\n","'''real_label, predicted_label'''\n","\n","print(type(real_label))\n","\n","df = pd.DataFrame({'REAL': np.asarray(real_label_list), 'PREDICTED':np.asarray(pred_label_list)})\n","df.plot('REAL', 'PREDICTED', kind='scatter')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9a53ncwAVyPA","colab_type":"code","colab":{}},"source":["#See unique real values \n","print(df.PREDICTED.unique())\n","\n","#Check the average value of the predicted labels\n","df.groupby('REAL').mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePLVTMv_V0VN","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","def r2_rmse( g ):\n","    r2 = r2_score( g.REAL, g.PREDICTED)\n","    count = len(g.REAL)\n","    mse = mean_squared_error( g['REAL'], g['PREDICTED'] ) \n","    rmse = np.sqrt( mean_squared_error( g['REAL'], g['PREDICTED'] ) ) \n","    return pd.Series( dict( count = int(count), r2 = r2, rmse = rmse, mse = mse ) )\n","\n","print(\"Global:\", r2_rmse(df))\n","\n","#Statistics over REAL value\n","df.groupby( 'REAL' ).apply( r2_rmse ).reset_index()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gcg6abORzxqU","colab_type":"code","colab":{}},"source":["#df.to_csv(r'./result-b0-DepthData.csv', index = False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zt4EUtT4HbVh","colab_type":"code","colab":{}},"source":["df.to_csv(file_test_labels, index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6Qdt9i93Byu","colab_type":"code","colab":{}},"source":["print(\"Script ended successfully. Stored results in .csv :)\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6GVqbQI1wMil","colab_type":"code","colab":{}},"source":["# Sleep for a few seconds.\n","import time\n","time.sleep(2)\n","\n","# Play an audio beep. Any audio URL will do.\n","from google.colab import output\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZX2n3iaq4-L8","colab_type":"text"},"source":["## Full Test 4 MARCO :D"]},{"cell_type":"code","metadata":{"id":"Ku7ilL_u4937","colab_type":"code","outputId":"0c25ade7-d8b9-490e-f599-00926970d0a6","executionInfo":{"status":"ok","timestamp":1590854181078,"user_tz":-120,"elapsed":15966,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","\n","\n","model = EfficientNet.from_pretrained(net_name)\n","model._fc = nn.Linear(2048, 1)\n","#print(model)\n","\n","def f(x):\n","    return abs(x[0] - x[1])\n","\n","device='cuda:0'\n","loss_fn = get_cost_function()\n","\n","def r2_rmse( g ):\n","    r2 = r2_score( g.REAL, g.PREDICTED)\n","    count = len(g.REAL)\n","    mse = mean_squared_error( g['REAL'], g['PREDICTED'] ) \n","    mae = mean_absolute_error(g['REAL'], g['PREDICTED'])\n","    rmse = np.sqrt( mean_squared_error( g['REAL'], g['PREDICTED'] ) ) \n","    return pd.Series( dict( mae = mae) )\n","\n","#print(\"Global:\", r2_rmse(df))\n","\n","#Statistics over REAL value\n","\n","test_list = generateDatasetIDS(test_IDs.ID, content)\n","print(len(test_list))\n","test_custom = CustomListDataset(images_list = test_list, df_weights = weights, root_dir=content, transform = transform)\n","test_final_loader = torch.utils.data.DataLoader(test_custom, batch_size=64, shuffle=False, num_workers=2)\n","\n","print(len(test_final_loader))\n","print(len(test_final_loader.dataset))\n","\n","for fold in range(1,4):\n","  print(fold)\n","  cumulative_val_loss = 0.0\n","  val_samples = 0\n","  model.load_state_dict(torch.load(\"/content/drive/My Drive/model/efficientnet-b5_100_fold\" + str(fold +1 ) + \".pt\"))\n","  model.to(device)\n","  predicted_label = list()\n","  real_label = list()\n","\n","  #Set the network in eval mode\n","  model.eval()\n","  with torch.no_grad():\n","    # Loop over the dataset\n","    for batch_idx, (inputs, targets) in enumerate(test_final_loader):\n","      # Load data into GPU\n","      inputs = inputs.to(device)\n","      #print('inputs', inputs.shape)\n","\n","      targets = targets.to(device)\n","      #print('targets', targets.shape)\n","\n","      # Forward pass\n","      outputs = model.forward(inputs)\n","\n","      cumulative_val_loss += loss_fn(targets, outputs).item()\n","      val_samples += inputs.shape[0]\n","        \n","      #print('Out:',outputs.shape)\n","      \n","      arr1 = outputs.data.cpu().numpy()\n","      arr2 = targets.data.cpu().numpy()\n","\n","      predicted_label.extend(arr1)\n","      real_label.extend(arr2)\n","    avg_val_loss = cumulative_val_loss / val_samples\n","\n","    print(\"Fold:\", fold , \"Loss:\", avg_val_loss)\n","\n","  predicted_label = np.array(predicted_label,dtype=float)\n","  real_label = np.array(real_label, dtype=int)\n","\n","  pred_label_list = list()\n","  for x in np.nditer(predicted_label):\n","    #print(x)\n","    pred_label_list.append(x)\n","\n","  real_label_list = list()\n","  for x in np.nditer(real_label):\n","    real_label_list.append(x)\n","\n","  df = pd.DataFrame({'REAL': np.asarray(real_label_list), 'PREDICTED':np.asarray(pred_label_list)})\n","  save_model_path = \"./drive/My Drive/risultati-datasets/\"\n","\n","  df.to_csv(save_model_path + 'segnet5_' + str(fold) + '.csv', index = False)\n","\n","  print(df)\n","  #df = df.apply(f, axis=1)\n","  #df1 = df.groupby('REAL').mean()\n","  df = df.groupby(\"REAL\").apply( r2_rmse ).reset_index()\n","\n","  #mae = df1['PREDICTED'].apply(f, axis=1)\n","  print(df)\n","  \n","  plt.errorbar(np.array(df.REAL), np.array(df.mae), yerr=0.1, fmt='.k') # TODO sostituire cl_mean_list e cp_mean_list con la lista dei pesi della gt e cp_list con la lista del peso predetto\n","  plt.xlabel(\"weight\")\n","  plt.ylabel(\"MAE\")\n","  plt.savefig(save_model_path + 'segnet5_' + str(fold) + '.pdf')\n","  plt.close()\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b5\n","200\n","4\n","200\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["Fold: 1 Loss: 0.4794729834794998\n","     REAL  PREDICTED\n","0      65  65.065117\n","1      65  64.981277\n","2      65  65.482986\n","3      65  65.206139\n","4      65  64.844376\n","..    ...        ...\n","195    93  93.302132\n","196    93  93.390938\n","197    93  94.190483\n","198    93  94.302887\n","199    93  94.163322\n","\n","[200 rows x 2 columns]\n","   REAL       mae\n","0    65  0.435849\n","1    67  2.506591\n","2    70  3.594572\n","3    73  0.623841\n","4    74  0.760006\n","5    75  7.090876\n","6    77  0.616977\n","7    78  0.650331\n","8    93  0.944695\n","2\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["Fold: 2 Loss: 0.30817866444587705\n","     REAL  PREDICTED\n","0      65  67.530533\n","1      65  69.447029\n","2      65  67.300964\n","3      65  67.219971\n","4      65  67.505821\n","..    ...        ...\n","195    93  91.484177\n","196    93  91.623894\n","197    93  93.639450\n","198    93  94.187347\n","199    93  93.068863\n","\n","[200 rows x 2 columns]\n","   REAL       mae\n","0    65  2.155658\n","1    67  0.678043\n","2    70  0.923128\n","3    73  0.800999\n","4    74  0.843082\n","5    75  1.310370\n","6    77  1.792678\n","7    78  0.835047\n","8    93  0.869568\n","3\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["Fold: 3 Loss: 0.3162054768204689\n","     REAL  PREDICTED\n","0      65  66.852455\n","1      65  68.732399\n","2      65  66.821434\n","3      65  66.683426\n","4      65  66.754608\n","..    ...        ...\n","195    93  92.558907\n","196    93  93.097862\n","197    93  94.451080\n","198    93  94.978111\n","199    93  93.826508\n","\n","[200 rows x 2 columns]\n","   REAL       mae\n","0    65  1.638692\n","1    67  0.825879\n","2    70  0.792054\n","3    73  0.721826\n","4    74  0.478555\n","5    75  1.481060\n","6    77  1.549024\n","7    78  0.610340\n","8    93  0.718420\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t8i33tIsSh-w","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}