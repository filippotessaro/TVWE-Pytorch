{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EfficientNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"P_FwoC8GviT1","colab_type":"text"},"source":["# WEIGHT ESTIMATION - TEST EFFICIENT NET Research Project"]},{"cell_type":"code","metadata":{"id":"ZxOZswaXv8Pl","colab_type":"code","outputId":"e2592273-d10a-4e39-bf0e-306de0cd2e49","executionInfo":{"status":"ok","timestamp":1586956443144,"user_tz":-120,"elapsed":4327,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":92,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qeD00JVfe22S","colab_type":"code","colab":{}},"source":["# import libraries\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import numpy as np\n","from torchvision import datasets\n","from skimage import io, transform\n","from torch.utils.data import DataLoader\n","import time\n","import os\n","from PIL import Image\n","from torchvision import transforms\n","import logging\n","from datetime import datetime\n","import copy\n","import time\n","from sklearn.model_selection import KFold\n","from tqdm import tqdm\n","import random\n","import os\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUa0-vIv7oET","colab_type":"code","outputId":"9fcc6d9d-a0df-4c79-d2e9-5f0ef3c58316","executionInfo":{"status":"ok","timestamp":1586956443145,"user_tz":-120,"elapsed":4311,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Get the seconds since epoch\n","secondsSinceEpoch = time.time()\n","# Convert seconds since epoch to struct_time\n","timeObj = time.localtime(secondsSinceEpoch)\n","\n","time = str(timeObj.tm_mday)+ '-' + str(timeObj.tm_mon) +'-'+ str(timeObj.tm_year)+'-'+str(timeObj.tm_hour)+'_'+str(timeObj.tm_min)\n","print(time)"],"execution_count":94,"outputs":[{"output_type":"stream","text":["15-4-2020-13_14\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nfO7vaDhwEPk","colab_type":"code","outputId":"a7f39947-6017-465d-fe03-d252c5842b9f","executionInfo":{"status":"ok","timestamp":1586956443145,"user_tz":-120,"elapsed":4301,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Path of Folders\n","content = '/content/drive/My Drive/new-frames/'\n","labels_csv = '/content/drive/My Drive/weights.csv'\n","train_path = content + \"train\"\n","test_path = content + \"test\"\n","validation_path = content + \"validation\"\n","\n","weights=pd.read_csv(labels_csv)\n","weights = weights['WEIGHT'].values\n","\n","print('Start initialization logging file')\n","logging.basicConfig(filename='app_' + time + '.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s')\n","logging.warning('Initialized File')\n","\n","# Instantiate visualizer\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# default `log_dir` is \"runs\" - we'll be more specific here\n","writer = SummaryWriter('runs/Efficient-Net')"],"execution_count":95,"outputs":[{"output_type":"stream","text":["Start initialization logging file\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nbGPbiyrzChA","colab_type":"text"},"source":["## Efficient Net\n"]},{"cell_type":"code","metadata":{"id":"Gfzu6JmWRnAl","colab_type":"code","colab":{}},"source":["# Source: https://github.com/lukemelas/EfficientNet-PyTorch\n","# Version: 0.4.0\n","\"\"\"\n","This file contains helper functions for building the model and for loading model parameters.\n","These helper functions are built to mirror those in the official TensorFlow implementation.\n","\"\"\"\n","\n","import re\n","import math\n","import collections\n","from functools import partial\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils import model_zoo\n","\n","\n","########################################################################\n","############### HELPERS FUNCTIONS FOR MODEL ARCHITECTURE ###############\n","########################################################################\n","\n","\n","# Parameters for the entire model (stem, all blocks, and head)\n","GlobalParams = collections.namedtuple('GlobalParams', [\n","    'batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate',\n","    'num_classes', 'width_coefficient', 'depth_coefficient',\n","    'depth_divisor', 'min_depth', 'drop_connect_rate', 'image_size'])\n","\n","\n","# Parameters for an individual model block\n","BlockArgs = collections.namedtuple('BlockArgs', [\n","    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n","    'expand_ratio', 'id_skip', 'stride', 'se_ratio'])\n","\n","\n","# Change namedtuple defaults\n","GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n","BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n","\n","\n","def relu_fn(x):\n","    \"\"\" Swish activation function \"\"\"\n","    return x * torch.sigmoid(x)\n","\n","\n","def round_filters(filters, global_params):\n","    \"\"\" Calculate and round number of filters based on depth multiplier. \"\"\"\n","    multiplier = global_params.width_coefficient\n","    if not multiplier:\n","        return filters\n","    divisor = global_params.depth_divisor\n","    min_depth = global_params.min_depth\n","    filters *= multiplier\n","    min_depth = min_depth or divisor\n","    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n","    if new_filters < 0.9 * filters:  # prevent rounding by more than 10%\n","        new_filters += divisor\n","    return int(new_filters)\n","\n","\n","def round_repeats(repeats, global_params):\n","    \"\"\" Round number of filters based on depth multiplier. \"\"\"\n","    multiplier = global_params.depth_coefficient\n","    if not multiplier:\n","        return repeats\n","    return int(math.ceil(multiplier * repeats))\n","\n","\n","def drop_connect(inputs, p, training):\n","    \"\"\" Drop connect. \"\"\"\n","    if not training: return inputs\n","    batch_size = inputs.shape[0]\n","    keep_prob = 1 - p\n","    random_tensor = keep_prob\n","    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype, device=inputs.device)\n","    binary_tensor = torch.floor(random_tensor)\n","    output = inputs / keep_prob * binary_tensor\n","    return output\n","\n","\n","def get_same_padding_conv2d(image_size=None):\n","    \"\"\" Chooses static padding if you have specified an image size, and dynamic padding otherwise.\n","        Static padding is necessary for ONNX exporting of models. \"\"\"\n","    if image_size is None:\n","        return Conv2dDynamicSamePadding\n","    else:\n","        return partial(Conv2dStaticSamePadding, image_size=image_size)\n","\n","class Conv2dDynamicSamePadding(nn.Conv2d):\n","    \"\"\" 2D Convolutions like TensorFlow, for a dynamic image size \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n","        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n","        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]]*2\n","\n","    def forward(self, x):\n","        ih, iw = x.size()[-2:]\n","        kh, kw = self.weight.size()[-2:]\n","        sh, sw = self.stride\n","        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n","        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n","        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n","        if pad_h > 0 or pad_w > 0:\n","            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n","        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n","\n","\n","class Conv2dStaticSamePadding(nn.Conv2d):\n","    \"\"\" 2D Convolutions like TensorFlow, for a fixed image size\"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, image_size=None, **kwargs):\n","        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n","        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n","\n","        # Calculate padding based on image size and save it\n","        assert image_size is not None\n","        ih, iw = image_size if type(image_size) == list else [image_size, image_size]\n","        kh, kw = self.weight.size()[-2:]\n","        sh, sw = self.stride\n","        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n","        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n","        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n","        if pad_h > 0 or pad_w > 0:\n","            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))\n","        else:\n","            self.static_padding = Identity()\n","\n","    def forward(self, x):\n","        x = self.static_padding(x)\n","        x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n","        return x\n","\n","\n","class Identity(nn.Module):\n","    def __init__(self,):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, input):\n","        return input\n","\n","\n","########################################################################\n","############## HELPERS FUNCTIONS FOR LOADING MODEL PARAMS ##############\n","########################################################################\n","\n","\n","def efficientnet_params(model_name):\n","    \"\"\" Map EfficientNet model name to parameter coefficients. \"\"\"\n","    params_dict = {\n","        # Coefficients:   width,depth,res,dropout\n","        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n","        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n","        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n","        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n","        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n","        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n","        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n","        'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n","    }\n","    return params_dict[model_name]\n","\n","\n","class BlockDecoder(object):\n","    \"\"\" Block Decoder for readability, straight from the official TensorFlow repository \"\"\"\n","\n","    @staticmethod\n","    def _decode_block_string(block_string):\n","        \"\"\" Gets a block through a string notation of arguments. \"\"\"\n","        assert isinstance(block_string, str)\n","\n","        ops = block_string.split('_')\n","        options = {}\n","        for op in ops:\n","            splits = re.split(r'(\\d.*)', op)\n","            if len(splits) >= 2:\n","                key, value = splits[:2]\n","                options[key] = value\n","\n","        # Check stride\n","        assert (('s' in options and len(options['s']) == 1) or\n","                (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\n","\n","        return BlockArgs(\n","            kernel_size=int(options['k']),\n","            num_repeat=int(options['r']),\n","            input_filters=int(options['i']),\n","            output_filters=int(options['o']),\n","            expand_ratio=int(options['e']),\n","            id_skip=('noskip' not in block_string),\n","            se_ratio=float(options['se']) if 'se' in options else None,\n","            stride=[int(options['s'][0])])\n","\n","    @staticmethod\n","    def _encode_block_string(block):\n","        \"\"\"Encodes a block to a string.\"\"\"\n","        args = [\n","            'r%d' % block.num_repeat,\n","            'k%d' % block.kernel_size,\n","            's%d%d' % (block.strides[0], block.strides[1]),\n","            'e%s' % block.expand_ratio,\n","            'i%d' % block.input_filters,\n","            'o%d' % block.output_filters\n","        ]\n","        if 0 < block.se_ratio <= 1:\n","            args.append('se%s' % block.se_ratio)\n","        if block.id_skip is False:\n","            args.append('noskip')\n","        return '_'.join(args)\n","\n","    @staticmethod\n","    def decode(string_list):\n","        \"\"\"\n","        Decodes a list of string notations to specify blocks inside the network.\n","\n","        :param string_list: a list of strings, each string is a notation of block\n","        :return: a list of BlockArgs namedtuples of block args\n","        \"\"\"\n","        assert isinstance(string_list, list)\n","        blocks_args = []\n","        for block_string in string_list:\n","            blocks_args.append(BlockDecoder._decode_block_string(block_string))\n","        return blocks_args\n","\n","    @staticmethod\n","    def encode(blocks_args):\n","        \"\"\"\n","        Encodes a list of BlockArgs to a list of strings.\n","\n","        :param blocks_args: a list of BlockArgs namedtuples of block args\n","        :return: a list of strings, each string is a notation of block\n","        \"\"\"\n","        block_strings = []\n","        for block in blocks_args:\n","            block_strings.append(BlockDecoder._encode_block_string(block))\n","        return block_strings\n","\n","\n","def efficientnet(width_coefficient=None, depth_coefficient=None, dropout_rate=0.2,\n","                 drop_connect_rate=0.2, image_size=None, num_classes=1000):\n","    \"\"\" Creates a efficientnet model. \"\"\"\n","\n","    blocks_args = [\n","        'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n","        'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n","        'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n","        'r1_k3_s11_e6_i192_o320_se0.25',\n","    ]\n","    blocks_args = BlockDecoder.decode(blocks_args)\n","\n","    global_params = GlobalParams(\n","        batch_norm_momentum=0.99,\n","        batch_norm_epsilon=1e-3,\n","        dropout_rate=dropout_rate,\n","        drop_connect_rate=drop_connect_rate,\n","        # data_format='channels_last',  # removed, this is always true in PyTorch\n","        num_classes=num_classes,\n","        width_coefficient=width_coefficient,\n","        depth_coefficient=depth_coefficient,\n","        depth_divisor=8,\n","        min_depth=None,\n","        image_size=image_size,\n","    )\n","\n","    return blocks_args, global_params\n","\n","\n","def get_model_params(model_name, override_params):\n","    \"\"\" Get the block args and global params for a given model \"\"\"\n","    if model_name.startswith('efficientnet'):\n","        w, d, s, p = efficientnet_params(model_name)\n","        # note: all models have drop connect rate = 0.2\n","        blocks_args, global_params = efficientnet(\n","            width_coefficient=w, depth_coefficient=d, dropout_rate=p, image_size=s)\n","    else:\n","        raise NotImplementedError('model name is not pre-defined: %s' % model_name)\n","    if override_params:\n","        # ValueError will be raised here if override_params has fields not included in global_params.\n","        global_params = global_params._replace(**override_params)\n","    return blocks_args, global_params\n","\n","\n","# url_map = {\n","#     'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b0-355c32eb.pth',\n","#     'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b1-f1951068.pth',\n","#     'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b2-8bb594d6.pth',\n","#     'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth',\n","#     'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b4-6ed6700e.pth',\n","#     'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b5-b6417697.pth',\n","#     'efficientnet-b6': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b6-c76e70fd.pth',\n","#     'efficientnet-b7': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b7-dcc49843.pth',\n","# }\n","\n","url_map = {\n","    'efficientnet-b0': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth',\n","    'efficientnet-b1': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth',\n","    'efficientnet-b2': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth',\n","    'efficientnet-b3': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth',\n","    'efficientnet-b4': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth',\n","    'efficientnet-b5': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth',\n","    'efficientnet-b6': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b6-c76e70fd.pth',\n","    'efficientnet-b7': 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth',\n","}\n","\n","def load_pretrained_weights(model, model_name, load_fc=True):\n","    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n","    state_dict = model_zoo.load_url(url_map[model_name])\n","    if load_fc:\n","        model.load_state_dict(state_dict)\n","    else:\n","        state_dict.pop('_fc.weight')\n","        state_dict.pop('_fc.bias')\n","        res = model.load_state_dict(state_dict, strict=False)\n","        assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n","    print('Loaded pretrained weights for {}'.format(model_name))\n","\n","class MBConvBlock(nn.Module):\n","    \"\"\"\n","    Mobile Inverted Residual Bottleneck Block\n","\n","    Args:\n","        block_args (namedtuple): BlockArgs, see above\n","        global_params (namedtuple): GlobalParam, see above\n","\n","    Attributes:\n","        has_se (bool): Whether the block contains a Squeeze and Excitation layer.\n","    \"\"\"\n","\n","    def __init__(self, block_args, global_params):\n","        super().__init__()\n","        self._block_args = block_args\n","        self._bn_mom = 1 - global_params.batch_norm_momentum\n","        self._bn_eps = global_params.batch_norm_epsilon\n","        self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)\n","        self.id_skip = block_args.id_skip  # skip connection and drop connect\n","\n","        # Get static or dynamic convolution depending on image size\n","        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n","\n","        # Expansion phase\n","        inp = self._block_args.input_filters  # number of input channels\n","        oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels\n","        if self._block_args.expand_ratio != 1:\n","            self._expand_conv = Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n","            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n","\n","        # Depthwise convolution phase\n","        k = self._block_args.kernel_size\n","        s = self._block_args.stride\n","        self._depthwise_conv = Conv2d(\n","            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise\n","            kernel_size=k, stride=s, bias=False)\n","        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n","\n","        # Squeeze and Excitation layer, if desired\n","        if self.has_se:\n","            num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))\n","            self._se_reduce = Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n","            self._se_expand = Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n","\n","        # Output phase\n","        final_oup = self._block_args.output_filters\n","        self._project_conv = Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n","        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n","\n","    def forward(self, inputs, drop_connect_rate=None):\n","        \"\"\"\n","        :param inputs: input tensor\n","        :param drop_connect_rate: drop connect rate (float, between 0 and 1)\n","        :return: output of block\n","        \"\"\"\n","\n","        # Expansion and Depthwise Convolution\n","        x = inputs\n","        if self._block_args.expand_ratio != 1:\n","            x = relu_fn(self._bn0(self._expand_conv(inputs)))\n","        x = relu_fn(self._bn1(self._depthwise_conv(x)))\n","\n","        # Squeeze and Excitation\n","        if self.has_se:\n","            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n","            x_squeezed = self._se_expand(relu_fn(self._se_reduce(x_squeezed)))\n","            x = torch.sigmoid(x_squeezed) * x\n","\n","        x = self._bn2(self._project_conv(x))\n","\n","        # Skip connection and drop connect\n","        input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\n","        if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n","            if drop_connect_rate:\n","                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n","            x = x + inputs  # skip connection\n","        return x\n","\n","\n","class EfficientNet(nn.Module):\n","    \"\"\"\n","    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n","\n","    Args:\n","        blocks_args (list): A list of BlockArgs to construct blocks\n","        global_params (namedtuple): A set of GlobalParams shared between blocks\n","\n","    Example:\n","        model = EfficientNet.from_pretrained('efficientnet-b0')\n","\n","    \"\"\"\n","\n","    def __init__(self, blocks_args=None, global_params=None):\n","        super().__init__()\n","        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n","        assert len(blocks_args) > 0, 'block args must be greater than 0'\n","        self._global_params = global_params\n","        self._blocks_args = blocks_args\n","\n","        # Get static or dynamic convolution depending on image size\n","        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n","\n","        # Batch norm parameters\n","        bn_mom = 1 - self._global_params.batch_norm_momentum\n","        bn_eps = self._global_params.batch_norm_epsilon\n","\n","        # Stem\n","        in_channels = 3  # rgb\n","        out_channels = round_filters(32, self._global_params)  # number of output channels\n","        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n","        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n","\n","        # Build blocks\n","        self._blocks = nn.ModuleList([])\n","        for block_args in self._blocks_args:\n","\n","            # Update block input and output filters based on depth multiplier.\n","            block_args = block_args._replace(\n","                input_filters=round_filters(block_args.input_filters, self._global_params),\n","                output_filters=round_filters(block_args.output_filters, self._global_params),\n","                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n","            )\n","\n","            # The first block needs to take care of stride and filter size increase.\n","            self._blocks.append(MBConvBlock(block_args, self._global_params))\n","            if block_args.num_repeat > 1:\n","                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n","            for _ in range(block_args.num_repeat - 1):\n","                self._blocks.append(MBConvBlock(block_args, self._global_params))\n","\n","        # Head\n","        in_channels = block_args.output_filters  # output of final block\n","        out_channels = round_filters(1280, self._global_params)\n","        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n","        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n","\n","        # Final linear layer\n","        self._dropout = self._global_params.dropout_rate\n","        self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n","\n","    def extract_features(self, inputs):\n","        \"\"\" Returns output of the final convolution layer \"\"\"\n","\n","        # Stem\n","        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n","\n","        # Blocks\n","        for idx, block in enumerate(self._blocks):\n","            drop_connect_rate = self._global_params.drop_connect_rate\n","            if drop_connect_rate:\n","                drop_connect_rate *= float(idx) / len(self._blocks)\n","            x = block(x, drop_connect_rate=drop_connect_rate)\n","\n","        # Head\n","        x = relu_fn(self._bn1(self._conv_head(x)))\n","\n","        return x\n","\n","    def forward(self, inputs):\n","        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n","\n","        # Convolution layers\n","        x = self.extract_features(inputs)\n","\n","        # Pooling and final linear layer\n","        x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n","        if self._dropout:\n","            x = F.dropout(x, p=self._dropout, training=self.training)\n","        x = self._fc(x)\n","        return x\n","\n","    @classmethod\n","    def from_name(cls, model_name, override_params=None):\n","        cls._check_model_name_is_valid(model_name)\n","        blocks_args, global_params = get_model_params(model_name, override_params)\n","        return EfficientNet(blocks_args, global_params)\n","\n","    @classmethod\n","    def from_pretrained(cls, model_name, num_classes=1000):\n","        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n","        load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000))\n","        return model\n","\n","    @classmethod\n","    def get_image_size(cls, model_name):\n","        cls._check_model_name_is_valid(model_name)\n","        _, _, res, _ = efficientnet_params(model_name)\n","        return res\n","\n","    @classmethod\n","    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n","        \"\"\" Validates model name. None that pretrained weights are only available for\n","        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n","        num_models = 4 if also_need_pretrained_weights else 8\n","        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n","        if model_name.replace('-','_') not in valid_models:\n","            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MAx0lsewycv1","colab_type":"text"},"source":["## Optimizer and Cost Function\n","Declaration of the optimizer and of the cost function."]},{"cell_type":"code","metadata":{"id":"31jAoGYg3hjK","colab_type":"code","colab":{}},"source":["def get_optimizer(net, lr):\n","  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","  return optimizer\n","\n","def get_cost_function():\n","  cost_function = torch.nn.MSELoss()\n","  return cost_function"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y4ksS3d6_GS9","colab_type":"text"},"source":["## New KFold Cross Validation\n","This is an improvement of the section before since this one creates dinamically the minibatch for the computatation of a single fold\n"]},{"cell_type":"code","metadata":{"id":"GBnEJt1XDwCx","colab_type":"code","outputId":"db2960d1-fcd5-456a-c915-0035b6389baa","executionInfo":{"status":"ok","timestamp":1586956444210,"user_tz":-120,"elapsed":5344,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["weights=pd.read_csv(labels_csv)\n","train_IDs, test_IDs = train_test_split(weights, test_size=0.1, random_state=42)\n","\n","# Check len of IDs\n","print('Train:', len(train_IDs))\n","print('Test:', len(test_IDs))"],"execution_count":98,"outputs":[{"output_type":"stream","text":["Train: 92\n","Test: 11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"icvCSDSHDLUl","colab_type":"code","colab":{}},"source":["def generateDatasetIDS(list, root_folder = \"/content/drive/My Drive/frames/\"):\n","  \"\"\"\n","  Return a list with all the image paths relative to those IDs\n","  \"\"\"\n","  test_list = []\n","  for id in list:\n","    #print(\"Id:\", id)\n","    for root, dirs, files in os.walk(root_folder + str(id) ):\n","        for filename in files:\n","            #print(\"\\t\", str(id) + \"/\" + filename)\n","            if('.png' in filename):\n","              add_file = str(id) + \"/\" + filename\n","              test_list.append(add_file)\n","  return test_list\n","\n","class CustomListDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, images_list, df_weights, root_dir,transform = None):\n","        \"\"\"\n","        Args:\n","            images_list(list): list with IDs into the dataset\n","            root_dir(string): directory with all the images\n","            df_weights(pd_dataframe): dataframe with all the weights of the people\n","            transform: trasform operation for images\n","        \"\"\"\n","        self.images_list = images_list\n","        self.root_dir = root_dir\n","        self.df_weights = df_weights\n","        self.df_weights = self.df_weights['WEIGHT'].values\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images_list)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.root_dir, self.images_list[idx])\n","        image = Image.open(img_name)\n","        image = image.convert(mode='RGB')\n","        if(self.transform is not None):\n","            image = self.transform(image)\n","        frame_name = self.images_list[idx].split(\"/\")\n","        id = int(frame_name[0]) \n","        labels = self.df_weights[id]\n","        labels = np.float(labels)\n","        return image, torch.as_tensor(labels)\n","\n","transform = transforms.Compose([\n","    # you can add other transformations in this list\n","    #transforms.Resize((299,299), interpolation=2),\n","    #transforms.RandomHorizontalFlip(),\n","    #transforms.RandomRotation(20),\n","    transforms.ToTensor()\n","])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUul2Fts-U2W","colab_type":"code","colab":{}},"source":["# save checkpoint function\n","def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n","    torch.save(state, filename)\n","    if is_best:\n","        shutil.copyfile(filename, filename + \"best\")\n","\n","def adjust_learning_rate(optimizer, epoch, learning_rate):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 100 epochs\"\"\"\n","    lr = learning_rate * (0.1 ** (epoch // 50))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","    return lr\n","\n","def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UgrUvQGv_Xew","colab_type":"code","outputId":"7436b66f-12f7-40ad-f30a-d601a458c16e","executionInfo":{"status":"ok","timestamp":1586962288286,"user_tz":-120,"elapsed":4036428,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import time\n","seed_torch(11)\n","device='cuda:0'\n","learning_rate = 0.01\n","momentum_ = 0.9\n","weight_decay = 1e-4\n","\n","num_epochs = 100\n","splits = 3\n","batch_size = 32\n","\n","model = EfficientNet.from_pretrained('efficientnet-b5')\n","model._fc = nn.Linear(2048, 1)\n","print(model)\n","\n","\n","optimizer = get_optimizer(model, learning_rate)\n","# optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n","#                                 momentum=momentum_,\n","#                                 weight_decay=weight_decay)\n","\n","loss_fn = get_cost_function()\n","\n","kf = KFold(n_splits=splits, shuffle=True)\n","fold = 1\n","\n","# best accuracy to be stored\n","best_acc1 = 0\n","\n","\"\"\"# Add values to plots\n","tb.save_value('Loss/train_loss', visualization_name, 0, train_loss)\n","tb.save_value('Loss/test_loss', visualization_name, 0, test_loss)\n","\n","# Update plots \n","tb.flush_line(visualization_name)\n","\"\"\"\n","global_epoch = 0\n","\n","for train_index, test_index in kf.split(train_IDs):\n","  #print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n","  model.cuda()\n","  train_images_list = generateDatasetIDS(train_index,\"/content/drive/My Drive/frames/\")\n","  train = CustomListDataset(images_list = train_images_list, df_weights = weights, root_dir=\"/content/drive/My Drive/frames/\", transform = transform)\n","  trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\n","\n","  test_images_list = generateDatasetIDS(test_index,\"/content/drive/My Drive/frames/\")\n","  test = CustomListDataset(images_list = test_images_list, df_weights = weights, root_dir=\"/content/drive/My Drive/frames/\", transform = transform)\n","  validationloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n","\n","  print(f'Len Train (in batch): {len(trainloader)}')\n","  print(f'Len validation (in batch): {len(validationloader)}')\n","\n","  print(f'Fold {fold}')\n","  fold += 1\n","  \n","  for epoch in range(num_epochs):\n","      start_time = time.time()\n","      \n","      # adjust learning rate\n","      curr_learnig = adjust_learning_rate(optimizer, global_epoch, learning_rate)\n","      global_epoch += 1\n","\n","      model.train()\n","      avg_loss = 0.\n","      cumulative_loss = 0.\n","      samples = 0\n","      for i, (x_batch, y_batch) in enumerate(trainloader):\n","          x_batch = x_batch.to(device)\n","          y_batch = y_batch.to(device)\n","          y_batch = y_batch.view(-1,1)\n","          y_pred = model(x_batch)\n","          loss = loss_fn(y_pred, y_batch)\n","          \n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          \n","          samples+=x_batch.shape[0]\n","          cumulative_loss += loss.item()\n","      avg_loss = cumulative_loss / samples\n","      \n","      model.eval()\n","      avg_val_loss = 0.\n","      cumulative_val_loss = 0.\n","      val_samples = 0\n","      with torch.no_grad():\n","        for i, (x_batch, y_batch) in enumerate(validationloader):\n","            x_batch = x_batch.to(device)\n","            y_batch = y_batch.to(device)\n","            y_batch = y_batch.view(-1,1)\n","            y_pred = model(x_batch)\n","            cumulative_val_loss += loss_fn(y_pred, y_batch).item()\n","            val_samples += x_batch.shape[0]\n","        avg_val_loss = cumulative_val_loss / val_samples\n","          #valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n","\n","      elapsed_time = time.time() - start_time \n","\n","      writer.add_scalar('training loss',\n","                            avg_loss,\n","                            global_epoch)\n","      \n","      writer.add_scalar('validation loss',\n","                            avg_val_loss,\n","                            global_epoch)\n","\n","      acc1 = avg_val_loss\n","\n","      # remember best acc@1 and save checkpoint\n","      is_best = acc1 > best_acc1\n","      best_acc1 = max(acc1, best_acc1)\n","\n","      print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s , lr={:.4f}'.format(\n","          epoch + 1, num_epochs, avg_loss, avg_val_loss, elapsed_time, curr_learnig))\n","      \n","      # save every 20 epoches\n","      # if epoch%20:\n","      #   save_checkpoint({\n","      #       'epoch': epoch + 1,\n","      #       'fold': fold,\n","      #       'state_dict': model.state_dict(),\n","      #       'best_acc1': best_acc1,\n","      #       'optimizer' : optimizer.state_dict(),\n","      #   }, is_best, \"/content/drive/My Drive/model/effic_lr01_200epoch-fold\" + str(fold) + \"epochnum\" + str(epoch+1)+ \".pth.tar\")\n","  "],"execution_count":101,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b5\n","EfficientNet(\n","  (_conv_stem): Conv2dStaticSamePadding(\n","    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n","    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n","  )\n","  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_blocks): ModuleList(\n","    (0): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        48, 12, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        12, 48, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (1): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        24, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 24, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (2): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        24, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 24, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (3): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n","        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        144, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 144, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (4): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (5): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (6): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (7): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (8): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (9): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (10): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (11): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (12): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (13): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        384, 384, kernel_size=(3, 3), stride=[2, 2], groups=384, bias=False\n","        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        384, 16, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        16, 384, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (14): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (15): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (16): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (17): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (18): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (19): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (20): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        768, 768, kernel_size=(5, 5), stride=[1, 1], groups=768, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        768, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        32, 768, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (21): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (22): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (23): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (24): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (25): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (26): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (27): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1056, 1056, kernel_size=(5, 5), stride=[2, 2], groups=1056, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (28): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (29): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (30): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (31): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (32): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (33): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (34): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (35): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (36): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1824, 1824, kernel_size=(3, 3), stride=[1, 1], groups=1824, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (37): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","    (38): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n","        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n","      )\n","      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (_conv_head): Conv2dStaticSamePadding(\n","    512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","    (static_padding): Identity()\n","  )\n","  (_bn1): BatchNorm2d(2048, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_fc): Linear(in_features=2048, out_features=1, bias=True)\n",")\n","Len Train (in batch): 54\n","Len validation (in batch): 32\n","Fold 1\n","Epoch 1/100 \t loss=27.1491 \t val_loss=751276921129637.2500 \t time=18.86s , lr=0.0100\n","Epoch 2/100 \t loss=3.2718 \t val_loss=8183811.4851 \t time=18.63s , lr=0.0100\n","Epoch 3/100 \t loss=2.3305 \t val_loss=252.2199 \t time=18.78s , lr=0.0100\n","Epoch 4/100 \t loss=1.7280 \t val_loss=111.4247 \t time=18.72s , lr=0.0100\n","Epoch 5/100 \t loss=1.4935 \t val_loss=37.3246 \t time=18.72s , lr=0.0100\n","Epoch 6/100 \t loss=1.0400 \t val_loss=45.4943 \t time=18.80s , lr=0.0100\n","Epoch 7/100 \t loss=0.8027 \t val_loss=35.9992 \t time=18.73s , lr=0.0100\n","Epoch 8/100 \t loss=0.7800 \t val_loss=22.5067 \t time=18.70s , lr=0.0100\n","Epoch 9/100 \t loss=0.7481 \t val_loss=19.0422 \t time=18.85s , lr=0.0100\n","Epoch 10/100 \t loss=0.5743 \t val_loss=11.4342 \t time=18.66s , lr=0.0100\n","Epoch 11/100 \t loss=0.4086 \t val_loss=9.1190 \t time=18.69s , lr=0.0100\n","Epoch 12/100 \t loss=0.4979 \t val_loss=13.1276 \t time=18.79s , lr=0.0100\n","Epoch 13/100 \t loss=0.6095 \t val_loss=14.7186 \t time=18.76s , lr=0.0100\n","Epoch 14/100 \t loss=0.4894 \t val_loss=16.3874 \t time=18.75s , lr=0.0100\n","Epoch 15/100 \t loss=0.5218 \t val_loss=12.3737 \t time=18.77s , lr=0.0100\n","Epoch 16/100 \t loss=0.4932 \t val_loss=7.9363 \t time=18.73s , lr=0.0100\n","Epoch 17/100 \t loss=0.5364 \t val_loss=11.9905 \t time=18.78s , lr=0.0100\n","Epoch 18/100 \t loss=0.3542 \t val_loss=7.0250 \t time=18.74s , lr=0.0100\n","Epoch 19/100 \t loss=0.4960 \t val_loss=8.6053 \t time=18.85s , lr=0.0100\n","Epoch 20/100 \t loss=0.3479 \t val_loss=17.3581 \t time=18.76s , lr=0.0100\n","Epoch 21/100 \t loss=0.3321 \t val_loss=8.4484 \t time=18.79s , lr=0.0100\n","Epoch 22/100 \t loss=0.3201 \t val_loss=9.4582 \t time=18.77s , lr=0.0100\n","Epoch 23/100 \t loss=0.3586 \t val_loss=6.8617 \t time=18.74s , lr=0.0100\n","Epoch 24/100 \t loss=0.3784 \t val_loss=7.2137 \t time=18.80s , lr=0.0100\n","Epoch 25/100 \t loss=0.3384 \t val_loss=7.5046 \t time=18.92s , lr=0.0100\n","Epoch 26/100 \t loss=0.2707 \t val_loss=13.4282 \t time=18.87s , lr=0.0100\n","Epoch 27/100 \t loss=0.3167 \t val_loss=8.9906 \t time=18.83s , lr=0.0100\n","Epoch 28/100 \t loss=0.2598 \t val_loss=12.5349 \t time=18.75s , lr=0.0100\n","Epoch 29/100 \t loss=0.2962 \t val_loss=9.5543 \t time=18.83s , lr=0.0100\n","Epoch 30/100 \t loss=0.2591 \t val_loss=7.4011 \t time=18.84s , lr=0.0100\n","Epoch 31/100 \t loss=0.2394 \t val_loss=8.0060 \t time=18.75s , lr=0.0100\n","Epoch 32/100 \t loss=0.2493 \t val_loss=9.6793 \t time=18.77s , lr=0.0100\n","Epoch 33/100 \t loss=0.2282 \t val_loss=7.3572 \t time=18.74s , lr=0.0100\n","Epoch 34/100 \t loss=0.2253 \t val_loss=10.0362 \t time=18.78s , lr=0.0100\n","Epoch 35/100 \t loss=0.1802 \t val_loss=6.3735 \t time=18.78s , lr=0.0100\n","Epoch 36/100 \t loss=0.2239 \t val_loss=4.9018 \t time=18.70s , lr=0.0100\n","Epoch 37/100 \t loss=0.2475 \t val_loss=9.3246 \t time=18.76s , lr=0.0100\n","Epoch 38/100 \t loss=0.2650 \t val_loss=6.2379 \t time=18.83s , lr=0.0100\n","Epoch 39/100 \t loss=0.2620 \t val_loss=10.3380 \t time=18.80s , lr=0.0100\n","Epoch 40/100 \t loss=0.2868 \t val_loss=9.3599 \t time=18.75s , lr=0.0100\n","Epoch 41/100 \t loss=0.2912 \t val_loss=7.3557 \t time=18.79s , lr=0.0100\n","Epoch 42/100 \t loss=0.2727 \t val_loss=6.8998 \t time=18.79s , lr=0.0100\n","Epoch 43/100 \t loss=0.2390 \t val_loss=8.1112 \t time=18.84s , lr=0.0100\n","Epoch 44/100 \t loss=0.3355 \t val_loss=10.1614 \t time=18.80s , lr=0.0100\n","Epoch 45/100 \t loss=0.2177 \t val_loss=10.4419 \t time=18.80s , lr=0.0100\n","Epoch 46/100 \t loss=0.2298 \t val_loss=11.7459 \t time=18.76s , lr=0.0100\n","Epoch 47/100 \t loss=1.0698 \t val_loss=19.3369 \t time=18.75s , lr=0.0100\n","Epoch 48/100 \t loss=1.0059 \t val_loss=11.8629 \t time=18.80s , lr=0.0100\n","Epoch 49/100 \t loss=0.5662 \t val_loss=17.5528 \t time=18.76s , lr=0.0100\n","Epoch 50/100 \t loss=0.4295 \t val_loss=20.8623 \t time=18.78s , lr=0.0100\n","Epoch 51/100 \t loss=0.2253 \t val_loss=11.1645 \t time=18.76s , lr=0.0012\n","Epoch 52/100 \t loss=0.1778 \t val_loss=7.7277 \t time=18.75s , lr=0.0012\n","Epoch 53/100 \t loss=0.1585 \t val_loss=6.9330 \t time=18.66s , lr=0.0012\n","Epoch 54/100 \t loss=0.1406 \t val_loss=6.5298 \t time=18.71s , lr=0.0012\n","Epoch 55/100 \t loss=0.1448 \t val_loss=6.0440 \t time=18.82s , lr=0.0012\n","Epoch 56/100 \t loss=0.1411 \t val_loss=6.1377 \t time=18.68s , lr=0.0012\n","Epoch 57/100 \t loss=0.1371 \t val_loss=6.1559 \t time=18.70s , lr=0.0012\n","Epoch 58/100 \t loss=0.1210 \t val_loss=6.0272 \t time=18.73s , lr=0.0012\n","Epoch 59/100 \t loss=0.1218 \t val_loss=6.3405 \t time=18.83s , lr=0.0012\n","Epoch 60/100 \t loss=0.1228 \t val_loss=6.1964 \t time=18.73s , lr=0.0012\n","Epoch 61/100 \t loss=0.1150 \t val_loss=6.0906 \t time=18.71s , lr=0.0012\n","Epoch 62/100 \t loss=0.1293 \t val_loss=5.6927 \t time=18.72s , lr=0.0012\n","Epoch 63/100 \t loss=0.1097 \t val_loss=6.0125 \t time=18.78s , lr=0.0012\n","Epoch 64/100 \t loss=0.1022 \t val_loss=6.3241 \t time=18.70s , lr=0.0012\n","Epoch 65/100 \t loss=0.0993 \t val_loss=6.1040 \t time=18.67s , lr=0.0012\n","Epoch 66/100 \t loss=0.0968 \t val_loss=5.9887 \t time=18.75s , lr=0.0012\n","Epoch 67/100 \t loss=0.1003 \t val_loss=6.0827 \t time=18.69s , lr=0.0012\n","Epoch 68/100 \t loss=0.0989 \t val_loss=6.4127 \t time=18.79s , lr=0.0012\n","Epoch 69/100 \t loss=0.0986 \t val_loss=6.1484 \t time=18.74s , lr=0.0012\n","Epoch 70/100 \t loss=0.0981 \t val_loss=5.8945 \t time=18.78s , lr=0.0012\n","Epoch 71/100 \t loss=0.1034 \t val_loss=6.0585 \t time=18.78s , lr=0.0012\n","Epoch 72/100 \t loss=0.0931 \t val_loss=6.1606 \t time=18.71s , lr=0.0012\n","Epoch 73/100 \t loss=0.1044 \t val_loss=6.0138 \t time=18.74s , lr=0.0012\n","Epoch 74/100 \t loss=0.0905 \t val_loss=6.3186 \t time=18.71s , lr=0.0012\n","Epoch 75/100 \t loss=0.0919 \t val_loss=6.1824 \t time=18.77s , lr=0.0012\n","Epoch 76/100 \t loss=0.0930 \t val_loss=6.1784 \t time=18.69s , lr=0.0012\n","Epoch 77/100 \t loss=0.0904 \t val_loss=6.3782 \t time=18.75s , lr=0.0012\n","Epoch 78/100 \t loss=0.0949 \t val_loss=6.1376 \t time=18.77s , lr=0.0012\n","Epoch 79/100 \t loss=0.0892 \t val_loss=5.8053 \t time=18.69s , lr=0.0012\n","Epoch 80/100 \t loss=0.1028 \t val_loss=5.9149 \t time=18.76s , lr=0.0012\n","Epoch 81/100 \t loss=0.0890 \t val_loss=6.2462 \t time=18.77s , lr=0.0012\n","Epoch 82/100 \t loss=0.0967 \t val_loss=6.3622 \t time=18.75s , lr=0.0012\n","Epoch 83/100 \t loss=0.0899 \t val_loss=6.0575 \t time=18.75s , lr=0.0012\n","Epoch 84/100 \t loss=0.0893 \t val_loss=6.1441 \t time=18.78s , lr=0.0012\n","Epoch 85/100 \t loss=0.0926 \t val_loss=5.9955 \t time=18.75s , lr=0.0012\n","Epoch 86/100 \t loss=0.0875 \t val_loss=6.0670 \t time=18.70s , lr=0.0012\n","Epoch 87/100 \t loss=0.0895 \t val_loss=5.9799 \t time=18.82s , lr=0.0012\n","Epoch 88/100 \t loss=0.0848 \t val_loss=6.1426 \t time=18.72s , lr=0.0012\n","Epoch 89/100 \t loss=0.0839 \t val_loss=6.0585 \t time=18.65s , lr=0.0012\n","Epoch 90/100 \t loss=0.0802 \t val_loss=5.8421 \t time=18.74s , lr=0.0012\n","Epoch 91/100 \t loss=0.0880 \t val_loss=5.8127 \t time=18.78s , lr=0.0012\n","Epoch 92/100 \t loss=0.0873 \t val_loss=6.2000 \t time=18.86s , lr=0.0012\n","Epoch 93/100 \t loss=0.0863 \t val_loss=6.0828 \t time=18.74s , lr=0.0012\n","Epoch 94/100 \t loss=0.0812 \t val_loss=6.0358 \t time=18.75s , lr=0.0012\n","Epoch 95/100 \t loss=0.0786 \t val_loss=6.4274 \t time=18.82s , lr=0.0012\n","Epoch 96/100 \t loss=0.0842 \t val_loss=5.9615 \t time=18.74s , lr=0.0012\n","Epoch 97/100 \t loss=0.0822 \t val_loss=5.9773 \t time=18.86s , lr=0.0012\n","Epoch 98/100 \t loss=0.0822 \t val_loss=5.9102 \t time=18.83s , lr=0.0012\n","Epoch 99/100 \t loss=0.0829 \t val_loss=5.9095 \t time=18.85s , lr=0.0012\n","Epoch 100/100 \t loss=0.0824 \t val_loss=5.8265 \t time=18.74s , lr=0.0012\n","Len Train (in batch): 58\n","Len validation (in batch): 28\n","Fold 2\n","Epoch 1/100 \t loss=2.5482 \t val_loss=0.1325 \t time=19.74s , lr=0.0001\n","Epoch 2/100 \t loss=1.6022 \t val_loss=0.1476 \t time=19.82s , lr=0.0001\n","Epoch 3/100 \t loss=1.0775 \t val_loss=0.4209 \t time=19.69s , lr=0.0001\n","Epoch 4/100 \t loss=0.8778 \t val_loss=0.3464 \t time=19.69s , lr=0.0001\n","Epoch 5/100 \t loss=0.7325 \t val_loss=0.3717 \t time=19.78s , lr=0.0001\n","Epoch 6/100 \t loss=0.5955 \t val_loss=0.4150 \t time=19.78s , lr=0.0001\n","Epoch 7/100 \t loss=0.5157 \t val_loss=0.5365 \t time=19.79s , lr=0.0001\n","Epoch 8/100 \t loss=0.4537 \t val_loss=0.5482 \t time=19.92s , lr=0.0001\n","Epoch 9/100 \t loss=0.4128 \t val_loss=0.5745 \t time=19.78s , lr=0.0001\n","Epoch 10/100 \t loss=0.3895 \t val_loss=0.4993 \t time=19.71s , lr=0.0001\n","Epoch 11/100 \t loss=0.3550 \t val_loss=0.5072 \t time=19.70s , lr=0.0001\n","Epoch 12/100 \t loss=0.3067 \t val_loss=0.5211 \t time=19.77s , lr=0.0001\n","Epoch 13/100 \t loss=0.3038 \t val_loss=0.5251 \t time=19.62s , lr=0.0001\n","Epoch 14/100 \t loss=0.2979 \t val_loss=0.6173 \t time=19.73s , lr=0.0001\n","Epoch 15/100 \t loss=0.2560 \t val_loss=0.6749 \t time=19.69s , lr=0.0001\n","Epoch 16/100 \t loss=0.2428 \t val_loss=0.5669 \t time=19.76s , lr=0.0001\n","Epoch 17/100 \t loss=0.2392 \t val_loss=0.5906 \t time=19.70s , lr=0.0001\n","Epoch 18/100 \t loss=0.2149 \t val_loss=0.5394 \t time=19.63s , lr=0.0001\n","Epoch 19/100 \t loss=0.2115 \t val_loss=0.6431 \t time=19.70s , lr=0.0001\n","Epoch 20/100 \t loss=0.2095 \t val_loss=0.5761 \t time=19.63s , lr=0.0001\n","Epoch 21/100 \t loss=0.1885 \t val_loss=0.6399 \t time=19.66s , lr=0.0001\n","Epoch 22/100 \t loss=0.1929 \t val_loss=0.5236 \t time=19.71s , lr=0.0001\n","Epoch 23/100 \t loss=0.1849 \t val_loss=0.6405 \t time=19.65s , lr=0.0001\n","Epoch 24/100 \t loss=0.1620 \t val_loss=0.5934 \t time=19.67s , lr=0.0001\n","Epoch 25/100 \t loss=0.1539 \t val_loss=0.6618 \t time=19.58s , lr=0.0001\n","Epoch 26/100 \t loss=0.1526 \t val_loss=0.6503 \t time=19.71s , lr=0.0001\n","Epoch 27/100 \t loss=0.1567 \t val_loss=0.6660 \t time=19.61s , lr=0.0001\n","Epoch 28/100 \t loss=0.1469 \t val_loss=0.6278 \t time=19.67s , lr=0.0001\n","Epoch 29/100 \t loss=0.1382 \t val_loss=0.5799 \t time=19.63s , lr=0.0001\n","Epoch 30/100 \t loss=0.1438 \t val_loss=0.6144 \t time=19.70s , lr=0.0001\n","Epoch 31/100 \t loss=0.1420 \t val_loss=0.5990 \t time=19.65s , lr=0.0001\n","Epoch 32/100 \t loss=0.1296 \t val_loss=0.5562 \t time=19.76s , lr=0.0001\n","Epoch 33/100 \t loss=0.1337 \t val_loss=0.7007 \t time=19.64s , lr=0.0001\n","Epoch 34/100 \t loss=0.1283 \t val_loss=0.6166 \t time=19.66s , lr=0.0001\n","Epoch 35/100 \t loss=0.1244 \t val_loss=0.6358 \t time=19.69s , lr=0.0001\n","Epoch 36/100 \t loss=0.1226 \t val_loss=0.6690 \t time=19.59s , lr=0.0001\n","Epoch 37/100 \t loss=0.1237 \t val_loss=0.5924 \t time=19.75s , lr=0.0001\n","Epoch 38/100 \t loss=0.1099 \t val_loss=0.5909 \t time=19.79s , lr=0.0001\n","Epoch 39/100 \t loss=0.1171 \t val_loss=0.6334 \t time=19.70s , lr=0.0001\n","Epoch 40/100 \t loss=0.1153 \t val_loss=0.6686 \t time=19.69s , lr=0.0001\n","Epoch 41/100 \t loss=0.1116 \t val_loss=0.6516 \t time=19.66s , lr=0.0001\n","Epoch 42/100 \t loss=0.1154 \t val_loss=0.6686 \t time=19.60s , lr=0.0001\n","Epoch 43/100 \t loss=0.1090 \t val_loss=0.6545 \t time=19.70s , lr=0.0001\n","Epoch 44/100 \t loss=0.1095 \t val_loss=0.6200 \t time=19.61s , lr=0.0001\n","Epoch 45/100 \t loss=0.0999 \t val_loss=0.6588 \t time=19.70s , lr=0.0001\n","Epoch 46/100 \t loss=0.1106 \t val_loss=0.6601 \t time=19.61s , lr=0.0001\n","Epoch 47/100 \t loss=0.1008 \t val_loss=0.6412 \t time=19.71s , lr=0.0001\n","Epoch 48/100 \t loss=0.1080 \t val_loss=0.7204 \t time=19.71s , lr=0.0001\n","Epoch 49/100 \t loss=0.1062 \t val_loss=0.6912 \t time=19.64s , lr=0.0001\n","Epoch 50/100 \t loss=0.1135 \t val_loss=0.6435 \t time=19.80s , lr=0.0001\n","Epoch 51/100 \t loss=0.1056 \t val_loss=0.6654 \t time=19.72s , lr=0.0000\n","Epoch 52/100 \t loss=0.0986 \t val_loss=0.6552 \t time=19.58s , lr=0.0000\n","Epoch 53/100 \t loss=0.0952 \t val_loss=0.6694 \t time=19.66s , lr=0.0000\n","Epoch 54/100 \t loss=0.0955 \t val_loss=0.6621 \t time=19.60s , lr=0.0000\n","Epoch 55/100 \t loss=0.1007 \t val_loss=0.6629 \t time=19.59s , lr=0.0000\n","Epoch 56/100 \t loss=0.0949 \t val_loss=0.6566 \t time=19.71s , lr=0.0000\n","Epoch 57/100 \t loss=0.1003 \t val_loss=0.6749 \t time=19.69s , lr=0.0000\n","Epoch 58/100 \t loss=0.0956 \t val_loss=0.6647 \t time=19.71s , lr=0.0000\n","Epoch 59/100 \t loss=0.0977 \t val_loss=0.6677 \t time=19.71s , lr=0.0000\n","Epoch 60/100 \t loss=0.0981 \t val_loss=0.6591 \t time=19.70s , lr=0.0000\n","Epoch 61/100 \t loss=0.0915 \t val_loss=0.6545 \t time=19.71s , lr=0.0000\n","Epoch 62/100 \t loss=0.0995 \t val_loss=0.6835 \t time=19.67s , lr=0.0000\n","Epoch 63/100 \t loss=0.0935 \t val_loss=0.6616 \t time=19.76s , lr=0.0000\n","Epoch 64/100 \t loss=0.0951 \t val_loss=0.6735 \t time=19.70s , lr=0.0000\n","Epoch 65/100 \t loss=0.0958 \t val_loss=0.6658 \t time=19.69s , lr=0.0000\n","Epoch 66/100 \t loss=0.0918 \t val_loss=0.6683 \t time=19.75s , lr=0.0000\n","Epoch 67/100 \t loss=0.0907 \t val_loss=0.6615 \t time=19.71s , lr=0.0000\n","Epoch 68/100 \t loss=0.0901 \t val_loss=0.6672 \t time=19.67s , lr=0.0000\n","Epoch 69/100 \t loss=0.0911 \t val_loss=0.6527 \t time=19.66s , lr=0.0000\n","Epoch 70/100 \t loss=0.0952 \t val_loss=0.6611 \t time=19.67s , lr=0.0000\n","Epoch 71/100 \t loss=0.0915 \t val_loss=0.6843 \t time=19.74s , lr=0.0000\n","Epoch 72/100 \t loss=0.0962 \t val_loss=0.6764 \t time=19.65s , lr=0.0000\n","Epoch 73/100 \t loss=0.0978 \t val_loss=0.6661 \t time=19.69s , lr=0.0000\n","Epoch 74/100 \t loss=0.0951 \t val_loss=0.6465 \t time=19.60s , lr=0.0000\n","Epoch 75/100 \t loss=0.0994 \t val_loss=0.6311 \t time=19.58s , lr=0.0000\n","Epoch 76/100 \t loss=0.0950 \t val_loss=0.6669 \t time=19.62s , lr=0.0000\n","Epoch 77/100 \t loss=0.0887 \t val_loss=0.6421 \t time=19.61s , lr=0.0000\n","Epoch 78/100 \t loss=0.0900 \t val_loss=0.6469 \t time=19.61s , lr=0.0000\n","Epoch 79/100 \t loss=0.0942 \t val_loss=0.6492 \t time=19.62s , lr=0.0000\n","Epoch 80/100 \t loss=0.0965 \t val_loss=0.6477 \t time=19.69s , lr=0.0000\n","Epoch 81/100 \t loss=0.0943 \t val_loss=0.6396 \t time=19.74s , lr=0.0000\n","Epoch 82/100 \t loss=0.0963 \t val_loss=0.6423 \t time=19.62s , lr=0.0000\n","Epoch 83/100 \t loss=0.0933 \t val_loss=0.6569 \t time=19.69s , lr=0.0000\n","Epoch 84/100 \t loss=0.0900 \t val_loss=0.6627 \t time=19.58s , lr=0.0000\n","Epoch 85/100 \t loss=0.0941 \t val_loss=0.6486 \t time=19.69s , lr=0.0000\n","Epoch 86/100 \t loss=0.0889 \t val_loss=0.6675 \t time=19.67s , lr=0.0000\n","Epoch 87/100 \t loss=0.0909 \t val_loss=0.6546 \t time=19.70s , lr=0.0000\n","Epoch 88/100 \t loss=0.0961 \t val_loss=0.6424 \t time=19.65s , lr=0.0000\n","Epoch 89/100 \t loss=0.0965 \t val_loss=0.6418 \t time=19.63s , lr=0.0000\n","Epoch 90/100 \t loss=0.0851 \t val_loss=0.6603 \t time=19.64s , lr=0.0000\n","Epoch 91/100 \t loss=0.0892 \t val_loss=0.6640 \t time=19.67s , lr=0.0000\n","Epoch 92/100 \t loss=0.0950 \t val_loss=0.6561 \t time=19.66s , lr=0.0000\n","Epoch 93/100 \t loss=0.0989 \t val_loss=0.6634 \t time=19.67s , lr=0.0000\n","Epoch 94/100 \t loss=0.0895 \t val_loss=0.6535 \t time=19.66s , lr=0.0000\n","Epoch 95/100 \t loss=0.0907 \t val_loss=0.6676 \t time=19.58s , lr=0.0000\n","Epoch 96/100 \t loss=0.0884 \t val_loss=0.6734 \t time=19.65s , lr=0.0000\n","Epoch 97/100 \t loss=0.0859 \t val_loss=0.6408 \t time=19.69s , lr=0.0000\n","Epoch 98/100 \t loss=0.0933 \t val_loss=0.6442 \t time=19.71s , lr=0.0000\n","Epoch 99/100 \t loss=0.0930 \t val_loss=0.6378 \t time=19.69s , lr=0.0000\n","Epoch 100/100 \t loss=0.0875 \t val_loss=0.6682 \t time=19.67s , lr=0.0000\n","Len Train (in batch): 59\n","Len validation (in batch): 26\n","Fold 3\n","Epoch 1/100 \t loss=0.3216 \t val_loss=0.0148 \t time=19.89s , lr=0.0000\n","Epoch 2/100 \t loss=0.2982 \t val_loss=0.0128 \t time=19.98s , lr=0.0000\n","Epoch 3/100 \t loss=0.2938 \t val_loss=0.0125 \t time=20.01s , lr=0.0000\n","Epoch 4/100 \t loss=0.2837 \t val_loss=0.0123 \t time=20.04s , lr=0.0000\n","Epoch 5/100 \t loss=0.2791 \t val_loss=0.0122 \t time=20.06s , lr=0.0000\n","Epoch 6/100 \t loss=0.2608 \t val_loss=0.0118 \t time=20.02s , lr=0.0000\n","Epoch 7/100 \t loss=0.2759 \t val_loss=0.0117 \t time=20.05s , lr=0.0000\n","Epoch 8/100 \t loss=0.2632 \t val_loss=0.0118 \t time=20.08s , lr=0.0000\n","Epoch 9/100 \t loss=0.2675 \t val_loss=0.0119 \t time=19.97s , lr=0.0000\n","Epoch 10/100 \t loss=0.2566 \t val_loss=0.0124 \t time=20.04s , lr=0.0000\n","Epoch 11/100 \t loss=0.2537 \t val_loss=0.0129 \t time=20.01s , lr=0.0000\n","Epoch 12/100 \t loss=0.2617 \t val_loss=0.0128 \t time=20.05s , lr=0.0000\n","Epoch 13/100 \t loss=0.2412 \t val_loss=0.0129 \t time=19.99s , lr=0.0000\n","Epoch 14/100 \t loss=0.2620 \t val_loss=0.0130 \t time=19.94s , lr=0.0000\n","Epoch 15/100 \t loss=0.2537 \t val_loss=0.0132 \t time=19.96s , lr=0.0000\n","Epoch 16/100 \t loss=0.2406 \t val_loss=0.0133 \t time=20.04s , lr=0.0000\n","Epoch 17/100 \t loss=0.2491 \t val_loss=0.0134 \t time=19.93s , lr=0.0000\n","Epoch 18/100 \t loss=0.2377 \t val_loss=0.0135 \t time=20.06s , lr=0.0000\n","Epoch 19/100 \t loss=0.2278 \t val_loss=0.0137 \t time=20.00s , lr=0.0000\n","Epoch 20/100 \t loss=0.2393 \t val_loss=0.0139 \t time=20.04s , lr=0.0000\n","Epoch 21/100 \t loss=0.2409 \t val_loss=0.0144 \t time=19.96s , lr=0.0000\n","Epoch 22/100 \t loss=0.2278 \t val_loss=0.0145 \t time=19.98s , lr=0.0000\n","Epoch 23/100 \t loss=0.2350 \t val_loss=0.0147 \t time=19.99s , lr=0.0000\n","Epoch 24/100 \t loss=0.2337 \t val_loss=0.0146 \t time=20.02s , lr=0.0000\n","Epoch 25/100 \t loss=0.2172 \t val_loss=0.0150 \t time=20.01s , lr=0.0000\n","Epoch 26/100 \t loss=0.2225 \t val_loss=0.0152 \t time=20.00s , lr=0.0000\n","Epoch 27/100 \t loss=0.2163 \t val_loss=0.0153 \t time=20.09s , lr=0.0000\n","Epoch 28/100 \t loss=0.2200 \t val_loss=0.0150 \t time=20.02s , lr=0.0000\n","Epoch 29/100 \t loss=0.2327 \t val_loss=0.0149 \t time=20.08s , lr=0.0000\n","Epoch 30/100 \t loss=0.2317 \t val_loss=0.0153 \t time=19.94s , lr=0.0000\n","Epoch 31/100 \t loss=0.2092 \t val_loss=0.0157 \t time=19.93s , lr=0.0000\n","Epoch 32/100 \t loss=0.2210 \t val_loss=0.0155 \t time=19.97s , lr=0.0000\n","Epoch 33/100 \t loss=0.2221 \t val_loss=0.0160 \t time=20.02s , lr=0.0000\n","Epoch 34/100 \t loss=0.2212 \t val_loss=0.0155 \t time=20.01s , lr=0.0000\n","Epoch 35/100 \t loss=0.2134 \t val_loss=0.0157 \t time=20.01s , lr=0.0000\n","Epoch 36/100 \t loss=0.2172 \t val_loss=0.0163 \t time=19.93s , lr=0.0000\n","Epoch 37/100 \t loss=0.2077 \t val_loss=0.0164 \t time=19.99s , lr=0.0000\n","Epoch 38/100 \t loss=0.2120 \t val_loss=0.0169 \t time=19.95s , lr=0.0000\n","Epoch 39/100 \t loss=0.2123 \t val_loss=0.0169 \t time=19.93s , lr=0.0000\n","Epoch 40/100 \t loss=0.2145 \t val_loss=0.0167 \t time=19.96s , lr=0.0000\n","Epoch 41/100 \t loss=0.2141 \t val_loss=0.0165 \t time=19.99s , lr=0.0000\n","Epoch 42/100 \t loss=0.2069 \t val_loss=0.0165 \t time=19.91s , lr=0.0000\n","Epoch 43/100 \t loss=0.2013 \t val_loss=0.0164 \t time=19.97s , lr=0.0000\n","Epoch 44/100 \t loss=0.2043 \t val_loss=0.0165 \t time=19.94s , lr=0.0000\n","Epoch 45/100 \t loss=0.2132 \t val_loss=0.0171 \t time=19.97s , lr=0.0000\n","Epoch 46/100 \t loss=0.2025 \t val_loss=0.0177 \t time=19.94s , lr=0.0000\n","Epoch 47/100 \t loss=0.2073 \t val_loss=0.0183 \t time=20.00s , lr=0.0000\n","Epoch 48/100 \t loss=0.2017 \t val_loss=0.0183 \t time=19.90s , lr=0.0000\n","Epoch 49/100 \t loss=0.1964 \t val_loss=0.0181 \t time=20.01s , lr=0.0000\n","Epoch 50/100 \t loss=0.1958 \t val_loss=0.0181 \t time=19.93s , lr=0.0000\n","Epoch 51/100 \t loss=0.2009 \t val_loss=0.0176 \t time=19.98s , lr=0.0000\n","Epoch 52/100 \t loss=0.2074 \t val_loss=0.0175 \t time=19.97s , lr=0.0000\n","Epoch 53/100 \t loss=0.1904 \t val_loss=0.0181 \t time=20.03s , lr=0.0000\n","Epoch 54/100 \t loss=0.2059 \t val_loss=0.0178 \t time=19.92s , lr=0.0000\n","Epoch 55/100 \t loss=0.1905 \t val_loss=0.0179 \t time=20.00s , lr=0.0000\n","Epoch 56/100 \t loss=0.1954 \t val_loss=0.0182 \t time=19.93s , lr=0.0000\n","Epoch 57/100 \t loss=0.1949 \t val_loss=0.0179 \t time=20.04s , lr=0.0000\n","Epoch 58/100 \t loss=0.1982 \t val_loss=0.0179 \t time=19.98s , lr=0.0000\n","Epoch 59/100 \t loss=0.1998 \t val_loss=0.0178 \t time=19.96s , lr=0.0000\n","Epoch 60/100 \t loss=0.1967 \t val_loss=0.0180 \t time=19.94s , lr=0.0000\n","Epoch 61/100 \t loss=0.1914 \t val_loss=0.0180 \t time=19.96s , lr=0.0000\n","Epoch 62/100 \t loss=0.2078 \t val_loss=0.0183 \t time=19.95s , lr=0.0000\n","Epoch 63/100 \t loss=0.2014 \t val_loss=0.0181 \t time=19.97s , lr=0.0000\n","Epoch 64/100 \t loss=0.1940 \t val_loss=0.0182 \t time=20.00s , lr=0.0000\n","Epoch 65/100 \t loss=0.1885 \t val_loss=0.0179 \t time=20.03s , lr=0.0000\n","Epoch 66/100 \t loss=0.2015 \t val_loss=0.0177 \t time=19.97s , lr=0.0000\n","Epoch 67/100 \t loss=0.1968 \t val_loss=0.0175 \t time=19.90s , lr=0.0000\n","Epoch 68/100 \t loss=0.2069 \t val_loss=0.0174 \t time=19.88s , lr=0.0000\n","Epoch 69/100 \t loss=0.2032 \t val_loss=0.0175 \t time=19.97s , lr=0.0000\n","Epoch 70/100 \t loss=0.1999 \t val_loss=0.0178 \t time=19.96s , lr=0.0000\n","Epoch 71/100 \t loss=0.1957 \t val_loss=0.0179 \t time=20.00s , lr=0.0000\n","Epoch 72/100 \t loss=0.1952 \t val_loss=0.0181 \t time=19.97s , lr=0.0000\n","Epoch 73/100 \t loss=0.1868 \t val_loss=0.0182 \t time=20.03s , lr=0.0000\n","Epoch 74/100 \t loss=0.1899 \t val_loss=0.0180 \t time=19.91s , lr=0.0000\n","Epoch 75/100 \t loss=0.1935 \t val_loss=0.0180 \t time=19.90s , lr=0.0000\n","Epoch 76/100 \t loss=0.1921 \t val_loss=0.0183 \t time=19.95s , lr=0.0000\n","Epoch 77/100 \t loss=0.2039 \t val_loss=0.0183 \t time=19.96s , lr=0.0000\n","Epoch 78/100 \t loss=0.1939 \t val_loss=0.0182 \t time=19.94s , lr=0.0000\n","Epoch 79/100 \t loss=0.1951 \t val_loss=0.0182 \t time=19.92s , lr=0.0000\n","Epoch 80/100 \t loss=0.2009 \t val_loss=0.0181 \t time=20.06s , lr=0.0000\n","Epoch 81/100 \t loss=0.1920 \t val_loss=0.0184 \t time=20.00s , lr=0.0000\n","Epoch 82/100 \t loss=0.1907 \t val_loss=0.0181 \t time=19.91s , lr=0.0000\n","Epoch 83/100 \t loss=0.1945 \t val_loss=0.0181 \t time=20.00s , lr=0.0000\n","Epoch 84/100 \t loss=0.2031 \t val_loss=0.0181 \t time=19.91s , lr=0.0000\n","Epoch 85/100 \t loss=0.2030 \t val_loss=0.0179 \t time=20.03s , lr=0.0000\n","Epoch 86/100 \t loss=0.1899 \t val_loss=0.0179 \t time=19.95s , lr=0.0000\n","Epoch 87/100 \t loss=0.1898 \t val_loss=0.0181 \t time=19.97s , lr=0.0000\n","Epoch 88/100 \t loss=0.1970 \t val_loss=0.0180 \t time=20.00s , lr=0.0000\n","Epoch 89/100 \t loss=0.1924 \t val_loss=0.0182 \t time=19.99s , lr=0.0000\n","Epoch 90/100 \t loss=0.1979 \t val_loss=0.0184 \t time=20.00s , lr=0.0000\n","Epoch 91/100 \t loss=0.1927 \t val_loss=0.0180 \t time=20.01s , lr=0.0000\n","Epoch 92/100 \t loss=0.1999 \t val_loss=0.0182 \t time=19.97s , lr=0.0000\n","Epoch 93/100 \t loss=0.1946 \t val_loss=0.0180 \t time=19.95s , lr=0.0000\n","Epoch 94/100 \t loss=0.1975 \t val_loss=0.0180 \t time=19.94s , lr=0.0000\n","Epoch 95/100 \t loss=0.1941 \t val_loss=0.0183 \t time=19.96s , lr=0.0000\n","Epoch 96/100 \t loss=0.1902 \t val_loss=0.0179 \t time=20.01s , lr=0.0000\n","Epoch 97/100 \t loss=0.1907 \t val_loss=0.0180 \t time=20.01s , lr=0.0000\n","Epoch 98/100 \t loss=0.1917 \t val_loss=0.0180 \t time=19.96s , lr=0.0000\n","Epoch 99/100 \t loss=0.1937 \t val_loss=0.0178 \t time=19.99s , lr=0.0000\n","Epoch 100/100 \t loss=0.1943 \t val_loss=0.0183 \t time=20.01s , lr=0.0000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zML7-wribUM1","colab_type":"text"},"source":["*Test* the final Results:\n"]},{"cell_type":"code","metadata":{"id":"nVTqTCmYcSlb","colab_type":"code","colab":{}},"source":["# Save the network parameters\n","torch.save(model.state_dict(), \"/content/drive/My Drive/model/efficientnet-b5_100_3fold.pt\") \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XZyM1crONQc_","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"J6Mq82xrVl3b","colab_type":"code","outputId":"d7db01fa-0675-49cb-9a72-8529763d741a","executionInfo":{"status":"ok","timestamp":1586962290056,"user_tz":-120,"elapsed":1776,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["test_list = generateDatasetIDS(test_IDs.ID,\"/content/drive/My Drive/frames/\")\n","print(len(test_list))\n","test_custom = CustomListDataset(images_list = test_list, df_weights = weights, root_dir=\"/content/drive/My Drive/frames/\", transform = transform)\n","test_final_loader = torch.utils.data.DataLoader(test_custom, batch_size=64, shuffle=False, num_workers=2)\n","\n","print(len(test_final_loader))\n","print(len(test_final_loader.dataset))\n","\n","predicted_label = list()\n","real_label = list()\n","\n","#Set the network in eval mode\n","model.eval()\n","with torch.no_grad():\n","  # Loop over the dataset\n","  for batch_idx, (inputs, targets) in enumerate(test_final_loader):\n","    # Load data into GPU\n","    inputs = inputs.to(device)\n","    #print('inputs', inputs.shape)\n","\n","    targets = targets.to(device)\n","    #print('targets', targets.shape)\n","\n","    # Forward pass\n","    outputs = model.forward(inputs)\n","    \n","    #print('Out:',outputs.shape)\n","    \n","    arr1 = outputs.data.cpu().numpy()\n","    arr2 = targets.data.cpu().numpy()\n","\n","    predicted_label.extend(arr1)\n","    real_label.extend(arr2)\n"],"execution_count":103,"outputs":[{"output_type":"stream","text":["357\n","6\n","357\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kzKmppbOVpsl","colab_type":"code","outputId":"f7228dee-ea4b-4910-951f-5791b1f5092a","executionInfo":{"status":"ok","timestamp":1586962290056,"user_tz":-120,"elapsed":66,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#print (predicted_label)\n","\n","import numpy as np\n","predicted_label = np.array(predicted_label,dtype=int)\n","real_label = np.array(real_label, dtype=int)\n","#print(predicted_label)\n","\n","pred_label_list = list()\n","for x in np.nditer(predicted_label):\n","  #print(x)\n","  pred_label_list.append(x)\n","\n","real_label_list = list()\n","for x in np.nditer(real_label):\n","  real_label_list.append(x)\n","\n","print(len(pred_label_list))"],"execution_count":104,"outputs":[{"output_type":"stream","text":["357\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DSTeHo56Vvz7","colab_type":"code","outputId":"960fee0e-dbb2-4a05-ed1c-de95f4b47ed2","executionInfo":{"status":"ok","timestamp":1586962290057,"user_tz":-120,"elapsed":56,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":313}},"source":["import numpy as np\n","import pandas as pd\n","\n","'''real_label, predicted_label'''\n","\n","print(type(real_label))\n","\n","df = pd.DataFrame({'REAL': np.asarray(real_label_list), 'PREDICTED':np.asarray(pred_label_list)})\n","df.plot('REAL', 'PREDICTED', kind='scatter')"],"execution_count":105,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fa5ea2d8748>"]},"metadata":{"tags":[]},"execution_count":105},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfrElEQVR4nO3de5RU5Znv8e+vuV9EoOkg4aIohshS7GDHiAZWEtRExyM4motnGcycOJgzuYwmmWg85yROZiVjPOa4JskZT9Bc0IwmChESJzEa4kzMjHHSImkIREFRLgNt24KAIjT0c/6o3VjdVHV1Qe2u6q7fZ61K13527b0fdsqnd7/73e+riMDMzKpHTbkTMDOz3uXCb2ZWZVz4zcyqjAu/mVmVceE3M6syA8udQE+MGzcuTjrppHKnYWbWpzz11FMvR0Rd13ifKPwnnXQSjY2N5U7DzKxPkfRirribeszMqowLv5lZlXHhNzOrMi78ZmZVxoXfzKzKuPCbmVWojc17WNq4hY3Ne0q63z7RndPMrNp8afka7v7d5sPLC2dP4SvzzyjJvn3Fb2ZWYTY27+lU9AHufmJzya78XfjNzCrM6i27iooXy4XfzKzC1E8eXVS8WC78ZmYVZtr441g4e0qn2MLZU5g2/riS7N+F38ysAv3wic3dLh8LF34zswrz1Z+tpb1LrD2Jl4ILv5lZhXlo7Y6i4sVy4TczqzCXnH5CUfFipVr4Jf21pLWS/ijpuiQ2VtKjkjYkP8ekmYOZWV/zP/7L6UcU55okXgqpFX5JpwN/CZwNnAlcImkacCOwMiJOBVYmy2ZmliVXG3+ppHnFfxrwZES8HhEHgX8F/hyYDyxJPrMEWJBiDmZmfc7H7nqiqHix0iz8a4E5kmolDQcuBiYD4yNie/KZHcD4XBtLWiSpUVJjS0tLimmamVWWf9/0SlHxYqVW+CNiPfB14BHgYWA1cKjLZwKIPNsvjoiGiGioqztirmAzs37r3Klji4oXK9WbuxHx3Yg4KyLmAjuBZ4FmSRMAkp8vpZmDmVlf84NrZhcVL1bavXrekvycQqZ9/17gp8DVyUeuBlakmYOZWV80SN0vH4u0+/Evk7QO+BnwyYjYBdwCXCBpA3B+smxmZonbf7meti6N4G2RiZdCqhOxRMScHLFWYF6axzUz68tWNOV+QndF0w6uf/9px7x/P7lrZlZh5s/M/YRuvnixXPjNzCrM9e8/LWcbfymu9sGF38ysIr3rlNpOy+d0WT4WLvxmZhWmcVMrv93Y2in2+MZWGje15tmiOC78ZmYV5jcbXi4qXiwXfjOzCjP31HFFxYvlwm9mVmEaptYyZ1rnNv0502ppmFqadn4XfjOzCnRFw2QGD6hh8AAxeEANH2yYXLJ9u/CbmVWY1r37uWFZEwcOtXPgUHDgUDtfWNZE6979Jdm/C7+ZWYXZunMfg2o6l+dBNTVs3bmvJPt34TczqzCTxgyjrb3znFtt7e1MGjOsJPt34TczqzC1I4dw6+UzGTKwhuGDBzBkYA23Xj6T2pFDSrJ/F34zswoUHf8bby6Vigu/mVmF6bi5u/9g8HrbIfYfDN/cNTPrz3xz18ysyvTpm7uSrpf0R0lrJd0naaikH0jaJGl18qpPMwczs76m4+bu0EE1HDdkIEMHlfbmbmozcEmaCHwGmBER+yTdD3wkWf03EbE0rWObmfV1l9ZP5Lxp49i6cx+TxgwrWdGHlKdeTPY/TFIbMBz4z5SPZ2bWb9SOHFLSgt8htaaeiNgG3AZsBrYDr0bEI8nqr0pqknS7pJz/KkmLJDVKamxpaUkrTTOzqpNa4Zc0BpgPTAXeCoyQdBXwReDtwDuBscANubaPiMUR0RARDXV1dWmlaWZWddK8uXs+sCkiWiKiDfgJcG5EbI+M/cD3gbNTzMHMzLpIs/BvBs6RNFySgHnAekkTAJLYAmBtijmYmVkXqd3cjYgnJS0FVgEHgaeBxcAvJNUBAlYDn0grBzMzO1KqvXoi4svAl7uE35fmMc3MrHt+ctfMrMq48JuZVRkXfjOzKuPCb2ZWZVz4zcyqjAu/mVmVceE3M6syLvxmZlXGhd/MrMq48JuZVRkXfjOzKuPCb2bHbPmqLVyz5PcsX7Wl3KlYD6Q99aKZ9XPnfO1Rduw+AMCv1r/E1x/+E0/cdEGZs7Lu+IrfzI7a8lVbDhf9Dtt3H/CVf4Vz4Tezo/bQmh1Fxa0ypFr4JV0v6Y+S1kq6T9JQSVMlPSlpo6QfSxqcZg5mlp5LzjihqLhVhjQnW58IfAZoiIjTgQHAR4CvA7dHxDRgJ/DxtHIws3QtmDWZCaM6X7tNGDWYBbMmlykj64m0m3oGAsMkDQSGA9vJzMC1NFm/hMy8u2bWR23P0cZvlS21wh8R24DbyEy6vh14FXgK2BURB5OPbQUmppWDmaXr8z9eVVTcKkOaTT1jgPnAVOCtwAjgA0Vsv0hSo6TGlpaWlLI0s2Px6PqXiopbZUizqed8YFNEtEREG/AT4DxgdNL0AzAJ2JZr44hYHBENEdFQV1eXYppmdrQuOO0tRcWtMqRZ+DcD50gaLknAPGAd8BhwRfKZq4EVKeZgZim67cOziopbZUizjf9JMjdxVwFrkmMtBm4APitpI1ALfDetHMwsXT/8901Fxa0ypDpkQ0R8Gfhyl/DzwNlpHtfMeseKpu1541edO7WXs7Ge8pO7ZnbU5s+cUFTcKoMLv1kV2Ni8h6WNW9jYvKek+73q3KkcP3RAp9jxQwf4ar/CeXROs37uS8vXcPfvNh9eXjh7Cl+Zf0bJ9v+VBWfw+fv/wKEIBkj83YLS7dvS4St+s35sY/OeTkUf4O4nNpfsyr91735uWNZEW3vQHtDWHnxhWROte/eXZP+WDhd+s35s9ZZdRcWLtXXnPgbVdC4jg2pq2LpzX0n2b+lw4Tfrx+onjy4qXqxJY4bR1t7eKdbW3s6kMcNKsn9Lhwu/WT82bfxxLJw9pVNs4ewpTBt/XEn2XztyCLdePpOhg2o4bshAhg6q4dbLZ1I7ckhJ9m/p8M1ds37u7ieObOMv5c3dS+snct60cWzduY9JY4a56PcBvuI368fm3vKrouJHq3bkEM6cPNpFv48oWPglXS1plaTXklejpIW9kZyZHZvNu3L3rskXt+rQbVOPpKuB64DPkhlzR8As4H9Lioi4J/0UzexoTRk9JGeRnzLaV+bVrNAV/38HLouIxyLi1YjYFRG/Bi4HPpl+emZ2LH5z4/lFxa06FCr8oyLiha7BJDYqjYTMzCxdhQp/d09h+AkNswrnqREtl0LdOU+T1JQjLuDkFPIxsxLy1IiWS8HC3ytZmFkqLjjtLSx9+sgx8z01YnUr1NQzLCJejIgXgR0d75PlbgfcljRd0uqs125J10m6WdK2rPjFJfvXmFknnhrRcilU+O/Nev9El3X/2N2GEfFMRNRHRD1wFvA68GCy+vaOdRHx86IyNrOivG38iE7L07ssW/UpVPiV532u5e7MA55L/lIws16yct0Onm1+rVPsmebXWLluR5kyskpQqPBHnve5lrvzEeC+rOVPSWqS9D1JY3JtIGlR8pRwY0tLSxGHMrMOj6xrLipu1aFQ4Z8k6ZuSvpX1vmN5Yk8OIGkwcCnwQBK6AzgFqAe2A9/ItV1ELI6IhohoqKur68mhzKyLC2eMLypu1aFQr56/yXrf2GVd1+V8LgJWRUQzQMdPAEl3Ag/1cD9mVqR5M05g+vgRPJPV3DN9/AjmzTihjFlZuRUq/NMj4qZjPMaVZDXzSJoQER39yy4D1h7j/s2sG7+8/j2sXLeDR9Y1c+GM8S76hiLyN9VLWhURR93vS9IIYDNwckS8msTuIdPME8ALwLVZvwhyamhoiMbGnv6BYWZmAJKeioiGrvFCV/wDkpuvOXvwRMQr3W0cEa8BtV1iHy1wTDMzS1Ghwv924ClyF/7AwzaYmfU5hQr/uoh4R69kYmZmvcJTL5qZVZlChf9OSUd0opdUJ2loSjmZmVmKChX+emBOjvi7gdtLn46ZmaWtUOE/KyJ+0jUYEQ8Cc9NJyczM0lSo8A8/hm3N+pzWvfv5w5ZdtO49coJys/6iUK+elySdHRH/kR2U9E7AI6dZv7Ji9TZuWNbEoJoa2trbufXymVxa36Mhqcz6lJ6M1XO/pB+Q6c8P0AAsJDPiplm/0Lp3Pzcsa+KNtnbeoB2ALyxr4rxp46gdOaTM2ZmVVrfNNcmV/rvIPMD1seQl4F0R8WTayZn1lq079zGopvN/DoNqati6c1+ZMjJLT6Er/o7RNL/cC7mYlc2kMcNoa2/vFGtrb2fSmGFlysgsPd0WfklryD3hioCIiJmpZGXWy2pHDuHWy2fyuQf+QHtAjeDWy2e6mcf6pUJX/Jf0ShZmFeBrP19H26HMdc4h4O9/vs43d61fKtTG/2IyT+6rwFuS166suFm/sHzVFnbsPtAptn33AZav2lKmjMzS023hlzQk6dHzArAYuBN4IZkrd3D66Zn1jofW5J58PF/crC8r9BDW/wQGAZMj4h0RUQ9MIdNE9L/STs6st1xyRu5ZqfLFzfqyQoX/MuAvI2JPRyB5/1fJurwkTZe0Ouu1W9J1ksZKelTShuTnmGP/Z5gdmwWzJjNhVOc/YieMGsyCWZPLlJFZegoV/vaIeL1rMCL2kru3T/ZnnomI+uSvhLOA14EHgRuBlRFxKrAyWTYru5f3HOh22ay/KFT4Q9KY5Cq90wtoL7BttnnAc8kN4fnAkiS+BFhQfNpmpXX7L9fT1uVSpi0ycbP+plB3zuPpfurFnvoIcF/yfnzW5Oo7gPG5NpC0CFgEMGXKlCIOZVa8FU25b+KuaNrB9e8/rZezMUtXoe6cJ0XEyRExNcerR/PtJr1/LgUeyLH/IM8vkIhYHBENEdFQV3fEXDBmJTV/Zu6buPniZn1Zoe6cV2W9P6/Luk/18BgXAauSoR8AmiVNSPYxAXip5+mapeP695/GoC5/1w4Svtq3fqlQG/9ns95/q8u6/9bDY1zJm808AD8Frk7eXw2s6OF+zFKVq43frD8qVPiV532u5SM3lkYAFwDZs3jdAlwgaQNwfrJsVlaf/uHvi4qb9WWFbu5Gnve5lo/cOOI1oLZLrJVMLx+zivHrZ18uKm7WlxUq/G+X1ETm6v6U5D3Jco9u7pr1Be972zh+tvbI203ve9u4MmRjlq5Chd93tqxorXv3s3XnPiaNGdZnhjX+1lXv5Gc3/nPOuFl/023hzzcCp6QaMjdtPUKnddKX560dpM43dLv28jHrLwp15xwl6YuSvi3pQmV8Gnge+FDvpGh9Rfa8tXv2H+SNtna+sKyJ1r37y51aQX5y16pJoV499wDTgTXANcBjwBXAgoiYn3Ju1sf05Xlru3ty16y/KdTGf3JEnAEg6S5gOzAlIt5IPTPrc/ryvLXzZ57APzz2fM64WX9T6Iq/reNNRBwCtrro28bmPSxt3MLG5j2d4h3z1g4UDKiBgUcxb22+fafNT+5aNSl0xX+mpN28+bDWsKzliIhRqWZnFedLy9dw9+82H15eOHsKX5l/xuHlbz+2gYNZIzD938c29PjmbqF9p+22D9dz/Y9W007miugbH67vtWOb9aZCg7QNiIhREXFc8hqYteyiX2U2Nu/pVJgB7n5i8+Gr85XrdvBs82ud1j/T/Bor1xVuJy+077R13JjuaKhqhz5zY9qsWIV69QxNZs36tqRFkgr9hWD92Ootu7qNP7KuOef6fPFi9p22vnxj2qxYhdr4lwANZHr1XAx8I/WMrGLVTx7dbfzCGTmnVsgbL2bfaevLN6bNilWo8M+IiKsi4jtkunHO6YWcrEJNG38cC2d3nhRn4ewpTBt/HADzZpzA9PEjOq2fPn4E82YU7hlTaN9p67gxPXRQDccNGcjQQTVF35g26ysKNd1k9+o5KPlRxmr3wO+3HLGcfQP2mRxt/D31fEvnz25q6fm2pXBp/UTOmzauzw03YVasQlf8Z0ranbz2ADM73ie9e6yKfOexDew72Pnx1n0Hg+88tgGA//qdf8u5Xb54tsZNrfx2Y2un2OMbW2nc1Jpni3TUjhzCmZNHu+hbv9bTXj2j3KvHljdt7zb+Hy/mvhGbL57tNxtyD3+cL25mR6/QFb/ZYQtmTug2fvaJuW/E5otnm3tq7uGP88XN7OilWvgljZa0VNKfJK2XNFvSzZK2SVqdvC5OMwcrnWvfeyrDBna+zzNsoLj2vacCcO+15+XaLG88W8PUWuZM6zRnD3Om1dIwtTbPFmZ2tNLul/8PwMMRcYWkwcBw4P3A7RFxW8rHtj6m8YVXul02s9JI7Ypf0vHAXOC7ABFxICJ652kcS0Whm7sf/MfHc26XL17Mvs2sdNJs6pkKtADfl/S0pLuSydcBPiWpSdL3JI3JtXHypHCjpMaWlpYU07SeKnRzd9WW3B298sWL2beZlU6ahX8gMAu4IyLeAbwG3AjcAZwC1JMZ5jnn08ARsTgiGiKioa6uLsU0racK3dydNTl3R6988WL2bWalk2bh30pmGOcnk+WlwKyIaI6IQxHRDtwJnJ1iDlZChW7uPvBXuR/szhcvZt9mVjqpFf6I2AFskTQ9Cc0D1knKvoS7DFibVg5Werna4Uvlgw2TOy+/c3KeT5rZsUi7H/+ngX+S1ESmaedrwK2S1iSx9wLXp5yDlcj5t/262/h5X3s05/p88WzlHpbZrJqk2p0zIlaTGd0z20fTPKalZ+PLuYco7ohv230g5/p88WzdDcvcWwO1mVULP7lrPTZtXO4hijviE0cNzrk+XzxbuYdlNqsmLvzWY7/6/Pu6jf/bTRfkXJ8vnq3cwzKbVRMXfqsYZ504lsEDxJCBNQweIBpOHFvulMz6JRd+67H6m3/ebXz6F/855/p88Wwdc94eOBTsP9jOgUPhOW/NUuLCbz22643cXTc74vvz9OzMF8/mOW/Neo8Lv/XY6KG5Z2DriA/JM0Fbvng2z3lr1ntc+K3HVt+cewTtjvgzf/9nOdfni2erHTmEKWM7F/kTx3r6Q7M0uPBbj+WbBrEjvnzVlpzr88W77uPZHPP19vbUi2bVwIXfeqzQ9IgPrdmRc32+eDH7NrPSceG3His0PeIlZ5yQc32+eDH7NrPSceG3His0PeKCWZOZ0OUp3QmjBrNgVuHB1jz1olnvSXvqRetnrmiYzO+ebwUExBEjat548Qw+9+PVRPKJL148o8f7vueac2jc1MpvNrzM3FPHueibpcSF33qs4yGrtnaATOf8Lyxr4rxp46gdOeTw+uyRmrPX90TDVF/lm6XNTT3WY4UesvJDWGZ9gwu/9Vihh6z8EJZZ35Bq4Zc0WtJSSX+StF7SbEljJT0qaUPyM+dk61Z5akcO4dbLZzJ0UA3HDRnI0EE13Hr5zMPNOIXWm1llUETpps47YufSEuDxiLhL0mBgOHAT8EpE3CLpRmBMRNzQ3X4aGhqisbExtTytOK1797N15z4mjcn9ZG2h9WbWOyQ9FRFdJ8NK7+aupOOBucDHACLiAHBA0nzgPcnHlgD/AnRb+K2y1I4c0m1BL7TezMorzaaeqUAL8H1JT0u6S9IIYHxEbE8+swMYn2tjSYskNUpqbGlpSTFNM7PqkmbhHwjMAu6IiHcArwE3Zn8gMu1MOduaImJxRDRERENdXV2KaZqZVZc0C/9WYGtEPJksLyXzi6BZ0gSA5OdLKeZgfUzr3v38YcsuT8BilqLU2vgjYoekLZKmR8QzwDxgXfK6Grgl+bkirRysb1mxehs3LGtiUE0Nbe3t3Hr5TC6tn1jutMz6nbSf3P008E9Jj57ngb8g81fG/ZI+DrwIfCjlHKwP6Hjq9422dt4g8yxAsU/9mlnPpFr4I2I1cERXIjJX/2aHdTz121H04c2nfl34zUrLT+5aRfBTv2a9x4XfKoKf+jXrPR6d0yrGpfUTOW/aOD/1a5YyF36rKH7q1yx9buoxM6syLvxmZlXGhd/MrMq48JuZVRkXfjOzKuPCb2ZWZVz4zcyqjAu/mVmVceE3M6syLvxmZlXGhd/MrMq48JuZVZlUC7+kFyStkbRaUmMSu1nStiS2WtLFaeZgZmad9cbonO+NiJe7xG6PiNt64dhmZtaFm3rMzKpM2oU/gEckPSVpUVb8U5KaJH1P0phcG0paJKlRUmNLS0vKaZqZVY+0C/+7I2IWcBHwSUlzgTuAU4B6YDvwjVwbRsTiiGiIiIa6urqU0zQzqx6pFv6I2Jb8fAl4EDg7Ipoj4lBEtAN3AmendfzGTa38n0eeoXFTa1qHMDPrc1K7uStpBFATEXuS9xcCX5E0ISK2Jx+7DFibxvGvuut3/HZjpuB/89cbmTOtlnuuOSeNQ5mZ9Slp9uoZDzwoqeM490bEw5LukVRPpv3/BeDaUh+4cVPr4aLf4fGNrTRuaqVham2pD2dm1qekVvgj4nngzBzxj6Z1zA6/2dC19+ibcRd+M6t2/bI759xTxxUVNzOrJv2y8DdMrWXOtM5X9nOm1fpq38yMflr4IdOm392ymVm16peFf9bf/qKouJlZNemXhf+Vfe1Fxc3Mqkm/LPxjh+X+Z+WLm5lVk35ZCVd9+aKi4mZm1aRfFn6AE0YN7rQ8ocuymVm16peFf/mqLezYfaBTbPvuAyxftaVMGZmZVY5+WfgfWrOjqLiZWTXpl4X/kjNOKCpuZlZN+mXhXzBr8hFt+hNGDWbBrMllysjMrHL0xpy7ZfHETRewfNUWHlqzg0vOOMFF38ws0W8LP2Su/F3wzcw665dNPWZmlp8Lv5lZlUm1qUfSC8Ae4BBwMCIaJI0FfgycRGYGrg9FxM408zAzszf1xhX/eyOiPiIakuUbgZURcSqwMlk2M7NeUo6mnvnAkuT9EmBBGXIwM6taaffqCeARSQF8JyIWA+MjYnuyfgeZSdmPIGkRsChZ3CvpmZRzzWcckHsS3/JzbkfHuR0d53Z0ypnbibmCiojUjihpYkRsk/QW4FHg08BPI2J01md2RsSY1JI4RpIas5qpKopzOzrO7eg4t6NTibml2tQTEduSny8BDwJnA82SJgAkP19KMwczM+sstcIvaYSk4zreAxcCa4GfAlcnH7saWJFWDmZmdqQ02/jHAw9K6jjOvRHxsKTfA/dL+jjwIvChFHMohcXlTqAbzu3oOLej49yOTsXllmobv5mZVR4/uWtmVmVc+M3MqowLfxZJL0haI2m1pMYkdrOkbUlstaSLy5TbaElLJf1J0npJsyWNlfSopA3Jz7J0i82TW9nPm6TpWcdfLWm3pOsq4bx1k1vZz1uS3/WS/ihpraT7JA2VNFXSk5I2SvqxpLJMZJ0ntx9I2pR13urLlNtfJ3n9UdJ1Sazs37cj8nQb/5uSsYUaIuLlrNjNwN6IuK1ceSV5LAEej4i7kv/ghgM3Aa9ExC2SbgTGRMQNFZLbdVTAeesgaQCwDXgX8Ekq4Lzlye0vKPN5kzQR+C0wIyL2Sbof+DlwMfCTiPiRpP8H/CEi7qiQ3N4DPBQRS3szny65nQ78iEy39QPAw8AnyDyIWjHfN/AVf58g6XhgLvBdgIg4EBG7qIDhL7rJrdLMA56LiBepgPPWRXZulWIgMEzSQDK/yLcD7wM6Cms5z1vX3P6zTHl0dRrwZES8HhEHgX8F/pzK+7658HfRMcTEU8mQER0+JalJ0vfK9GfaVKAF+L6kpyXdlTwb0aPhL8qUG5T/vGX7CHBf8r4Szlu27NygzOctefDyNmAzmYL/KvAUsCspaABbgYmVkFtEPJKs/mpy3m6XNKS3cyPznNIcSbWShpP5C2kylfd9c+Hv4t0RMQu4CPikpLnAHcApQD2ZL9o3ypDXQGAWcEdEvAN4jS6jmkamza4c7Xb5cquE8wZA0vx0KfBA13VlPG9AztzKft6SXzbzyfxSfyswAvhAb+eRS67cJF0FfBF4O/BOYCzQ600pEbEe+DrwCJlmntVkhqTP/kxZv28dXPiz5BpiIiKaI+JQRLQDd5Jpv+ttW4GtEfFksryUTLGthOEvcuZWIeetw0XAqohoTpYr4bx16JRbhZy384FNEdESEW3AT4DzgNFJ8wrAJDL3JSoht3MjYntk7Ae+T5m+bxHx3Yg4KyLmAjuBZ6ms7xvgwn+Y8gwx0fF/WOIyMn/O9aqI2AFskTQ9Cc0D1lEBw1/ky60SzluWK+nclFL285alU24Vct42A+dIGi5JvPl9ewy4IvlMuc5brtzWZxVWkWlDL8v3TZkBKZE0hUz7/r1U1vcNcK+ewySdTOYqH94cYuKrku4h82d3kJkx7Nqs9rrezK8euAsYDDxPpvdHDXA/MIVk+IuIeKVCcvsmlXHeRpApFidHxKtJrJbKOG+5cquU79vfAh8GDgJPA9eQadP/EZmmlKeBq5Ir7ErI7RdAHSAyTSyfiIi9ZcjtcaAWaAM+GxErK+X7ls2F38ysyripx8ysyrjwm5lVGRd+M7Mq48JvZlZlXPjNzKqMC79ZF5IOJSM8rpX0M0mjk/hJkvap86iaC7O2q5cUkj7QZX+93q3QrDsu/GZH2hcR9RFxOvAKmdE8OzyXrOt43Z217koyI0de2ZvJmhUrzTl3zfqDJ4CZhT6UPDH6QeAC4HFJQyPijbSTMzsavuI3yyMZJ38emUfuO5zSpalnThI/l8wYMs8B/wL8We9ma9ZzvuI3O9IwSavJDFGwHng0a91zEZFrdqcryQxnQPJzIbAs1SzNjpKHbDDrQtLeiBiZjKn+S+CBiPimpJPIzPJ0epfPDyAzSulBMsPwisx4LRMiYk/H/nr1H2HWDTf1mOUREa8DnwE+lzUccS7zgKaImBwRJ0XEiWSu9i/rjTzNiuXCb9aNiHgaaOLNnjpd2/g/k6x7sMumy7K2GS5pa9brs72TvVlubuoxM6syvuI3M6syLvxmZlXGhd/MrMq48JuZVRkXfjOzKuPCb2ZWZVz4zcyqzP8HBcfCxRrEO3QAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"9a53ncwAVyPA","colab_type":"code","outputId":"f1026993-7de3-4a19-9460-8c547bf5e041","executionInfo":{"status":"ok","timestamp":1586962290057,"user_tz":-120,"elapsed":46,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":362}},"source":["#See unique real values \n","print(df.PREDICTED.unique())\n","\n","#Check the average value of the predicted labels\n","df.groupby('REAL').mean()"],"execution_count":106,"outputs":[{"output_type":"stream","text":["[68 69 71 70 67 72 80 81 79 78 64 66 62 63 65 76 77 75 88 90 86 89 91 92\n"," 87 61 59 53 52 54]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PREDICTED</th>\n","    </tr>\n","    <tr>\n","      <th>REAL</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>53</th>\n","      <td>52.942857</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>63.852941</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>64.140000</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>64.368421</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>69.314286</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>76.564103</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>79.869565</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>89.789474</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      PREDICTED\n","REAL           \n","53    52.942857\n","64    63.852941\n","65    64.140000\n","67    64.368421\n","71    69.314286\n","78    76.564103\n","81    79.869565\n","92    89.789474"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"id":"ePLVTMv_V0VN","colab_type":"code","outputId":"7a731320-5486-458e-9381-68d263cb64a4","executionInfo":{"status":"ok","timestamp":1586962290058,"user_tz":-120,"elapsed":37,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":382}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","def r2_rmse( g ):\n","    r2 = r2_score( g.REAL, g.PREDICTED)\n","    count = len(g.REAL)\n","    mse = mean_squared_error( g['REAL'], g['PREDICTED'] ) \n","    rmse = np.sqrt( mean_squared_error( g['REAL'], g['PREDICTED'] ) ) \n","    return pd.Series( dict( count = int(count), r2 = r2, rmse = rmse, mse = mse ) )\n","\n","print(\"Global:\", r2_rmse(df))\n","\n","#Statistics over REAL value\n","df.groupby( 'REAL' ).apply( r2_rmse ).reset_index()\n"],"execution_count":107,"outputs":[{"output_type":"stream","text":["Global: count    357.000000\n","r2         0.971334\n","rmse       1.767272\n","mse        3.123249\n","dtype: float64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>REAL</th>\n","      <th>count</th>\n","      <th>r2</th>\n","      <th>rmse</th>\n","      <th>mse</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>53</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>0.478091</td>\n","      <td>0.228571</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>64</td>\n","      <td>68.0</td>\n","      <td>0.0</td>\n","      <td>1.224745</td>\n","      <td>1.500000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65</td>\n","      <td>100.0</td>\n","      <td>0.0</td>\n","      <td>1.624808</td>\n","      <td>2.640000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>67</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>3.276712</td>\n","      <td>10.736842</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>2.035401</td>\n","      <td>4.142857</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>78</td>\n","      <td>39.0</td>\n","      <td>0.0</td>\n","      <td>1.617215</td>\n","      <td>2.615385</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>81</td>\n","      <td>23.0</td>\n","      <td>0.0</td>\n","      <td>1.383128</td>\n","      <td>1.913043</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>92</td>\n","      <td>38.0</td>\n","      <td>0.0</td>\n","      <td>2.544344</td>\n","      <td>6.473684</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   REAL  count   r2      rmse        mse\n","0    53   35.0  0.0  0.478091   0.228571\n","1    64   68.0  0.0  1.224745   1.500000\n","2    65  100.0  0.0  1.624808   2.640000\n","3    67   19.0  0.0  3.276712  10.736842\n","4    71   35.0  0.0  2.035401   4.142857\n","5    78   39.0  0.0  1.617215   2.615385\n","6    81   23.0  0.0  1.383128   1.913043\n","7    92   38.0  0.0  2.544344   6.473684"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"Gcg6abORzxqU","colab_type":"code","colab":{}},"source":["df.to_csv(r'./result.csv', index = False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zt4EUtT4HbVh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}