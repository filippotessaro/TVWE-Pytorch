{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AUTOENCODER-ML-SKLEARN","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"P_FwoC8GviT1","colab_type":"text"},"source":["# WEIGHT ESTIMATION - Research Project"]},{"cell_type":"code","metadata":{"id":"hhxjeABq9ix4","colab_type":"code","outputId":"84fa545c-f572-4ab5-cece-9cc3e3af1c3a","executionInfo":{"status":"ok","timestamp":1582105091203,"user_tz":-60,"elapsed":73067,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDDjBrLjswtyZ4p28Vo67M9H4UcnX66HmXFNf6J=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":514}},"source":["!pip uninstall torch torchvision fastai -y\n","!pip install \\\n","  http://storage.googleapis.com/pytorch-tpu-releases/tf-1.13/torch-1.0.0a0+1d94a2b-cp36-cp36m-linux_x86_64.whl  \\\n","  http://storage.googleapis.com/pytorch-tpu-releases/tf-1.13/torch_xla-0.1+5622d42-cp36-cp36m-linux_x86_64.whl\n","!pip install torchvision==0.2.0 \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Uninstalling torch-1.4.0:\n","  Successfully uninstalled torch-1.4.0\n","Uninstalling torchvision-0.5.0:\n","  Successfully uninstalled torchvision-0.5.0\n","Uninstalling fastai-1.0.60:\n","  Successfully uninstalled fastai-1.0.60\n","Collecting torch==1.0.0a0+1d94a2b\n","\u001b[?25l  Downloading http://storage.googleapis.com/pytorch-tpu-releases/tf-1.13/torch-1.0.0a0+1d94a2b-cp36-cp36m-linux_x86_64.whl (266.4MB)\n","\u001b[K     |████████████████████████████████| 266.4MB 1.3MB/s \n","\u001b[?25hCollecting torch-xla==0.1+5622d42\n","\u001b[?25l  Downloading http://storage.googleapis.com/pytorch-tpu-releases/tf-1.13/torch_xla-0.1+5622d42-cp36-cp36m-linux_x86_64.whl (57.9MB)\n","\u001b[K     |████████████████████████████████| 57.9MB 1.2MB/s \n","\u001b[?25hInstalling collected packages: torch, torch-xla\n","Successfully installed torch-1.0.0a0+1d94a2b torch-xla-0.1+5622d42\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting torchvision==0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/c9/f4eb36734bffd36eb8095247d816cbe6aeca0a2b9218b78678288edfdb92/torchvision-0.2.0-py2.py3-none-any.whl (48kB)\n","\r\u001b[K     |██████▊                         | 10kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.0) (6.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.0) (1.12.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.0) (1.0.0a0+1d94a2b)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.0) (1.17.5)\n","Installing collected packages: torchvision\n","Successfully installed torchvision-0.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y6kUPtM-zmrs","colab_type":"code","outputId":"fec01cc9-f1c9-42cb-c3c6-35a02dd3fce4","executionInfo":{"status":"ok","timestamp":1582105353113,"user_tz":-60,"elapsed":2513,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDDjBrLjswtyZ4p28Vo67M9H4UcnX66HmXFNf6J=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","print(torch.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.0.0a0+1d94a2b\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZxOZswaXv8Pl","colab_type":"code","outputId":"d414c08c-d381-4eef-853a-3a569d3bbeb9","executionInfo":{"status":"ok","timestamp":1590388987609,"user_tz":-120,"elapsed":27814,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qeD00JVfe22S","colab_type":"code","colab":{}},"source":["# import libraries\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import numpy as np\n","from torchvision import datasets\n","from skimage import io, transform\n","from torch.utils.data import DataLoader\n","import time\n","import os\n","#from tensorboardcolab import TensorBoardColab\n","from PIL import Image\n","from torchvision import transforms\n","import logging\n","from datetime import datetime\n","from torch.autograd import Variable\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUa0-vIv7oET","colab_type":"code","outputId":"94e45343-0895-4561-eead-f6ca61b8acd2","executionInfo":{"status":"ok","timestamp":1590221715865,"user_tz":-120,"elapsed":4406,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Get the seconds since epoch\n","secondsSinceEpoch = time.time()\n","# Convert seconds since epoch to struct_time\n","timeObj = time.localtime(secondsSinceEpoch)\n","\n","time = str(timeObj.tm_mday)+ '-' + str(timeObj.tm_mon) +'-'+ str(timeObj.tm_year)+'-'+str(timeObj.tm_hour)+'_'+str(timeObj.tm_min)\n","print(time)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["23-5-2020-8_15\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nfO7vaDhwEPk","colab_type":"code","outputId":"104e0795-bdea-4ec8-8ae8-44b52eee2468","executionInfo":{"status":"ok","timestamp":1590221721546,"user_tz":-120,"elapsed":1549,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Path of Folders\n","content = '/content/drive/My Drive/new-frames/'\n","labels_csv = '/content/drive/My Drive/weights.csv'\n","train_path = content + \"train\"\n","test_path = content + \"test\"\n","validation_path = content + \"validation\"\n","\n","weights=pd.read_csv(labels_csv)\n","weights = weights['WEIGHT'].values\n","\n","print('Start initialization logging file')\n","logging.basicConfig(filename='app_' + time + '.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s')\n","logging.warning('Initialized File')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start initialization logging file\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y4ksS3d6_GS9","colab_type":"text"},"source":["## New KFold Cross Validation\n","This is an improvement of the section before since this one creates dinamically the minibatch for the computatation of a single fold\n"]},{"cell_type":"code","metadata":{"id":"lG5kBo8xCZCa","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","from sklearn.model_selection import train_test_split\n","\n","weights=pd.read_csv(labels_csv)\n","train_IDs, test_IDs = train_test_split(weights, test_size=0.30, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBnEJt1XDwCx","colab_type":"code","outputId":"abd511ba-545e-446e-8746-92860778b72a","executionInfo":{"status":"ok","timestamp":1590221724869,"user_tz":-120,"elapsed":1102,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Check len of IDs\n","print('Train:', len(train_IDs))\n","print('Test:', len(test_IDs))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train: 72\n","Test: 31\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"icvCSDSHDLUl","colab_type":"code","colab":{}},"source":["def generateDatasetIDS(list, root_folder = \"/content/drive/My Drive/frames/\"):\n","  \"\"\"\n","  Return a list with all the image paths relative to those IDs\n","  \"\"\"\n","  test_list = []\n","  for id in list:\n","    #print(\"Id:\", id)\n","    for root, dirs, files in os.walk(root_folder + str(id) ):\n","        for filename in files:\n","            #print(\"\\t\", str(id) + \"/\" + filename)\n","            if('.png' in filename):\n","              add_file = str(id) + \"/\" + filename\n","              test_list.append(add_file)\n","  return test_list\n","\n","\n","class CustomListDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, images_list, df_weights, root_dir,transform = None):\n","        \"\"\"\n","        Args:\n","            images_list(list): list with IDs into the dataset\n","            root_dir(string): directory with all the images\n","            df_weights(pd_dataframe): dataframe with all the weights of the people\n","            transform: trasform operation for images\n","        \"\"\"\n","        self.images_list = images_list\n","        self.root_dir = root_dir\n","        self.df_weights = df_weights\n","        self.df_weights = self.df_weights['WEIGHT'].values\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images_list)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.root_dir, self.images_list[idx])\n","        image = Image.open(img_name)\n","        image = image.convert(mode='RGB')\n","        \n","        if(self.transform is not None):\n","            image = self.transform(image)\n","\n","        frame_name = self.images_list[idx].split(\"/\")\n","        id = int(frame_name[0])\n","        \n","        labels = self.df_weights[id]\n","        labels = np.float(labels)\n","        #print(labels)\n","        #sample = {'image': image, 'labels': labels}\n","        return image, torch.as_tensor(labels)\n","\n","\n","# Training with data augmentation\n","transform = transforms.Compose([\n","    #transforms.RandomHorizontalFlip(),\n","    #transforms.RandomRotation(20),\n","    transforms.ToTensor()\n","])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"30k01YQYRQn1","colab_type":"code","colab":{}},"source":["IMAGE_SIZE = 150 * 150\n","IMAGE_WIDTH = IMAGE_HEIGHT = 150\n","\n","class AutoEncoder(nn.Module):\n","    \n","    def __init__(self, code_size):\n","        super().__init__()\n","        self.code_size = code_size\n","        \n","        # Encoder specification\n","        self.enc_cnn_1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.enc_cnn_2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.enc_linear_1 = nn.Linear(34 * 34 * 20, 150)\n","        #self.enc_linear_12 = nn.Linear(100, 150)\n","        self.enc_linear_2 = nn.Linear(150, self.code_size)\n","        \n","        # Decoder specification\n","        self.dec_linear_1 = nn.Linear(self.code_size, 150)\n","        self.dec_linear_2 = nn.Linear(150, IMAGE_SIZE)\n","        \n","    def forward(self, images):\n","        code = self.encode(images)\n","        out = self.decode(code)\n","        return out, code\n","    \n","    def encode(self, images):\n","        code = self.enc_cnn_1(images)\n","        code = F.selu(F.max_pool2d(code, 2))\n","        \n","        code = self.enc_cnn_2(code)\n","        code = F.selu(F.max_pool2d(code, 2))\n","        #print(\"first \\t\", code.shape)\n","        code = code.view([images.size(0), -1])\n","        #print(\"first \\t\", code.shape)\n","        code = F.selu(self.enc_linear_1(code))\n","        #code = F.selu(self.enc_linear_12(code))\n","\n","        code = self.enc_linear_2(code)\n","        return code\n","    \n","    def decode(self, code):\n","        out = F.selu(self.dec_linear_1(code))\n","        #out = torch.sigmoid(self.dec_linear_12(out))\n","        out = torch.sigmoid(self.dec_linear_2(out))\n","        out = out.view([code.size(0), 1, IMAGE_WIDTH, IMAGE_HEIGHT])\n","        return out\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pswgi4Pb9Ml6","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","from torchsummary import summary\n","\n","class conv2DBatchNormRelu(nn.Module):\n","    def __init__(\n","            self,\n","            in_channels,\n","            n_filters,\n","            k_size,\n","            stride,\n","            padding,\n","            bias=True,\n","            dilation=1,\n","            with_bn=True,\n","    ):\n","        super(conv2DBatchNormRelu, self).__init__()\n","\n","        conv_mod = nn.Conv2d(int(in_channels),\n","                             int(n_filters),\n","                             kernel_size=k_size,\n","                             padding=padding,\n","                             stride=stride,\n","                             bias=bias,\n","                             dilation=dilation, )\n","\n","        if with_bn:\n","            self.cbr_unit = nn.Sequential(conv_mod,\n","                                          nn.BatchNorm2d(int(n_filters)),\n","                                          nn.ReLU(inplace=True))\n","        else:\n","            self.cbr_unit = nn.Sequential(conv_mod, nn.ReLU(inplace=True))\n","\n","    def forward(self, inputs):\n","        outputs = self.cbr_unit(inputs)\n","        return outputs\n","\n","\n","class segnetDown2(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(segnetDown2, self).__init__()\n","        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n","        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n","\n","    def forward(self, inputs):\n","        outputs = self.conv1(inputs)\n","        outputs = self.conv2(outputs)\n","        unpooled_shape = outputs.size()\n","        outputs, indices = self.maxpool_with_argmax(outputs)\n","        return outputs, indices, unpooled_shape\n","\n","\n","class segnetDown3(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(segnetDown3, self).__init__()\n","        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n","        self.conv3 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n","        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n","\n","    def forward(self, inputs):\n","        outputs = self.conv1(inputs)\n","        outputs = self.conv2(outputs)\n","        outputs = self.conv3(outputs)\n","        unpooled_shape = outputs.size()\n","        outputs, indices = self.maxpool_with_argmax(outputs)\n","        return outputs, indices, unpooled_shape\n","\n","\n","class segnetUp2(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(segnetUp2, self).__init__()\n","        self.unpool = nn.MaxUnpool2d(2, 2)\n","        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n","        self.conv2 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","\n","    def forward(self, inputs, indices, output_shape):\n","        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n","        outputs = self.conv1(outputs)\n","        outputs = self.conv2(outputs)\n","        return outputs\n","\n","\n","class segnetUp3(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(segnetUp3, self).__init__()\n","        self.unpool = nn.MaxUnpool2d(2, 2)\n","        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n","        self.conv2 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n","        self.conv3 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","\n","    def forward(self, inputs, indices, output_shape):\n","        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n","        outputs = self.conv1(outputs)\n","        outputs = self.conv2(outputs)\n","        outputs = self.conv3(outputs)\n","        return outputs\n","\n","\n","class SegNet(nn.Module):\n","    def __init__(self, n_classes=3, in_channels=3, is_unpooling=True):\n","        super(SegNet, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.is_unpooling = is_unpooling\n","\n","        self.down1 = segnetDown2(self.in_channels, 64)\n","        self.down2 = segnetDown2(64, 128)\n","        self.down3 = segnetDown3(128, 256)\n","        self.down4 = segnetDown3(256, 512)\n","        self.down5 = segnetDown3(512, 512)\n","\n","        self.up5 = segnetUp3(512, 512)\n","        self.up4 = segnetUp3(512, 256)\n","        self.up3 = segnetUp3(256, 128)\n","        self.up2 = segnetUp2(128, 64)\n","        self.up1 = segnetUp2(64, n_classes)\n","\n","    def forward(self, inputs):\n","\n","        down1, indices_1, unpool_shape1 = self.down1(inputs)\n","        down2, indices_2, unpool_shape2 = self.down2(down1)\n","        down3, indices_3, unpool_shape3 = self.down3(down2)\n","        down4, indices_4, unpool_shape4 = self.down4(down3)\n","        down5, indices_5, unpool_shape5 = self.down5(down4)\n","\n","        up5 = self.up5(down5, indices_5, unpool_shape5)\n","        up4 = self.up4(up5, indices_4, unpool_shape4)\n","        up3 = self.up3(up4, indices_3, unpool_shape3)\n","        up2 = self.up2(up3, indices_2, unpool_shape2)\n","        up1 = self.up1(up2, indices_1, unpool_shape1)\n","\n","        return up1\n","\n","\n","    def encode(self, inputs):\n","        down1, indices_1, unpool_shape1 = self.down1(inputs)\n","        down2, indices_2, unpool_shape2 = self.down2(down1)\n","        down3, indices_3, unpool_shape3 = self.down3(down2)\n","        down4, indices_4, unpool_shape4 = self.down4(down3)\n","        down5, indices_5, unpool_shape5 = self.down5(down4)\n","        \n","        return down5\n","\n","    def init_vgg16_params(self, vgg16):\n","        blocks = [self.down1, self.down2, self.down3, self.down4, self.down5]\n","\n","        ranges = [[0, 4], [5, 9], [10, 16], [17, 23], [24, 29]]\n","        features = list(vgg16.features.children())\n","\n","        vgg_layers = []\n","        for _layer in features:\n","            if isinstance(_layer, nn.Conv2d):\n","                vgg_layers.append(_layer)\n","\n","        merged_layers = []\n","        for idx, conv_block in enumerate(blocks):\n","            if idx < 2:\n","                units = [conv_block.conv1.cbr_unit, conv_block.conv2.cbr_unit]\n","            else:\n","                units = [\n","                    conv_block.conv1.cbr_unit,\n","                    conv_block.conv2.cbr_unit,\n","                    conv_block.conv3.cbr_unit,\n","                ]\n","            for _unit in units:\n","                for _layer in _unit:\n","                    if isinstance(_layer, nn.Conv2d):\n","                        merged_layers.append(_layer)\n","\n","        assert len(vgg_layers) == len(merged_layers)\n","\n","        for l1, l2 in zip(vgg_layers, merged_layers):\n","            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n","                assert l1.weight.size() == l2.weight.size()\n","                assert l1.bias.size() == l2.bias.size()\n","                l2.weight.data = l1.weight.data\n","                l2.bias.data = l1.bias.data\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTwbfFh5A9eP","colab_type":"code","outputId":"510bf061-a9a5-4be7-ff2a-52a7d3bd7492","executionInfo":{"status":"ok","timestamp":1590429211854,"user_tz":-120,"elapsed":17613,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torchvision.models as models\n","autoencoder = SegNet()\n","checkpoint = torch.load(\"/content/drive/My Drive/model/conv_autoencoder_test1.pt\")\n","autoencoder.load_state_dict(checkpoint)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"7r7U0HA84l1e","colab_type":"text"},"source":["###SVM Integration Part "]},{"cell_type":"code","metadata":{"id":"UgrUvQGv_Xew","colab_type":"code","outputId":"f71d826b-635d-41b9-ca8c-4860489a9c81","executionInfo":{"status":"error","timestamp":1590237351623,"user_tz":-120,"elapsed":11853209,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import copy\n","import time\n","from sklearn.model_selection import KFold\n","from tqdm import tqdm\n","import random\n","from sklearn.svm import SVR\n","import numpy as np\n","from sklearn import metrics\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","\n","def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_torch(123)\n","device='cuda:0'\n","num_epochs = 5\n","splits = 5\n","batch_size = 64\n","\n","kf = KFold(n_splits=splits, shuffle=True)\n","fold = 1\n","\n","#clf = KNeighborsRegressor(n_neighbors=5)\n","#clf = SVR(gamma='scale', C=1.0, epsilon=0.2)\n","#clf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n","#clf = SVR(kernel='linear', C=64, gamma='auto')\n","#clf = SVR(kernel='poly', C=50, gamma='auto', degree=6, epsilon=.1,coef0=1)\n","\n","clf = RandomForestRegressor(max_depth=5, random_state=10)\n","\n","for train_index, test_index in kf.split(train_IDs):\n","  #print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n","  #feature_extractor.cuda()\n","  train_images_list = generateDatasetIDS(train_index,\"/content/drive/My Drive/frames/\")\n","  train = CustomListDataset(images_list = train_images_list, df_weights = weights, root_dir=\"/content/drive/My Drive/frames/\", transform = transform)\n","  trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n","\n","  test_images_list = generateDatasetIDS(test_index,\"/content/drive/My Drive/frames/\")\n","  test = CustomListDataset(images_list = test_images_list, df_weights = weights, root_dir=\"/content/drive/My Drive/frames/\", transform = transform)\n","  validationloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n","\n","  print(f'Len Train (in batch): {len(trainloader)}')\n","  print(f'Len validation (in batch): {len(validationloader)}')\n","\n","\n","  print(f'Fold {fold}')\n","  fold += 1\n","\n","  with torch.no_grad():\n","    for epoch in range(num_epochs):\n","        start_time = time.time()\n","        \n","        avg_loss = 0.\n","        cumulative_loss = 0.\n","        samples = 0\n","        for i, (x_batch, y_batch) in enumerate(trainloader):\n","            featrues_x = autoencoder.encode(x_batch)\n","            #print(features_array.shape)\n","            #featrues_x=featrues_x.view(featrues_x.size(0),featrues_x.size(1))\n","            featrues_x = featrues_x.mean(3)\n","            featrues_x = featrues_x.mean(2)\n","\n","            print(featrues_x.shape)   \n","            #featrues_x.size(0)\n","            features_array = np.asarray(featrues_x)\n","            print(features_array.shape)\n","            y_batch = y_batch.view(-1,1)\n","            y_batch = np.asarray(y_batch)\n","            #print('\\t Training Batch number:', i)\n","            clf.fit(features_array, y_batch.ravel()) \n","            prediction = clf.predict(features_array)\n","            cumulative_loss += mean_squared_error(y_batch.ravel(), prediction)\n","        print('\\t TRAIN EPOCH MEAN MSE:',cumulative_loss/len(trainloader))\n","    cumulative_loss = 0.\n","    print('\\n \\tStart Testing')\n","    for i, (x_batch, y_batch) in enumerate(validationloader):\n","        featrues_x = autoencoder.encode(x_batch)\n","        featrues_x = featrues_x.mean(3)\n","        featrues_x = featrues_x.mean(2)\n","        features_array = np.asarray(featrues_x)\n","        y_batch = y_batch.view(-1,1)\n","        y_batch = np.asarray(y_batch)\n","        y_pred = clf.predict(features_array)\n","        cumulative_loss += mean_squared_error(y_batch.ravel(), y_pred)\n","    print('\\t VALIDATION EPOCH MEAN MSE:',cumulative_loss/len(validationloader))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Len Train (in batch): 27\n","Len validation (in batch): 9\n","Fold 1\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([50, 512])\n","(50, 512)\n","\t TRAIN EPOCH MEAN MSE: 25.697742037321\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([50, 512])\n","(50, 512)\n","\t TRAIN EPOCH MEAN MSE: 25.95655023928701\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([50, 512])\n","(50, 512)\n","\t TRAIN EPOCH MEAN MSE: 25.30324716687679\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([50, 512])\n","(50, 512)\n","\t TRAIN EPOCH MEAN MSE: 24.42968338578092\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([50, 512])\n","(50, 512)\n","\t TRAIN EPOCH MEAN MSE: 24.71464753663689\n","\n"," \tStart Testing\n","\t VALIDATION EPOCH MEAN MSE: 212.72685936146038\n","Len Train (in batch): 29\n","Len validation (in batch): 7\n","Fold 2\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([38, 512])\n","(38, 512)\n","\t TRAIN EPOCH MEAN MSE: 22.308108298500056\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([38, 512])\n","(38, 512)\n","\t TRAIN EPOCH MEAN MSE: 22.655070558693975\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([38, 512])\n","(38, 512)\n","\t TRAIN EPOCH MEAN MSE: 21.422627674090243\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([38, 512])\n","(38, 512)\n","\t TRAIN EPOCH MEAN MSE: 22.176506930203658\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([38, 512])\n","(38, 512)\n","\t TRAIN EPOCH MEAN MSE: 22.25126068583557\n","\n"," \tStart Testing\n","\t VALIDATION EPOCH MEAN MSE: 234.96099715684053\n","Len Train (in batch): 29\n","Len validation (in batch): 7\n","Fold 3\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([35, 512])\n","(35, 512)\n","\t TRAIN EPOCH MEAN MSE: 26.786094442186172\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([35, 512])\n","(35, 512)\n","\t TRAIN EPOCH MEAN MSE: 26.833118406426507\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([35, 512])\n","(35, 512)\n","\t TRAIN EPOCH MEAN MSE: 27.781099698819524\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([35, 512])\n","(35, 512)\n","\t TRAIN EPOCH MEAN MSE: 27.35313289341203\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([35, 512])\n","(35, 512)\n","\t TRAIN EPOCH MEAN MSE: 27.84694519867214\n","\n"," \tStart Testing\n","\t VALIDATION EPOCH MEAN MSE: 180.81021496345133\n","Len Train (in batch): 29\n","Len validation (in batch): 8\n","Fold 4\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([7, 512])\n","(7, 512)\n","\t TRAIN EPOCH MEAN MSE: 26.946961936605664\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([7, 512])\n","(7, 512)\n","\t TRAIN EPOCH MEAN MSE: 26.791233486690803\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([7, 512])\n","(7, 512)\n","\t TRAIN EPOCH MEAN MSE: 25.655343382101726\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([7, 512])\n","(7, 512)\n","\t TRAIN EPOCH MEAN MSE: 27.260836714864983\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([7, 512])\n","(7, 512)\n","\t TRAIN EPOCH MEAN MSE: 26.01455954354538\n","\n"," \tStart Testing\n","\t VALIDATION EPOCH MEAN MSE: 377.2393495703125\n","Len Train (in batch): 29\n","Len validation (in batch): 7\n","Fold 5\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([46, 512])\n","(46, 512)\n","\t TRAIN EPOCH MEAN MSE: 29.904418088330466\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([46, 512])\n","(46, 512)\n","\t TRAIN EPOCH MEAN MSE: 30.696625650615417\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([46, 512])\n","(46, 512)\n","\t TRAIN EPOCH MEAN MSE: 30.560911158560977\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n","torch.Size([64, 512])\n","(64, 512)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-22317864a754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mfeatrues_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;31m#print(features_array.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m#featrues_x=featrues_x.view(featrues_x.size(0),featrues_x.size(1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-5ba0137f0a42>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mdown1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpool_shape1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mdown2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpool_shape2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mdown3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpool_shape3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mdown4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpool_shape4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mdown5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpool_shape5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-5ba0137f0a42>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0munpooled_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool_with_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-5ba0137f0a42>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbr_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1922\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m     )\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"RUn9UEZVdIGO","colab_type":"code","colab":{}},"source":["'''#TEST AREA\n","import copy\n","import time\n","from sklearn.model_selection import KFold\n","from tqdm import tqdm\n","import random\n","from sklearn.svm import SVR\n","import numpy as np\n","from sklearn import metrics\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor\n","\n","\n","def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_torch(123)\n","device='cuda:0'\n","num_epochs = 10\n","splits = 5\n","batch_size = 64\n","\n","kf = KFold(n_splits=splits, shuffle=True)\n","fold = 1\n","\n","for train_index, test_index in kf.split(train_IDs):\n","  train_images_list = generateDatasetIDS(train_index,\"/content/drive/My Drive/frames/\")\n","  train = CustomListDataset(images_list = train_images_list, df_weights = weights, root_dir=\"/content/drive/My Drive/frames/\", transform = transform)\n","  trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=False)\n","\n","  test_images_list = generateDatasetIDS(test_index,\"/content/drive/My Drive/frames/\")\n","  test = CustomListDataset(images_list = test_images_list, df_weights = weights, root_dir=\"/content/drive/My Drive/frames/\", transform = transform)\n","  validationloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=False)\n","\n","  print(f'Len Train (in batch): {len(trainloader)}')\n","  print(f'Len validation (in batch): {len(validationloader)}')\n","\n","\n","  print(f'Fold {fold}')\n","  fold += 1\n","\n","  with torch.no_grad():\n","    for epoch in range(num_epochs):\n","        start_time = time.time()\n","        \n","        for i, (x_batch, y_batch) in enumerate(trainloader):\n","            _, featrues_x = autoencoder(Variable(x_batch))\n","            featrues_x=featrues_x.view(featrues_x.size(0),16)\n","            features_array = np.asarray(featrues_x)\n","            if(i==0):\n","              print(\"Shape features_x:\", featrues_x.shape)\n","              print(\"features array: \", features_array)\n","\n","            \n","            y_batch = y_batch.view(-1,1)\n","            y_batch = np.asarray(y_batch)\n","            print('\\t Training Batch number:', i)\n","            #clf.fit(features_array, y_batch.ravel()) \n","            #prediction = clf.predict(features_array)\n","            #print('\\t Validation summed MSE:',mean_squared_error(y_batch.ravel(), prediction))'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7YFalulWxEO","colab_type":"code","outputId":"f5d4405e-1afb-43a6-8772-b21e57122011","executionInfo":{"status":"ok","timestamp":1582114939892,"user_tz":-60,"elapsed":8150,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDDjBrLjswtyZ4p28Vo67M9H4UcnX66HmXFNf6J=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":330}},"source":["import numpy as np\n","import pandas as pd\n","\n","\n","# Take only real images\n","test_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","\n","TEST_images_list = generateDatasetIDS(test_IDs.ID,\"/content/drive/My Drive/frames/\")\n","TEST = CustomListDataset(images_list = TEST_images_list, df_weights = weights, root_dir=\"/content/drive/My Drive/frames/\", transform = test_transform)\n","testLoader = torch.utils.data.DataLoader(TEST, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n","\n","predicted_label = list()\n","real_label = list()\n","mse_list = list()\n","\n","cum_mse = 0.\n","with torch.no_grad():\n","  print('Start Testing')\n","  for i, (x_batch, y_batch) in enumerate(testLoader):\n","      _, featrues_x = autoencoder(Variable(x_batch))\n","      featrues_x=featrues_x.view(featrues_x.size(0),16)\n","      features_array = np.asarray(featrues_x)\n","      y_batch = y_batch.view(-1,1)\n","      y_batch = np.asarray(y_batch)\n","      y_pred = clf.predict(features_array)\n","      mse = mean_squared_error(y_batch.ravel(), y_pred)\n","      cum_mse += mse\n","      predicted_label.extend(y_pred)\n","      real_label.extend(y_batch.ravel())\n","\n","print('Average Value MSE wrt batch:', cum_mse/len(testLoader))\n","\n","predicted_label = np.array(predicted_label,dtype=int)\n","\n","df = pd.DataFrame({'REAL': np.asarray(real_label), 'PREDICTED':np.asarray(predicted_label)})\n","df.plot('REAL', 'PREDICTED', kind='scatter')\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start Testing\n","Average Value MSE wrt batch: 125.37159943580627\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f3ef45bed30>"]},"metadata":{"tags":[]},"execution_count":34},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngzkAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"7dOOMSAHAptK","colab_type":"code","outputId":"1306ddd8-8942-4d2c-ed95-52ff9671e1ad","executionInfo":{"status":"ok","timestamp":1582114939892,"user_tz":-60,"elapsed":8137,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDDjBrLjswtyZ4p28Vo67M9H4UcnX66HmXFNf6J=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":686}},"source":["#See unique real values \n","print(df.PREDICTED.unique())\n","\n","#Check the average value of the predicted labels\n","df.groupby('REAL').mean()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[70 64 80 72 71 82 66 77 67 68 63 69 74 65 75 78 73 76 60 62 79 59 61 81]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PREDICTED</th>\n","    </tr>\n","    <tr>\n","      <th>REAL</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>53.0</th>\n","      <td>69.685714</td>\n","    </tr>\n","    <tr>\n","      <th>56.0</th>\n","      <td>70.626263</td>\n","    </tr>\n","    <tr>\n","      <th>57.0</th>\n","      <td>71.135593</td>\n","    </tr>\n","    <tr>\n","      <th>64.0</th>\n","      <td>71.279412</td>\n","    </tr>\n","    <tr>\n","      <th>65.0</th>\n","      <td>69.560000</td>\n","    </tr>\n","    <tr>\n","      <th>66.0</th>\n","      <td>70.014706</td>\n","    </tr>\n","    <tr>\n","      <th>67.0</th>\n","      <td>69.842105</td>\n","    </tr>\n","    <tr>\n","      <th>69.0</th>\n","      <td>71.565217</td>\n","    </tr>\n","    <tr>\n","      <th>70.0</th>\n","      <td>70.388489</td>\n","    </tr>\n","    <tr>\n","      <th>71.0</th>\n","      <td>70.714286</td>\n","    </tr>\n","    <tr>\n","      <th>72.0</th>\n","      <td>71.039216</td>\n","    </tr>\n","    <tr>\n","      <th>73.0</th>\n","      <td>69.777778</td>\n","    </tr>\n","    <tr>\n","      <th>74.0</th>\n","      <td>71.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75.0</th>\n","      <td>73.026316</td>\n","    </tr>\n","    <tr>\n","      <th>78.0</th>\n","      <td>70.216216</td>\n","    </tr>\n","    <tr>\n","      <th>81.0</th>\n","      <td>68.956522</td>\n","    </tr>\n","    <tr>\n","      <th>83.0</th>\n","      <td>70.451613</td>\n","    </tr>\n","    <tr>\n","      <th>92.0</th>\n","      <td>69.342105</td>\n","    </tr>\n","    <tr>\n","      <th>100.0</th>\n","      <td>70.615385</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PREDICTED\n","REAL            \n","53.0   69.685714\n","56.0   70.626263\n","57.0   71.135593\n","64.0   71.279412\n","65.0   69.560000\n","66.0   70.014706\n","67.0   69.842105\n","69.0   71.565217\n","70.0   70.388489\n","71.0   70.714286\n","72.0   71.039216\n","73.0   69.777778\n","74.0   71.000000\n","75.0   73.026316\n","78.0   70.216216\n","81.0   68.956522\n","83.0   70.451613\n","92.0   69.342105\n","100.0  70.615385"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"ww23fU6mAqf7","colab_type":"code","outputId":"ff27f35e-11aa-4603-ba1d-dc9e9013d7ba","executionInfo":{"status":"ok","timestamp":1582114939893,"user_tz":-60,"elapsed":8129,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDDjBrLjswtyZ4p28Vo67M9H4UcnX66HmXFNf6J=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":723}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","def r2_rmse( g ):\n","    r2 = r2_score( g.REAL, g.PREDICTED)\n","    count = len(g.REAL)\n","    mse = mean_squared_error( g['REAL'], g['PREDICTED'] ) \n","    rmse = np.sqrt( mean_squared_error( g['REAL'], g['PREDICTED'] ) ) \n","    return pd.Series( dict( count = int(count), r2 = r2, rmse = rmse, mse = mse ) )\n","\n","print(\"Global:\", r2_rmse(df))\n","\n","#Statistics over REAL value\n","df.groupby( 'REAL' ).apply( r2_rmse ).reset_index()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Global: count    991.000000\n","r2        -0.210598\n","rmse      11.152597\n","mse      124.380424\n","dtype: float64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>REAL</th>\n","      <th>count</th>\n","      <th>r2</th>\n","      <th>rmse</th>\n","      <th>mse</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>53.0</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>16.838731</td>\n","      <td>283.542857</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>56.0</td>\n","      <td>99.0</td>\n","      <td>0.0</td>\n","      <td>15.486064</td>\n","      <td>239.818182</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>57.0</td>\n","      <td>59.0</td>\n","      <td>0.0</td>\n","      <td>14.936022</td>\n","      <td>223.084746</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>64.0</td>\n","      <td>68.0</td>\n","      <td>0.0</td>\n","      <td>7.980675</td>\n","      <td>63.691176</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>65.0</td>\n","      <td>100.0</td>\n","      <td>0.0</td>\n","      <td>5.996666</td>\n","      <td>35.960000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>66.0</td>\n","      <td>68.0</td>\n","      <td>0.0</td>\n","      <td>5.489294</td>\n","      <td>30.132353</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>67.0</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>4.834089</td>\n","      <td>23.368421</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>69.0</td>\n","      <td>23.0</td>\n","      <td>0.0</td>\n","      <td>6.537517</td>\n","      <td>42.739130</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>70.0</td>\n","      <td>139.0</td>\n","      <td>0.0</td>\n","      <td>4.558177</td>\n","      <td>20.776978</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>71.0</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>4.678217</td>\n","      <td>21.885714</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>72.0</td>\n","      <td>51.0</td>\n","      <td>0.0</td>\n","      <td>2.524391</td>\n","      <td>6.372549</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>73.0</td>\n","      <td>45.0</td>\n","      <td>0.0</td>\n","      <td>4.509250</td>\n","      <td>20.333333</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>74.0</td>\n","      <td>20.0</td>\n","      <td>0.0</td>\n","      <td>5.779273</td>\n","      <td>33.400000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>75.0</td>\n","      <td>38.0</td>\n","      <td>0.0</td>\n","      <td>5.588993</td>\n","      <td>31.236842</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>78.0</td>\n","      <td>74.0</td>\n","      <td>0.0</td>\n","      <td>8.986476</td>\n","      <td>80.756757</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>81.0</td>\n","      <td>23.0</td>\n","      <td>0.0</td>\n","      <td>12.784161</td>\n","      <td>163.434783</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>83.0</td>\n","      <td>31.0</td>\n","      <td>0.0</td>\n","      <td>13.487150</td>\n","      <td>181.903226</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>92.0</td>\n","      <td>38.0</td>\n","      <td>0.0</td>\n","      <td>22.927230</td>\n","      <td>525.657895</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>100.0</td>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>29.698485</td>\n","      <td>882.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     REAL  count   r2       rmse         mse\n","0    53.0   35.0  0.0  16.838731  283.542857\n","1    56.0   99.0  0.0  15.486064  239.818182\n","2    57.0   59.0  0.0  14.936022  223.084746\n","3    64.0   68.0  0.0   7.980675   63.691176\n","4    65.0  100.0  0.0   5.996666   35.960000\n","5    66.0   68.0  0.0   5.489294   30.132353\n","6    67.0   19.0  0.0   4.834089   23.368421\n","7    69.0   23.0  0.0   6.537517   42.739130\n","8    70.0  139.0  0.0   4.558177   20.776978\n","9    71.0   35.0  0.0   4.678217   21.885714\n","10   72.0   51.0  0.0   2.524391    6.372549\n","11   73.0   45.0  0.0   4.509250   20.333333\n","12   74.0   20.0  0.0   5.779273   33.400000\n","13   75.0   38.0  0.0   5.588993   31.236842\n","14   78.0   74.0  0.0   8.986476   80.756757\n","15   81.0   23.0  0.0  12.784161  163.434783\n","16   83.0   31.0  0.0  13.487150  181.903226\n","17   92.0   38.0  0.0  22.927230  525.657895\n","18  100.0   26.0  0.0  29.698485  882.000000"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"k_zG9XwyiZhz","colab_type":"text"},"source":["# FULLY CONNECTED + AUTOENCODER"]},{"cell_type":"markdown","metadata":{"id":"8YppBqnwjlrP","colab_type":"text"},"source":["## fully connected model"]},{"cell_type":"code","metadata":{"id":"mfDHWW5jkiDG","colab_type":"code","outputId":"c785cade-13f7-4920-d741-c2629c8399a8","executionInfo":{"status":"ok","timestamp":1590507225414,"user_tz":-120,"elapsed":21826,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oYVC8i9Slp8l","colab_type":"code","outputId":"8964f825-673c-44ac-b04e-fddb90beca9c","executionInfo":{"status":"ok","timestamp":1590507225415,"user_tz":-120,"elapsed":5665,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# import libraries\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import numpy as np\n","from torchvision import datasets\n","from skimage import io, transform\n","from torch.utils.data import DataLoader\n","import time\n","import os\n","from PIL import Image\n","from torchvision import transforms\n","import logging\n","from datetime import datetime\n","import copy\n","import time\n","from sklearn.model_selection import KFold\n","from tqdm import tqdm\n","import random\n","import os\n","from sklearn.model_selection import train_test_split\n","\n","# Path of Folders\n","content = '/content/drive/My Drive/datasets/DepthData/images/'\n","labels_csv = '/content/drive/My Drive/datasets/DepthData/labels.csv'\n","labels_train_csv = '/content/drive/My Drive/datasets/DepthData/labels.train.csv'\n","labels_test_csv = '/content/drive/My Drive/datasets/DepthData/labels.test.csv'\n","file_test_labels = '/content/drive/My Drive/risultati-datasets/atutoenc_fully_256_nodrop.csv'\n","\n","# weights=pd.read_csv(labels_csv)\n","# weights = weights['WEIGHT'].values\n","\n","print('Start initialization logging file')\n","logging.basicConfig(filename='app_' + str(time) + '.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s')\n","logging.warning('Initialized File')\n","\n","# Instantiate visualizer\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# default `log_dir` is \"runs\" - we'll be more specific here\n","writer = SummaryWriter('runs/Efficient-Net')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Start initialization logging file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"grK-UJ5xmmGy","colab_type":"code","outputId":"32239ac4-2201-47f0-8130-b6ceeb4a1e2a","executionInfo":{"status":"ok","timestamp":1590507227569,"user_tz":-120,"elapsed":6500,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["weights=pd.read_csv(labels_csv)\n","#train_IDs, test_IDs = train_test_split(weights, test_size=0.1, random_state=42)\n","train_IDs = pd.read_csv(labels_train_csv)\n","test_IDs = pd.read_csv(labels_test_csv)\n","\n","# Check len of IDs\n","print('Train:', len(train_IDs))\n","print('Test:', len(test_IDs))\n","\n","print(train_IDs)\n","\n","print(test_IDs)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Train: 94\n","Test: 9\n","     ID  WEIGHT\n","0     1      98\n","1     2      65\n","2     3      75\n","3     5      62\n","4     6      76\n","..  ...     ...\n","89   98      70\n","90   99      65\n","91  100      78\n","92  101      55\n","93  102      65\n","\n","[94 rows x 2 columns]\n","   ID  WEIGHT\n","0   0      65\n","1  36      67\n","2  58      70\n","3  81      73\n","4   4      74\n","5  21      75\n","6  35      77\n","7  48      78\n","8  14      93\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YcEBAHZS9U8w","colab_type":"code","outputId":"7b9c3db8-83cc-4335-d3fd-c5f6abdd5a6c","executionInfo":{"status":"ok","timestamp":1590507246229,"user_tz":-120,"elapsed":23261,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch.nn as nn\n","from torchsummary import summary\n","\n","class conv2DBatchNormRelu(nn.Module):\n","    def __init__(\n","            self,\n","            in_channels,\n","            n_filters,\n","            k_size,\n","            stride,\n","            padding,\n","            bias=True,\n","            dilation=1,\n","            with_bn=True,\n","    ):\n","        super(conv2DBatchNormRelu, self).__init__()\n","\n","        conv_mod = nn.Conv2d(int(in_channels),\n","                             int(n_filters),\n","                             kernel_size=k_size,\n","                             padding=padding,\n","                             stride=stride,\n","                             bias=bias,\n","                             dilation=dilation, )\n","\n","        if with_bn:\n","            self.cbr_unit = nn.Sequential(conv_mod,\n","                                          nn.BatchNorm2d(int(n_filters)),\n","                                          nn.ReLU(inplace=True))\n","        else:\n","            self.cbr_unit = nn.Sequential(conv_mod, nn.ReLU(inplace=True))\n","\n","    def forward(self, inputs):\n","        outputs = self.cbr_unit(inputs)\n","        return outputs\n","\n","\n","class segnetDown2(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(segnetDown2, self).__init__()\n","        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n","        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n","\n","    def forward(self, inputs):\n","        outputs = self.conv1(inputs)\n","        outputs = self.conv2(outputs)\n","        unpooled_shape = outputs.size()\n","        outputs, indices = self.maxpool_with_argmax(outputs)\n","        return outputs, indices, unpooled_shape\n","\n","\n","class segnetDown3(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(segnetDown3, self).__init__()\n","        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n","        self.conv3 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n","        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n","\n","    def forward(self, inputs):\n","        outputs = self.conv1(inputs)\n","        outputs = self.conv2(outputs)\n","        outputs = self.conv3(outputs)\n","        unpooled_shape = outputs.size()\n","        outputs, indices = self.maxpool_with_argmax(outputs)\n","        return outputs, indices, unpooled_shape\n","\n","\n","class segnetUp2(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(segnetUp2, self).__init__()\n","        self.unpool = nn.MaxUnpool2d(2, 2)\n","        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n","        self.conv2 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","\n","    def forward(self, inputs, indices, output_shape):\n","        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n","        outputs = self.conv1(outputs)\n","        outputs = self.conv2(outputs)\n","        return outputs\n","\n","\n","class segnetUp3(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(segnetUp3, self).__init__()\n","        self.unpool = nn.MaxUnpool2d(2, 2)\n","        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n","        self.conv2 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n","        self.conv3 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","\n","    def forward(self, inputs, indices, output_shape):\n","        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n","        outputs = self.conv1(outputs)\n","        outputs = self.conv2(outputs)\n","        outputs = self.conv3(outputs)\n","        return outputs\n","\n","\n","class SegNet(nn.Module):\n","    def __init__(self, n_classes=3, in_channels=3, is_unpooling=True):\n","        super(SegNet, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.is_unpooling = is_unpooling\n","\n","        self.down1 = segnetDown2(self.in_channels, 64)\n","        self.down2 = segnetDown2(64, 128)\n","        self.down3 = segnetDown3(128, 256)\n","        self.down4 = segnetDown3(256, 512)\n","        self.down5 = segnetDown3(512, 512)\n","\n","        self.up5 = segnetUp3(512, 512)\n","        self.up4 = segnetUp3(512, 256)\n","        self.up3 = segnetUp3(256, 128)\n","        self.up2 = segnetUp2(128, 64)\n","        self.up1 = segnetUp2(64, n_classes)\n","\n","    def forward(self, inputs):\n","\n","        down1, indices_1, unpool_shape1 = self.down1(inputs)\n","        down2, indices_2, unpool_shape2 = self.down2(down1)\n","        down3, indices_3, unpool_shape3 = self.down3(down2)\n","        down4, indices_4, unpool_shape4 = self.down4(down3)\n","        down5, indices_5, unpool_shape5 = self.down5(down4)\n","\n","        up5 = self.up5(down5, indices_5, unpool_shape5)\n","        up4 = self.up4(up5, indices_4, unpool_shape4)\n","        up3 = self.up3(up4, indices_3, unpool_shape3)\n","        up2 = self.up2(up3, indices_2, unpool_shape2)\n","        up1 = self.up1(up2, indices_1, unpool_shape1)\n","\n","        return up1\n","\n","\n","    def encode(self, inputs):\n","        down1, indices_1, unpool_shape1 = self.down1(inputs)\n","        down2, indices_2, unpool_shape2 = self.down2(down1)\n","        down3, indices_3, unpool_shape3 = self.down3(down2)\n","        down4, indices_4, unpool_shape4 = self.down4(down3)\n","        down5, indices_5, unpool_shape5 = self.down5(down4)\n","        \n","        return down5\n","\n","    def init_vgg16_params(self, vgg16):\n","        blocks = [self.down1, self.down2, self.down3, self.down4, self.down5]\n","\n","        ranges = [[0, 4], [5, 9], [10, 16], [17, 23], [24, 29]]\n","        features = list(vgg16.features.children())\n","\n","        vgg_layers = []\n","        for _layer in features:\n","            if isinstance(_layer, nn.Conv2d):\n","                vgg_layers.append(_layer)\n","\n","        merged_layers = []\n","        for idx, conv_block in enumerate(blocks):\n","            if idx < 2:\n","                units = [conv_block.conv1.cbr_unit, conv_block.conv2.cbr_unit]\n","            else:\n","                units = [\n","                    conv_block.conv1.cbr_unit,\n","                    conv_block.conv2.cbr_unit,\n","                    conv_block.conv3.cbr_unit,\n","                ]\n","            for _unit in units:\n","                for _layer in _unit:\n","                    if isinstance(_layer, nn.Conv2d):\n","                        merged_layers.append(_layer)\n","\n","        assert len(vgg_layers) == len(merged_layers)\n","\n","        for l1, l2 in zip(vgg_layers, merged_layers):\n","            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n","                assert l1.weight.size() == l2.weight.size()\n","                assert l1.bias.size() == l2.bias.size()\n","                l2.weight.data = l1.weight.data\n","                l2.bias.data = l1.bias.data\n","\n","import torchvision.models as models\n","autoencoder = SegNet()\n","checkpoint = torch.load(\"/content/drive/My Drive/model/conv_autoencoder_test1.pt\")\n","autoencoder.load_state_dict(checkpoint)\n"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"W8FJ4cwGikiz","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","# define the CNN architecture\n","class Net(nn.Module):\n","    def __init__(self, hidden_dim, dropout =0.3):\n","        \n","        super(Net, self).__init__()\n","        # Number of features\n","        self.fc1 = nn.Linear(512, hidden_dim)\n","        \n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n","        \n","        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim)\n","        \n","        self.fc4 = nn.Linear(hidden_dim, 64)\n","        \n","        self.fc5 = nn.Linear(64, 1) # regression and no softmax\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x):\n","        \n","        out = self.dropout(F.relu(self.fc1(x)))\n","        \n","        out = self.dropout(F.relu(self.fc2(out)))\n","        \n","        out = self.dropout(F.relu(self.fc3(out)))\n","        \n","        out = self.dropout(F.relu(self.fc4(out)))\n","        \n","        out = self.fc5(out)\n","        \n","        return out\n","\n","\n","# define the CNN architecture\n","class Net2(nn.Module):\n","    def __init__(self, hidden_dim, dropout =0.3):\n","        \n","        super(Net2, self).__init__()\n","        # Number of features\n","        self.fc1 = nn.Linear(512, hidden_dim)\n","        \n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n","        \n","        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim)\n","\n","        self.bn1 = nn.BatchNorm1d(num_features=hidden_dim)\n","        \n","        self.fc4 = nn.Linear(hidden_dim, 32)\n","        \n","        self.fc5 = nn.Linear(32, 1) # regression and no softmax\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x):\n","        \n","        out = self.dropout(F.relu(self.fc1(x)))\n","        \n","        out = self.dropout(F.relu(self.fc2(out)))\n","        \n","        out = F.relu(self.bn1(self.fc3(out)))\n","        \n","        out = self.dropout(F.relu(self.fc4(out)))\n","        \n","        out = self.fc5(out)\n","        \n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZM2FslH6lgT0","colab_type":"code","colab":{}},"source":["def generateDatasetIDS(list, root_folder = \"/content/drive/My Drive/frames/\"):\n","  \"\"\"\n","  Return a list with all the image paths relative to those IDs\n","  \"\"\"\n","  test_list = []\n","  for id in list:\n","    #print(\"Id:\", id)\n","    for root, dirs, files in os.walk(root_folder + str(id) ):\n","        for filename in files:\n","            #print(\"\\t\", str(id) + \"/\" + filename)\n","            if('.png' in filename):\n","              add_file = str(id) + \"/\" + filename\n","              test_list.append(add_file)\n","  return test_list\n","\n","class CustomListDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, images_list, df_weights, root_dir,transform = None):\n","        \"\"\"\n","        Args:\n","            images_list(list): list with IDs into the dataset\n","            root_dir(string): directory with all the images\n","            df_weights(pd_dataframe): dataframe with all the weights of the people\n","            transform: trasform operation for images\n","        \"\"\"\n","        self.images_list = images_list\n","        self.root_dir = root_dir\n","        self.df_weights = df_weights\n","        self.df_weights = self.df_weights['WEIGHT'].values\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images_list)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.root_dir, self.images_list[idx])\n","        image = Image.open(img_name)\n","        image = image.convert(mode='RGB')\n","        if(self.transform is not None):\n","            image = self.transform(image)\n","        frame_name = self.images_list[idx].split(\"/\")\n","        id = int(frame_name[0]) \n","        labels = self.df_weights[id]\n","        labels = np.float(labels)\n","        return image, torch.as_tensor(labels)\n","\n","transform = transforms.Compose([\n","    # you can add other transformations in this list\n","    #transforms.Resize((299,299), interpolation=2),\n","    #transforms.RandomHorizontalFlip(),\n","    #transforms.RandomRotation(20),\n","    transforms.ToTensor()\n","])\n","\n","def get_optimizer(net, lr):\n","  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","  return optimizer\n","\n","def get_cost_function():\n","  cost_function = torch.nn.MSELoss()\n","  return cost_function\n","\n","\n","# save checkpoint function\n","def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n","    torch.save(state, filename)\n","    if is_best:\n","        shutil.copyfile(filename, filename + \"best\")\n","\n","def adjust_learning_rate(optimizer, epoch, learning_rate):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 100 epochs\"\"\"\n","    lr = learning_rate * (0.5 ** (epoch // 50))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","    return lr\n","\n","def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SmijmK6lj4MD","colab_type":"code","outputId":"eba0ffb6-d607-41ce-b96b-cacaf67b5eb0","executionInfo":{"status":"ok","timestamp":1590510909151,"user_tz":-120,"elapsed":1449431,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import time\n","\n","import torchvision.models as models\n","\n","\n","seed_torch(11)\n","device='cuda:0'\n","learning_rate = 0.01\n","momentum_ = 0.9\n","weight_decay = 1e-4\n","\n","num_epochs = 100\n","splits = 3\n","batch_size = 32\n","\n","# model = EfficientNet.from_pretrained('efficientnet-b5')\n","# model._fc = nn.Linear(2048, 1)\n","# print(model)\n","\n","model = Net2(hidden_dim=256,dropout=0.0)\n","autoencoder = SegNet()\n","checkpoint = torch.load(\"/content/drive/My Drive/model/conv_autoencoder_test_shuf150it.pt\")\n","autoencoder.load_state_dict(checkpoint)\n","\n","\n","\n","optimizer = get_optimizer(model, learning_rate)\n","# optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n","#                                 momentum=momentum_,\n","#                                 weight_decay=weight_decay)\n","\n","loss_fn = get_cost_function()\n","\n","kf = KFold(n_splits=splits, shuffle=True)\n","fold = 1\n","\n","# best accuracy to be stored\n","best_acc1 = 0\n","\n","\"\"\"# Add values to plots\n","tb.save_value('Loss/train_loss', visualization_name, 0, train_loss)\n","tb.save_value('Loss/test_loss', visualization_name, 0, test_loss)\n","\n","# Update plots \n","tb.flush_line(visualization_name)\n","\"\"\"\n","global_epoch = 0\n","\n","for train_index, test_index in kf.split(train_IDs):\n","  #print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n","  model.cuda()\n","  autoencoder.cuda()\n","  train_images_list = generateDatasetIDS(train_index, content)\n","  train = CustomListDataset(images_list = train_images_list, df_weights = weights, root_dir=content, transform = transform)\n","  trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True, drop_last=True)\n","\n","  test_images_list = generateDatasetIDS(test_index, content)\n","  test = CustomListDataset(images_list = test_images_list, df_weights = weights, root_dir=content, transform = transform)\n","  validationloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True, drop_last=True)\n","\n","\n","  print(f'Len Train (in batch): {len(trainloader)}')\n","  print(f'Len validation (in batch): {len(validationloader)}')\n","\n","  print(f'Fold {fold}')\n","  fold += 1\n","  \n","  for epoch in range(num_epochs):\n","      start_time = time.time()\n","      \n","      # adjust learning rate\n","      curr_learnig = adjust_learning_rate(optimizer, global_epoch, learning_rate)\n","      global_epoch += 1\n","\n","      model.train()\n","      avg_loss = 0.\n","      cumulative_loss = 0.\n","      samples = 0\n","      for i, (x_batch, y_batch) in enumerate(trainloader):\n","          x_batch = x_batch.to(device)\n","          y_batch = y_batch.to(device)\n","\n","          # metti autoencoder\n","          featrues_x = autoencoder.encode(x_batch)\n","          featrues_x = featrues_x.mean(3)\n","          featrues_x = featrues_x.mean(2)\n","          \n","          featrues_x = featrues_x.to(device)\n","\n","\n","          y_batch = y_batch.view(-1,1)\n","          y_pred = model(featrues_x)\n","          loss = loss_fn(y_pred, y_batch)\n","          \n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          \n","          samples+=x_batch.shape[0]\n","          cumulative_loss += loss.item()\n","      avg_loss = cumulative_loss / samples\n","      \n","      model.eval()\n","      avg_val_loss = 0.\n","      cumulative_val_loss = 0.\n","      val_samples = 0\n","      with torch.no_grad():\n","        for i, (x_batch, y_batch) in enumerate(validationloader):\n","            x_batch = x_batch.to(device)\n","            y_batch = y_batch.to(device)\n","            y_batch = y_batch.view(-1,1)\n","\n","            # metti autoencoder\n","            featrues_x = autoencoder.encode(x_batch)\n","            featrues_x = featrues_x.mean(3)\n","            featrues_x = featrues_x.mean(2)\n","\n","            featrues_x = featrues_x.to(device)\n","\n","            y_pred = model(featrues_x)\n","            cumulative_val_loss += loss_fn(y_pred, y_batch).item()\n","            val_samples += x_batch.shape[0]\n","        avg_val_loss = cumulative_val_loss / val_samples\n","          #valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n","\n","      elapsed_time = time.time() - start_time \n","\n","      writer.add_scalar('training loss',\n","                            avg_loss,\n","                            global_epoch)\n","      \n","      writer.add_scalar('validation loss',\n","                            avg_val_loss,\n","                            global_epoch)\n","\n","      acc1 = avg_val_loss\n","\n","      # remember best acc@1 and save checkpoint\n","      is_best = acc1 > best_acc1\n","      best_acc1 = max(acc1, best_acc1)\n","\n","      print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s , lr={:.4f}'.format(\n","          epoch + 1, num_epochs, avg_loss, avg_val_loss, elapsed_time, curr_learnig))\n","      \n","      "],"execution_count":8,"outputs":[{"output_type":"stream","text":["Len Train (in batch): 37\n","Len validation (in batch): 21\n","Fold 1\n","Epoch 1/100 \t loss=43.6084 \t val_loss=138.6084 \t time=575.95s , lr=0.0100\n","Epoch 2/100 \t loss=5.0364 \t val_loss=48.3252 \t time=9.92s , lr=0.0100\n","Epoch 3/100 \t loss=4.6308 \t val_loss=122.3327 \t time=9.91s , lr=0.0100\n","Epoch 4/100 \t loss=3.5319 \t val_loss=25.0002 \t time=9.91s , lr=0.0100\n","Epoch 5/100 \t loss=3.2864 \t val_loss=127.6806 \t time=9.90s , lr=0.0100\n","Epoch 6/100 \t loss=2.9532 \t val_loss=22.0668 \t time=9.90s , lr=0.0100\n","Epoch 7/100 \t loss=3.0839 \t val_loss=12.0752 \t time=9.92s , lr=0.0100\n","Epoch 8/100 \t loss=2.6220 \t val_loss=78.0932 \t time=9.93s , lr=0.0100\n","Epoch 9/100 \t loss=2.6445 \t val_loss=8.4550 \t time=9.91s , lr=0.0100\n","Epoch 10/100 \t loss=2.6260 \t val_loss=10.9466 \t time=9.90s , lr=0.0100\n","Epoch 11/100 \t loss=2.8385 \t val_loss=4.1471 \t time=9.91s , lr=0.0100\n","Epoch 12/100 \t loss=2.3394 \t val_loss=18.5140 \t time=9.90s , lr=0.0100\n","Epoch 13/100 \t loss=2.4867 \t val_loss=30.7379 \t time=9.94s , lr=0.0100\n","Epoch 14/100 \t loss=2.1921 \t val_loss=4.5619 \t time=9.93s , lr=0.0100\n","Epoch 15/100 \t loss=2.2365 \t val_loss=38.3728 \t time=9.91s , lr=0.0100\n","Epoch 16/100 \t loss=2.0845 \t val_loss=2.8887 \t time=9.93s , lr=0.0100\n","Epoch 17/100 \t loss=1.9719 \t val_loss=2.5498 \t time=10.01s , lr=0.0100\n","Epoch 18/100 \t loss=2.1258 \t val_loss=2.5615 \t time=9.95s , lr=0.0100\n","Epoch 19/100 \t loss=1.8766 \t val_loss=4.4262 \t time=10.00s , lr=0.0100\n","Epoch 20/100 \t loss=1.9000 \t val_loss=2.8813 \t time=9.92s , lr=0.0100\n","Epoch 21/100 \t loss=1.6123 \t val_loss=12.6753 \t time=9.92s , lr=0.0100\n","Epoch 22/100 \t loss=1.8220 \t val_loss=4.6650 \t time=9.92s , lr=0.0100\n","Epoch 23/100 \t loss=1.9529 \t val_loss=14.3072 \t time=9.94s , lr=0.0100\n","Epoch 24/100 \t loss=1.7964 \t val_loss=7.5149 \t time=9.92s , lr=0.0100\n","Epoch 25/100 \t loss=2.0489 \t val_loss=2.6254 \t time=9.97s , lr=0.0100\n","Epoch 26/100 \t loss=1.7468 \t val_loss=8.1347 \t time=9.94s , lr=0.0100\n","Epoch 27/100 \t loss=1.7607 \t val_loss=7.5298 \t time=9.93s , lr=0.0100\n","Epoch 28/100 \t loss=1.8322 \t val_loss=18.6004 \t time=9.94s , lr=0.0100\n","Epoch 29/100 \t loss=1.5505 \t val_loss=3.4718 \t time=9.93s , lr=0.0100\n","Epoch 30/100 \t loss=1.6883 \t val_loss=4.4345 \t time=9.92s , lr=0.0100\n","Epoch 31/100 \t loss=1.7145 \t val_loss=6.0867 \t time=9.94s , lr=0.0100\n","Epoch 32/100 \t loss=1.4889 \t val_loss=4.4381 \t time=9.93s , lr=0.0100\n","Epoch 33/100 \t loss=1.6684 \t val_loss=2.3785 \t time=10.01s , lr=0.0100\n","Epoch 34/100 \t loss=1.6460 \t val_loss=3.5682 \t time=9.93s , lr=0.0100\n","Epoch 35/100 \t loss=1.6611 \t val_loss=7.7187 \t time=9.94s , lr=0.0100\n","Epoch 36/100 \t loss=1.8527 \t val_loss=2.6282 \t time=9.95s , lr=0.0100\n","Epoch 37/100 \t loss=1.5463 \t val_loss=10.2787 \t time=9.95s , lr=0.0100\n","Epoch 38/100 \t loss=1.5572 \t val_loss=21.6187 \t time=9.92s , lr=0.0100\n","Epoch 39/100 \t loss=1.6875 \t val_loss=6.5236 \t time=9.93s , lr=0.0100\n","Epoch 40/100 \t loss=1.5409 \t val_loss=3.2910 \t time=9.96s , lr=0.0100\n","Epoch 41/100 \t loss=1.5790 \t val_loss=6.9888 \t time=9.92s , lr=0.0100\n","Epoch 42/100 \t loss=1.8500 \t val_loss=12.2079 \t time=9.92s , lr=0.0100\n","Epoch 43/100 \t loss=1.6147 \t val_loss=6.9890 \t time=9.92s , lr=0.0100\n","Epoch 44/100 \t loss=1.4492 \t val_loss=2.6996 \t time=9.92s , lr=0.0100\n","Epoch 45/100 \t loss=1.4800 \t val_loss=7.5122 \t time=9.94s , lr=0.0100\n","Epoch 46/100 \t loss=1.5960 \t val_loss=6.2679 \t time=9.93s , lr=0.0100\n","Epoch 47/100 \t loss=1.6246 \t val_loss=5.1043 \t time=9.94s , lr=0.0100\n","Epoch 48/100 \t loss=1.5683 \t val_loss=3.9952 \t time=9.94s , lr=0.0100\n","Epoch 49/100 \t loss=1.6235 \t val_loss=7.9593 \t time=9.93s , lr=0.0100\n","Epoch 50/100 \t loss=1.4952 \t val_loss=3.5283 \t time=9.93s , lr=0.0100\n","Epoch 51/100 \t loss=1.3645 \t val_loss=4.1339 \t time=9.92s , lr=0.0050\n","Epoch 52/100 \t loss=1.3421 \t val_loss=5.5567 \t time=9.97s , lr=0.0050\n","Epoch 53/100 \t loss=1.3040 \t val_loss=2.8801 \t time=9.93s , lr=0.0050\n","Epoch 54/100 \t loss=1.3463 \t val_loss=4.0145 \t time=9.94s , lr=0.0050\n","Epoch 55/100 \t loss=1.3804 \t val_loss=4.2550 \t time=9.92s , lr=0.0050\n","Epoch 56/100 \t loss=1.4315 \t val_loss=3.0710 \t time=9.97s , lr=0.0050\n","Epoch 57/100 \t loss=1.2631 \t val_loss=3.9182 \t time=9.92s , lr=0.0050\n","Epoch 58/100 \t loss=1.4108 \t val_loss=4.4467 \t time=9.92s , lr=0.0050\n","Epoch 59/100 \t loss=1.4369 \t val_loss=3.7241 \t time=9.92s , lr=0.0050\n","Epoch 60/100 \t loss=1.4079 \t val_loss=5.0296 \t time=9.91s , lr=0.0050\n","Epoch 61/100 \t loss=1.2553 \t val_loss=2.4075 \t time=9.91s , lr=0.0050\n","Epoch 62/100 \t loss=1.4059 \t val_loss=2.3099 \t time=9.97s , lr=0.0050\n","Epoch 63/100 \t loss=1.1900 \t val_loss=2.9483 \t time=9.94s , lr=0.0050\n","Epoch 64/100 \t loss=1.1250 \t val_loss=3.6626 \t time=9.97s , lr=0.0050\n","Epoch 65/100 \t loss=1.3951 \t val_loss=2.9513 \t time=9.95s , lr=0.0050\n","Epoch 66/100 \t loss=1.2479 \t val_loss=3.4324 \t time=9.94s , lr=0.0050\n","Epoch 67/100 \t loss=1.2894 \t val_loss=7.5974 \t time=9.92s , lr=0.0050\n","Epoch 68/100 \t loss=1.3458 \t val_loss=2.9715 \t time=9.93s , lr=0.0050\n","Epoch 69/100 \t loss=1.4746 \t val_loss=12.0398 \t time=9.93s , lr=0.0050\n","Epoch 70/100 \t loss=1.2207 \t val_loss=8.7756 \t time=9.92s , lr=0.0050\n","Epoch 71/100 \t loss=1.3784 \t val_loss=5.0682 \t time=9.95s , lr=0.0050\n","Epoch 72/100 \t loss=1.4222 \t val_loss=2.4462 \t time=9.93s , lr=0.0050\n","Epoch 73/100 \t loss=1.5585 \t val_loss=3.8956 \t time=9.94s , lr=0.0050\n","Epoch 74/100 \t loss=1.2647 \t val_loss=3.6062 \t time=9.92s , lr=0.0050\n","Epoch 75/100 \t loss=1.2188 \t val_loss=11.0439 \t time=9.91s , lr=0.0050\n","Epoch 76/100 \t loss=1.2555 \t val_loss=3.8201 \t time=9.93s , lr=0.0050\n","Epoch 77/100 \t loss=1.1588 \t val_loss=4.1018 \t time=9.91s , lr=0.0050\n","Epoch 78/100 \t loss=1.2649 \t val_loss=6.9331 \t time=9.93s , lr=0.0050\n","Epoch 79/100 \t loss=1.2083 \t val_loss=3.1311 \t time=9.91s , lr=0.0050\n","Epoch 80/100 \t loss=1.2013 \t val_loss=12.0230 \t time=9.92s , lr=0.0050\n","Epoch 81/100 \t loss=1.4042 \t val_loss=5.1710 \t time=9.92s , lr=0.0050\n","Epoch 82/100 \t loss=1.4249 \t val_loss=34.1312 \t time=9.90s , lr=0.0050\n","Epoch 83/100 \t loss=1.2871 \t val_loss=6.0448 \t time=9.91s , lr=0.0050\n","Epoch 84/100 \t loss=1.3836 \t val_loss=3.4351 \t time=9.90s , lr=0.0050\n","Epoch 85/100 \t loss=1.2195 \t val_loss=4.0983 \t time=9.92s , lr=0.0050\n","Epoch 86/100 \t loss=1.1829 \t val_loss=16.1915 \t time=9.91s , lr=0.0050\n","Epoch 87/100 \t loss=1.2686 \t val_loss=15.4945 \t time=9.91s , lr=0.0050\n","Epoch 88/100 \t loss=1.2642 \t val_loss=8.0337 \t time=9.92s , lr=0.0050\n","Epoch 89/100 \t loss=1.2810 \t val_loss=9.8759 \t time=9.91s , lr=0.0050\n","Epoch 90/100 \t loss=1.1716 \t val_loss=15.8314 \t time=9.91s , lr=0.0050\n","Epoch 91/100 \t loss=1.3798 \t val_loss=15.9826 \t time=9.95s , lr=0.0050\n","Epoch 92/100 \t loss=1.2172 \t val_loss=2.9508 \t time=9.92s , lr=0.0050\n","Epoch 93/100 \t loss=1.1833 \t val_loss=4.5385 \t time=9.90s , lr=0.0050\n","Epoch 94/100 \t loss=1.3082 \t val_loss=18.1068 \t time=9.91s , lr=0.0050\n","Epoch 95/100 \t loss=1.2752 \t val_loss=9.3423 \t time=9.90s , lr=0.0050\n","Epoch 96/100 \t loss=1.2252 \t val_loss=6.6845 \t time=9.91s , lr=0.0050\n","Epoch 97/100 \t loss=1.2641 \t val_loss=11.1395 \t time=9.92s , lr=0.0050\n","Epoch 98/100 \t loss=1.1949 \t val_loss=6.5893 \t time=9.90s , lr=0.0050\n","Epoch 99/100 \t loss=1.0918 \t val_loss=8.6941 \t time=9.91s , lr=0.0050\n","Epoch 100/100 \t loss=1.2444 \t val_loss=2.3939 \t time=9.91s , lr=0.0050\n","Len Train (in batch): 39\n","Len validation (in batch): 18\n","Fold 2\n","Epoch 1/100 \t loss=1.6027 \t val_loss=3.4662 \t time=11.39s , lr=0.0025\n","Epoch 2/100 \t loss=1.4725 \t val_loss=4.6703 \t time=10.17s , lr=0.0025\n","Epoch 3/100 \t loss=1.3777 \t val_loss=9.5615 \t time=10.15s , lr=0.0025\n","Epoch 4/100 \t loss=1.2673 \t val_loss=3.1668 \t time=10.15s , lr=0.0025\n","Epoch 5/100 \t loss=1.2567 \t val_loss=3.2416 \t time=10.15s , lr=0.0025\n","Epoch 6/100 \t loss=1.3020 \t val_loss=3.3125 \t time=10.16s , lr=0.0025\n","Epoch 7/100 \t loss=1.3225 \t val_loss=4.8622 \t time=10.15s , lr=0.0025\n","Epoch 8/100 \t loss=1.2583 \t val_loss=3.7732 \t time=10.15s , lr=0.0025\n","Epoch 9/100 \t loss=1.1892 \t val_loss=3.8332 \t time=10.13s , lr=0.0025\n","Epoch 10/100 \t loss=1.1925 \t val_loss=3.9529 \t time=10.14s , lr=0.0025\n","Epoch 11/100 \t loss=1.2357 \t val_loss=8.4001 \t time=10.14s , lr=0.0025\n","Epoch 12/100 \t loss=1.2511 \t val_loss=4.1707 \t time=10.14s , lr=0.0025\n","Epoch 13/100 \t loss=1.2795 \t val_loss=6.6139 \t time=10.15s , lr=0.0025\n","Epoch 14/100 \t loss=1.2204 \t val_loss=4.8625 \t time=10.14s , lr=0.0025\n","Epoch 15/100 \t loss=1.3434 \t val_loss=4.8099 \t time=10.14s , lr=0.0025\n","Epoch 16/100 \t loss=1.1642 \t val_loss=3.0209 \t time=10.14s , lr=0.0025\n","Epoch 17/100 \t loss=1.2289 \t val_loss=10.0015 \t time=10.15s , lr=0.0025\n","Epoch 18/100 \t loss=1.1141 \t val_loss=3.3253 \t time=10.13s , lr=0.0025\n","Epoch 19/100 \t loss=1.2575 \t val_loss=6.9657 \t time=10.15s , lr=0.0025\n","Epoch 20/100 \t loss=1.3255 \t val_loss=4.7078 \t time=10.13s , lr=0.0025\n","Epoch 21/100 \t loss=1.1631 \t val_loss=4.3086 \t time=10.15s , lr=0.0025\n","Epoch 22/100 \t loss=1.2553 \t val_loss=3.9584 \t time=10.16s , lr=0.0025\n","Epoch 23/100 \t loss=1.1074 \t val_loss=3.7075 \t time=10.14s , lr=0.0025\n","Epoch 24/100 \t loss=1.1308 \t val_loss=4.4748 \t time=10.15s , lr=0.0025\n","Epoch 25/100 \t loss=1.1454 \t val_loss=3.5187 \t time=10.14s , lr=0.0025\n","Epoch 26/100 \t loss=1.1652 \t val_loss=3.8075 \t time=10.15s , lr=0.0025\n","Epoch 27/100 \t loss=1.2016 \t val_loss=5.5369 \t time=10.14s , lr=0.0025\n","Epoch 28/100 \t loss=1.1275 \t val_loss=3.7811 \t time=10.14s , lr=0.0025\n","Epoch 29/100 \t loss=1.1597 \t val_loss=4.6089 \t time=10.14s , lr=0.0025\n","Epoch 30/100 \t loss=1.1747 \t val_loss=3.4153 \t time=10.14s , lr=0.0025\n","Epoch 31/100 \t loss=1.1110 \t val_loss=3.1717 \t time=10.14s , lr=0.0025\n","Epoch 32/100 \t loss=1.1303 \t val_loss=5.1488 \t time=10.16s , lr=0.0025\n","Epoch 33/100 \t loss=1.1624 \t val_loss=5.5542 \t time=10.14s , lr=0.0025\n","Epoch 34/100 \t loss=1.1339 \t val_loss=3.7064 \t time=10.13s , lr=0.0025\n","Epoch 35/100 \t loss=1.1408 \t val_loss=5.0325 \t time=10.14s , lr=0.0025\n","Epoch 36/100 \t loss=1.1557 \t val_loss=4.9540 \t time=10.15s , lr=0.0025\n","Epoch 37/100 \t loss=1.0909 \t val_loss=3.2282 \t time=10.16s , lr=0.0025\n","Epoch 38/100 \t loss=1.0592 \t val_loss=4.2171 \t time=10.15s , lr=0.0025\n","Epoch 39/100 \t loss=1.0794 \t val_loss=3.8652 \t time=10.14s , lr=0.0025\n","Epoch 40/100 \t loss=1.1789 \t val_loss=4.4783 \t time=10.14s , lr=0.0025\n","Epoch 41/100 \t loss=1.0819 \t val_loss=13.8528 \t time=10.14s , lr=0.0025\n","Epoch 42/100 \t loss=1.0836 \t val_loss=3.1782 \t time=10.14s , lr=0.0025\n","Epoch 43/100 \t loss=1.1172 \t val_loss=6.4152 \t time=10.16s , lr=0.0025\n","Epoch 44/100 \t loss=1.0477 \t val_loss=3.7831 \t time=10.14s , lr=0.0025\n","Epoch 45/100 \t loss=1.0621 \t val_loss=5.1981 \t time=10.14s , lr=0.0025\n","Epoch 46/100 \t loss=1.0711 \t val_loss=4.1884 \t time=10.15s , lr=0.0025\n","Epoch 47/100 \t loss=1.1035 \t val_loss=4.1377 \t time=10.17s , lr=0.0025\n","Epoch 48/100 \t loss=1.1472 \t val_loss=3.4598 \t time=10.14s , lr=0.0025\n","Epoch 49/100 \t loss=1.1402 \t val_loss=3.6811 \t time=10.14s , lr=0.0025\n","Epoch 50/100 \t loss=1.0521 \t val_loss=3.0661 \t time=10.13s , lr=0.0025\n","Epoch 51/100 \t loss=1.0150 \t val_loss=3.5128 \t time=10.13s , lr=0.0013\n","Epoch 52/100 \t loss=0.9737 \t val_loss=3.4433 \t time=10.15s , lr=0.0013\n","Epoch 53/100 \t loss=1.0362 \t val_loss=3.3989 \t time=10.14s , lr=0.0013\n","Epoch 54/100 \t loss=1.0337 \t val_loss=4.2467 \t time=10.15s , lr=0.0013\n","Epoch 55/100 \t loss=0.9720 \t val_loss=3.6509 \t time=10.16s , lr=0.0013\n","Epoch 56/100 \t loss=1.0632 \t val_loss=3.9116 \t time=10.15s , lr=0.0013\n","Epoch 57/100 \t loss=0.9708 \t val_loss=3.4573 \t time=10.14s , lr=0.0013\n","Epoch 58/100 \t loss=0.9767 \t val_loss=4.3141 \t time=10.16s , lr=0.0013\n","Epoch 59/100 \t loss=0.9498 \t val_loss=5.2894 \t time=10.14s , lr=0.0013\n","Epoch 60/100 \t loss=0.9496 \t val_loss=3.5281 \t time=10.15s , lr=0.0013\n","Epoch 61/100 \t loss=0.9342 \t val_loss=4.0167 \t time=10.15s , lr=0.0013\n","Epoch 62/100 \t loss=0.9387 \t val_loss=3.6945 \t time=10.16s , lr=0.0013\n","Epoch 63/100 \t loss=1.0313 \t val_loss=4.2659 \t time=10.17s , lr=0.0013\n","Epoch 64/100 \t loss=0.9517 \t val_loss=3.7588 \t time=10.16s , lr=0.0013\n","Epoch 65/100 \t loss=1.0010 \t val_loss=3.9199 \t time=10.15s , lr=0.0013\n","Epoch 66/100 \t loss=0.9790 \t val_loss=4.0283 \t time=10.14s , lr=0.0013\n","Epoch 67/100 \t loss=0.9887 \t val_loss=3.7604 \t time=10.13s , lr=0.0013\n","Epoch 68/100 \t loss=0.9659 \t val_loss=3.5156 \t time=10.15s , lr=0.0013\n","Epoch 69/100 \t loss=0.9825 \t val_loss=4.2720 \t time=10.14s , lr=0.0013\n","Epoch 70/100 \t loss=0.9999 \t val_loss=5.6710 \t time=10.14s , lr=0.0013\n","Epoch 71/100 \t loss=0.8707 \t val_loss=3.5198 \t time=10.14s , lr=0.0013\n","Epoch 72/100 \t loss=0.9320 \t val_loss=6.5771 \t time=10.14s , lr=0.0013\n","Epoch 73/100 \t loss=1.0762 \t val_loss=5.5069 \t time=10.15s , lr=0.0013\n","Epoch 74/100 \t loss=1.0262 \t val_loss=3.7488 \t time=10.15s , lr=0.0013\n","Epoch 75/100 \t loss=1.0451 \t val_loss=5.4324 \t time=10.15s , lr=0.0013\n","Epoch 76/100 \t loss=0.9722 \t val_loss=5.0733 \t time=10.14s , lr=0.0013\n","Epoch 77/100 \t loss=0.8920 \t val_loss=4.1074 \t time=10.14s , lr=0.0013\n","Epoch 78/100 \t loss=0.9188 \t val_loss=4.1533 \t time=10.14s , lr=0.0013\n","Epoch 79/100 \t loss=0.9991 \t val_loss=4.0252 \t time=10.15s , lr=0.0013\n","Epoch 80/100 \t loss=0.8933 \t val_loss=4.1950 \t time=10.15s , lr=0.0013\n","Epoch 81/100 \t loss=0.9141 \t val_loss=4.4985 \t time=10.15s , lr=0.0013\n","Epoch 82/100 \t loss=0.9160 \t val_loss=4.9612 \t time=10.14s , lr=0.0013\n","Epoch 83/100 \t loss=0.9448 \t val_loss=4.6897 \t time=10.15s , lr=0.0013\n","Epoch 84/100 \t loss=0.8978 \t val_loss=4.6025 \t time=10.15s , lr=0.0013\n","Epoch 85/100 \t loss=0.9210 \t val_loss=3.7610 \t time=10.14s , lr=0.0013\n","Epoch 86/100 \t loss=0.9236 \t val_loss=3.5347 \t time=10.18s , lr=0.0013\n","Epoch 87/100 \t loss=0.8868 \t val_loss=4.2918 \t time=10.13s , lr=0.0013\n","Epoch 88/100 \t loss=0.9071 \t val_loss=3.3048 \t time=10.14s , lr=0.0013\n","Epoch 89/100 \t loss=0.9354 \t val_loss=3.9727 \t time=10.15s , lr=0.0013\n","Epoch 90/100 \t loss=0.9535 \t val_loss=5.4206 \t time=10.14s , lr=0.0013\n","Epoch 91/100 \t loss=0.9681 \t val_loss=3.8931 \t time=10.14s , lr=0.0013\n","Epoch 92/100 \t loss=0.9048 \t val_loss=3.7422 \t time=10.14s , lr=0.0013\n","Epoch 93/100 \t loss=0.9008 \t val_loss=3.0028 \t time=10.14s , lr=0.0013\n","Epoch 94/100 \t loss=0.8933 \t val_loss=3.8271 \t time=10.17s , lr=0.0013\n","Epoch 95/100 \t loss=0.9154 \t val_loss=3.9221 \t time=10.15s , lr=0.0013\n","Epoch 96/100 \t loss=0.9212 \t val_loss=6.0914 \t time=10.16s , lr=0.0013\n","Epoch 97/100 \t loss=0.8707 \t val_loss=6.5702 \t time=10.13s , lr=0.0013\n","Epoch 98/100 \t loss=0.8663 \t val_loss=5.2772 \t time=10.15s , lr=0.0013\n","Epoch 99/100 \t loss=0.8732 \t val_loss=3.4809 \t time=10.14s , lr=0.0013\n","Epoch 100/100 \t loss=0.8851 \t val_loss=3.6734 \t time=10.14s , lr=0.0013\n","Len Train (in batch): 40\n","Len validation (in batch): 18\n","Fold 3\n","Epoch 1/100 \t loss=1.3887 \t val_loss=2.6836 \t time=10.37s , lr=0.0006\n","Epoch 2/100 \t loss=1.3255 \t val_loss=4.1221 \t time=10.37s , lr=0.0006\n","Epoch 3/100 \t loss=1.2775 \t val_loss=3.0069 \t time=10.37s , lr=0.0006\n","Epoch 4/100 \t loss=1.2172 \t val_loss=2.2976 \t time=10.36s , lr=0.0006\n","Epoch 5/100 \t loss=1.1466 \t val_loss=2.3064 \t time=10.37s , lr=0.0006\n","Epoch 6/100 \t loss=1.2077 \t val_loss=2.8891 \t time=10.36s , lr=0.0006\n","Epoch 7/100 \t loss=1.2043 \t val_loss=2.5253 \t time=10.37s , lr=0.0006\n","Epoch 8/100 \t loss=1.1753 \t val_loss=2.3296 \t time=10.37s , lr=0.0006\n","Epoch 9/100 \t loss=1.1966 \t val_loss=2.3442 \t time=10.37s , lr=0.0006\n","Epoch 10/100 \t loss=1.1303 \t val_loss=2.2340 \t time=10.37s , lr=0.0006\n","Epoch 11/100 \t loss=1.1134 \t val_loss=2.0440 \t time=10.36s , lr=0.0006\n","Epoch 12/100 \t loss=1.1556 \t val_loss=2.4994 \t time=10.36s , lr=0.0006\n","Epoch 13/100 \t loss=1.2027 \t val_loss=2.4710 \t time=10.38s , lr=0.0006\n","Epoch 14/100 \t loss=1.1783 \t val_loss=2.2132 \t time=10.36s , lr=0.0006\n","Epoch 15/100 \t loss=1.1145 \t val_loss=2.4916 \t time=10.37s , lr=0.0006\n","Epoch 16/100 \t loss=1.1383 \t val_loss=2.5115 \t time=10.36s , lr=0.0006\n","Epoch 17/100 \t loss=1.0931 \t val_loss=2.4171 \t time=10.36s , lr=0.0006\n","Epoch 18/100 \t loss=1.2233 \t val_loss=2.3654 \t time=10.36s , lr=0.0006\n","Epoch 19/100 \t loss=1.1708 \t val_loss=2.5511 \t time=10.36s , lr=0.0006\n","Epoch 20/100 \t loss=1.0782 \t val_loss=2.5320 \t time=10.36s , lr=0.0006\n","Epoch 21/100 \t loss=1.0524 \t val_loss=2.4610 \t time=10.37s , lr=0.0006\n","Epoch 22/100 \t loss=1.0945 \t val_loss=2.6579 \t time=10.36s , lr=0.0006\n","Epoch 23/100 \t loss=1.1174 \t val_loss=2.3654 \t time=10.38s , lr=0.0006\n","Epoch 24/100 \t loss=1.1179 \t val_loss=3.1325 \t time=10.39s , lr=0.0006\n","Epoch 25/100 \t loss=1.1253 \t val_loss=2.3813 \t time=10.37s , lr=0.0006\n","Epoch 26/100 \t loss=1.0431 \t val_loss=2.2960 \t time=10.36s , lr=0.0006\n","Epoch 27/100 \t loss=1.0348 \t val_loss=2.3597 \t time=10.37s , lr=0.0006\n","Epoch 28/100 \t loss=1.0760 \t val_loss=2.4732 \t time=10.35s , lr=0.0006\n","Epoch 29/100 \t loss=1.0512 \t val_loss=2.2046 \t time=10.37s , lr=0.0006\n","Epoch 30/100 \t loss=1.0668 \t val_loss=2.9939 \t time=10.36s , lr=0.0006\n","Epoch 31/100 \t loss=1.2715 \t val_loss=3.0898 \t time=10.36s , lr=0.0006\n","Epoch 32/100 \t loss=1.0561 \t val_loss=2.5087 \t time=10.36s , lr=0.0006\n","Epoch 33/100 \t loss=0.9998 \t val_loss=2.3870 \t time=10.36s , lr=0.0006\n","Epoch 34/100 \t loss=1.0264 \t val_loss=2.5530 \t time=10.37s , lr=0.0006\n","Epoch 35/100 \t loss=1.0857 \t val_loss=2.9056 \t time=10.36s , lr=0.0006\n","Epoch 36/100 \t loss=1.1516 \t val_loss=2.8975 \t time=10.37s , lr=0.0006\n","Epoch 37/100 \t loss=1.0432 \t val_loss=2.5985 \t time=10.36s , lr=0.0006\n","Epoch 38/100 \t loss=1.0356 \t val_loss=2.8038 \t time=10.37s , lr=0.0006\n","Epoch 39/100 \t loss=1.0712 \t val_loss=2.6516 \t time=10.37s , lr=0.0006\n","Epoch 40/100 \t loss=1.0126 \t val_loss=2.7065 \t time=10.36s , lr=0.0006\n","Epoch 41/100 \t loss=1.0785 \t val_loss=2.3253 \t time=10.36s , lr=0.0006\n","Epoch 42/100 \t loss=1.0823 \t val_loss=2.5178 \t time=10.37s , lr=0.0006\n","Epoch 43/100 \t loss=1.0522 \t val_loss=2.5836 \t time=10.36s , lr=0.0006\n","Epoch 44/100 \t loss=1.0532 \t val_loss=3.0375 \t time=10.35s , lr=0.0006\n","Epoch 45/100 \t loss=1.0983 \t val_loss=2.3763 \t time=10.40s , lr=0.0006\n","Epoch 46/100 \t loss=1.0671 \t val_loss=2.6895 \t time=10.39s , lr=0.0006\n","Epoch 47/100 \t loss=1.0546 \t val_loss=2.5458 \t time=10.38s , lr=0.0006\n","Epoch 48/100 \t loss=1.0710 \t val_loss=2.7151 \t time=10.36s , lr=0.0006\n","Epoch 49/100 \t loss=1.0362 \t val_loss=3.0665 \t time=10.36s , lr=0.0006\n","Epoch 50/100 \t loss=1.0912 \t val_loss=2.6235 \t time=10.36s , lr=0.0006\n","Epoch 51/100 \t loss=1.0276 \t val_loss=2.4732 \t time=10.36s , lr=0.0003\n","Epoch 52/100 \t loss=0.9967 \t val_loss=2.6165 \t time=10.35s , lr=0.0003\n","Epoch 53/100 \t loss=0.9785 \t val_loss=2.6198 \t time=10.37s , lr=0.0003\n","Epoch 54/100 \t loss=0.9538 \t val_loss=2.4809 \t time=10.38s , lr=0.0003\n","Epoch 55/100 \t loss=0.9626 \t val_loss=2.6416 \t time=10.38s , lr=0.0003\n","Epoch 56/100 \t loss=0.9969 \t val_loss=2.6467 \t time=10.37s , lr=0.0003\n","Epoch 57/100 \t loss=0.9405 \t val_loss=2.5691 \t time=10.36s , lr=0.0003\n","Epoch 58/100 \t loss=0.9839 \t val_loss=2.6495 \t time=10.36s , lr=0.0003\n","Epoch 59/100 \t loss=0.9913 \t val_loss=2.7696 \t time=10.36s , lr=0.0003\n","Epoch 60/100 \t loss=0.9520 \t val_loss=2.5312 \t time=10.36s , lr=0.0003\n","Epoch 61/100 \t loss=0.9533 \t val_loss=2.4694 \t time=10.37s , lr=0.0003\n","Epoch 62/100 \t loss=1.0276 \t val_loss=2.5447 \t time=10.35s , lr=0.0003\n","Epoch 63/100 \t loss=0.9308 \t val_loss=2.5105 \t time=10.36s , lr=0.0003\n","Epoch 64/100 \t loss=0.9815 \t val_loss=2.6434 \t time=10.36s , lr=0.0003\n","Epoch 65/100 \t loss=0.9456 \t val_loss=2.4223 \t time=10.35s , lr=0.0003\n","Epoch 66/100 \t loss=0.9767 \t val_loss=2.7320 \t time=10.36s , lr=0.0003\n","Epoch 67/100 \t loss=0.9577 \t val_loss=2.6113 \t time=10.37s , lr=0.0003\n","Epoch 68/100 \t loss=0.9749 \t val_loss=2.6528 \t time=10.38s , lr=0.0003\n","Epoch 69/100 \t loss=1.0441 \t val_loss=2.5600 \t time=10.37s , lr=0.0003\n","Epoch 70/100 \t loss=0.9409 \t val_loss=2.5843 \t time=10.36s , lr=0.0003\n","Epoch 71/100 \t loss=0.9948 \t val_loss=2.4226 \t time=10.38s , lr=0.0003\n","Epoch 72/100 \t loss=0.9435 \t val_loss=2.6036 \t time=10.37s , lr=0.0003\n","Epoch 73/100 \t loss=0.9749 \t val_loss=2.7042 \t time=10.36s , lr=0.0003\n","Epoch 74/100 \t loss=0.9441 \t val_loss=2.4884 \t time=10.36s , lr=0.0003\n","Epoch 75/100 \t loss=1.0127 \t val_loss=2.5686 \t time=10.37s , lr=0.0003\n","Epoch 76/100 \t loss=0.9786 \t val_loss=2.7864 \t time=10.37s , lr=0.0003\n","Epoch 77/100 \t loss=0.9341 \t val_loss=2.5174 \t time=10.36s , lr=0.0003\n","Epoch 78/100 \t loss=0.9410 \t val_loss=2.8101 \t time=10.36s , lr=0.0003\n","Epoch 79/100 \t loss=0.9840 \t val_loss=2.5105 \t time=10.36s , lr=0.0003\n","Epoch 80/100 \t loss=0.9346 \t val_loss=2.6398 \t time=10.36s , lr=0.0003\n","Epoch 81/100 \t loss=1.0036 \t val_loss=2.5917 \t time=10.37s , lr=0.0003\n","Epoch 82/100 \t loss=0.9917 \t val_loss=2.5259 \t time=10.36s , lr=0.0003\n","Epoch 83/100 \t loss=0.9980 \t val_loss=2.6928 \t time=10.37s , lr=0.0003\n","Epoch 84/100 \t loss=0.9191 \t val_loss=2.5259 \t time=10.37s , lr=0.0003\n","Epoch 85/100 \t loss=0.9470 \t val_loss=2.6096 \t time=10.37s , lr=0.0003\n","Epoch 86/100 \t loss=0.9459 \t val_loss=2.7516 \t time=10.36s , lr=0.0003\n","Epoch 87/100 \t loss=0.8849 \t val_loss=2.6664 \t time=10.36s , lr=0.0003\n","Epoch 88/100 \t loss=0.9177 \t val_loss=2.5407 \t time=10.36s , lr=0.0003\n","Epoch 89/100 \t loss=1.0415 \t val_loss=2.6307 \t time=10.36s , lr=0.0003\n","Epoch 90/100 \t loss=0.9603 \t val_loss=2.7841 \t time=10.36s , lr=0.0003\n","Epoch 91/100 \t loss=0.9799 \t val_loss=2.5925 \t time=10.38s , lr=0.0003\n","Epoch 92/100 \t loss=0.9610 \t val_loss=2.7214 \t time=10.37s , lr=0.0003\n","Epoch 93/100 \t loss=0.9412 \t val_loss=2.6816 \t time=10.36s , lr=0.0003\n","Epoch 94/100 \t loss=0.9441 \t val_loss=2.9907 \t time=10.36s , lr=0.0003\n","Epoch 95/100 \t loss=0.9142 \t val_loss=2.7805 \t time=10.36s , lr=0.0003\n","Epoch 96/100 \t loss=0.9383 \t val_loss=2.8924 \t time=10.37s , lr=0.0003\n","Epoch 97/100 \t loss=0.9135 \t val_loss=2.7288 \t time=10.36s , lr=0.0003\n","Epoch 98/100 \t loss=0.9340 \t val_loss=2.6108 \t time=10.37s , lr=0.0003\n","Epoch 99/100 \t loss=0.9579 \t val_loss=2.7078 \t time=10.38s , lr=0.0003\n","Epoch 100/100 \t loss=0.9924 \t val_loss=2.5984 \t time=10.37s , lr=0.0003\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L5xmftscwjaT","colab_type":"code","colab":{}},"source":["torch.save(autoencoder.state_dict(), \"/content/drive/My Drive/model/fullyconautodrop128_proj16_batchnorm.pt\") "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-Cl-G-Am1YS","colab_type":"code","outputId":"0c9bfd2c-4a87-4580-f0c4-610e2ca86be7","executionInfo":{"status":"ok","timestamp":1590510911836,"user_tz":-120,"elapsed":888,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["test_list = generateDatasetIDS(test_IDs.ID, content)\n","print(len(test_list))\n","test_custom = CustomListDataset(images_list = test_list, df_weights = weights, root_dir=content, transform = transform)\n","test_final_loader = torch.utils.data.DataLoader(test_custom, batch_size=64, shuffle=False, num_workers=2)\n","\n","print(len(test_final_loader))\n","print(len(test_final_loader.dataset))\n","\n","predicted_label = list()\n","real_label = list()\n","\n","#Set the network in eval mode\n","model.eval()\n","with torch.no_grad():\n","  # Loop over the dataset\n","  for batch_idx, (inputs, targets) in enumerate(test_final_loader):\n","    # Load data into GPU\n","    inputs = inputs.to(device)\n","    #print('inputs', inputs.shape)\n","\n","    targets = targets.to(device)\n","    targets = targets.view(-1,1)\n","\n","    # metti autoencoder\n","    featrues_x = autoencoder.encode(inputs)\n","    featrues_x = featrues_x.mean(3)\n","    featrues_x = featrues_x.mean(2)\n","\n","    featrues_x = featrues_x.to(device)\n","\n","    targets = targets.to(device)\n","    #print('targets', targets.shape)\n","\n","    # Forward pass\n","    outputs = model.forward(featrues_x)\n","    \n","    #print('Out:',outputs.shape)\n","    \n","    arr1 = outputs.data.cpu().numpy()\n","    arr2 = targets.data.cpu().numpy()\n","\n","    predicted_label.extend(arr1)\n","    real_label.extend(arr2)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["200\n","4\n","200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tQ7DKiZpm4ZH","colab_type":"code","outputId":"d813db65-3925-4336-f86d-aacff3c5d462","executionInfo":{"status":"ok","timestamp":1590510911838,"user_tz":-120,"elapsed":31,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#print (predicted_label)\n","\n","import numpy as np\n","predicted_label = np.array(predicted_label,dtype=float)\n","real_label = np.array(real_label, dtype=int)\n","#print(predicted_label)\n","\n","pred_label_list = list()\n","for x in np.nditer(predicted_label):\n","  #print(x)\n","  pred_label_list.append(x)\n","\n","real_label_list = list()\n","for x in np.nditer(real_label):\n","  real_label_list.append(x)\n","\n","print(len(pred_label_list))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XeE2Fw-zm6v7","colab_type":"code","outputId":"5ee56073-eef7-40b7-b734-e54450cc3879","executionInfo":{"status":"ok","timestamp":1590510911838,"user_tz":-120,"elapsed":19,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":313}},"source":["import numpy as np\n","import pandas as pd\n","\n","'''real_label, predicted_label'''\n","\n","print(type(real_label))\n","\n","df = pd.DataFrame({'REAL': np.asarray(real_label_list), 'PREDICTED':np.asarray(pred_label_list)})\n","df.plot('REAL', 'PREDICTED', kind='scatter')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f15aaa862e8>"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"4TEfsDdnm9gn","colab_type":"code","outputId":"dbd600cb-57c0-466a-9b56-2add4709f3b8","executionInfo":{"status":"ok","timestamp":1590510912114,"user_tz":-120,"elapsed":282,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":937}},"source":["#See unique real values \n","print(df.PREDICTED.unique())\n","\n","#Check the average value of the predicted labels\n","df.groupby('REAL').mean()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[67.84299469 69.07353973 66.70152283 66.07081604 59.93281174 67.78611755\n"," 69.20560455 60.70837402 62.54121399 68.68491364 63.46917343 70.048172\n"," 73.6717453  73.47735596 68.4859848  68.84236145 69.20817566 61.16168213\n"," 65.79029846 59.74496078 66.37741089 66.99114227 64.36062622 62.05727386\n"," 66.31468201 60.35554123 61.90942764 65.59098816 65.44387054 68.41744232\n"," 67.11838531 71.37265778 61.17190552 66.59824371 71.03526306 65.70285797\n"," 61.41041946 70.9299469  71.08636475 69.67922211 65.43261719 68.8110733\n"," 61.10504532 70.42536926 68.21744537 69.14525604 67.56533813 69.65968323\n"," 66.52516174 69.11193085 60.62934113 69.98215485 61.34986496 65.22727966\n"," 59.12063599 63.71970367 58.32694244 64.93266296 69.15504456 59.32839966\n"," 65.99246216 58.99097443 66.29712677 68.29754639 62.78236771 71.91329193\n"," 69.62106323 64.12004852 65.35108185 65.65054321 69.9074173  68.42086792\n"," 65.97216797 64.81031036 66.94994354 64.21239471 63.18618774 66.74740601\n"," 63.9668808  67.87364197 64.5513382  67.83864594 72.29088593 67.60847473\n"," 68.12298584 66.70544434 69.20850372 67.78731537 67.59584808 67.93221283\n"," 63.66516495 65.45789337 68.91677856 70.52223206 68.67900085 68.87328339\n"," 68.63905334 67.03993225 66.54651642 77.27638245 73.60071564 77.62611389\n"," 78.02322388 79.63384247 78.87646484 79.85918427 73.74252319 81.89196014\n"," 77.22930145 82.25570679 74.29320526 79.5452652  74.94567871 73.26528931\n"," 74.39382935 69.08318329 77.98722076 71.81421661 70.19942474 70.44490051\n"," 71.77680969 66.98506927 72.4710083  74.26934052 71.53751373 73.60587311\n"," 69.20059204 76.37213898 67.54070282 68.69252777 69.43107605 71.48636627\n"," 68.31169128 67.90612793 66.84732056 69.11463165 69.27792358 69.07003021\n"," 65.63878632 70.14605713 73.96295166 66.73691559 70.93167114 69.58708954\n"," 69.24703217 68.51342773 70.54807281 66.3555069  68.88169861 70.74388123\n"," 71.90366364 74.62277222 71.49206543 73.44018555 76.93217468 75.02410126\n"," 73.98008728 74.77851868 78.8259201  75.42321777 73.10890198 70.64975739\n"," 76.36636353 72.83679199 73.48426056 67.20533752 67.40745544 75.25817871\n"," 68.79570007 70.24521637 67.12026215 66.76168823 65.05053711 64.29743958\n"," 63.03823853 65.45672607 68.49430084 67.96629333 70.91801453 71.21382904\n"," 68.1862793  66.00861359 74.7559967  65.04029083 65.8644104  64.04759979\n"," 65.64712524 66.27056122 79.5904007  77.46224976 83.60877228 78.85588837\n"," 67.88835144 64.54331207 60.97600555 61.27605057 60.72579956 64.58169556\n"," 77.26093292 69.59993744]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PREDICTED</th>\n","    </tr>\n","    <tr>\n","      <th>REAL</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>65</th>\n","      <td>66.201820</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>66.170469</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>67.683513</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>77.771398</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>71.772216</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>69.995783</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>73.126207</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>67.610874</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>70.530783</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      PREDICTED\n","REAL           \n","65    66.201820\n","67    66.170469\n","70    67.683513\n","73    77.771398\n","74    71.772216\n","75    69.995783\n","77    73.126207\n","78    67.610874\n","93    70.530783"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"8cbDPB9nm-Qw","colab_type":"code","outputId":"d65fbb25-8e09-4fc3-c938-995e7599ff9c","executionInfo":{"status":"ok","timestamp":1590510912115,"user_tz":-120,"elapsed":27,"user":{"displayName":"Filippo Tessaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggtg-S1ZMBMFO6cu3aoze6pbIUw2moTZOIFQEaI=s64","userId":"12902594735929592197"}},"colab":{"base_uri":"https://localhost:8080/","height":413}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","def r2_rmse( g ):\n","    r2 = r2_score( g.REAL, g.PREDICTED)\n","    count = len(g.REAL)\n","    mse = mean_squared_error( g['REAL'], g['PREDICTED'] ) \n","    rmse = np.sqrt( mean_squared_error( g['REAL'], g['PREDICTED'] ) ) \n","    return pd.Series( dict( count = int(count), r2 = r2, rmse = rmse, mse = mse ) )\n","\n","print(\"Global:\", r2_rmse(df))\n","\n","#Statistics over REAL value\n","df.groupby( 'REAL' ).apply( r2_rmse ).reset_index()\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Global: count    200.000000\n","r2        -0.273543\n","rmse       7.933989\n","mse       62.948174\n","dtype: float64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>REAL</th>\n","      <th>count</th>\n","      <th>r2</th>\n","      <th>rmse</th>\n","      <th>mse</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>65</td>\n","      <td>36.0</td>\n","      <td>0.0</td>\n","      <td>3.871577</td>\n","      <td>14.989107</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>67</td>\n","      <td>49.0</td>\n","      <td>0.0</td>\n","      <td>3.656960</td>\n","      <td>13.373354</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>70</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>2.856002</td>\n","      <td>8.156746</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>73</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>5.492482</td>\n","      <td>30.167362</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>74</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>3.753228</td>\n","      <td>14.086722</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>75</td>\n","      <td>24.0</td>\n","      <td>0.0</td>\n","      <td>5.630272</td>\n","      <td>31.699960</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>77</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>4.833851</td>\n","      <td>23.366117</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>78</td>\n","      <td>23.0</td>\n","      <td>0.0</td>\n","      <td>10.835411</td>\n","      <td>117.406122</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>93</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>23.850783</td>\n","      <td>568.859872</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   REAL  count   r2       rmse         mse\n","0    65   36.0  0.0   3.871577   14.989107\n","1    67   49.0  0.0   3.656960   13.373354\n","2    70   14.0  0.0   2.856002    8.156746\n","3    73   14.0  0.0   5.492482   30.167362\n","4    74    9.0  0.0   3.753228   14.086722\n","5    75   24.0  0.0   5.630272   31.699960\n","6    77   19.0  0.0   4.833851   23.366117\n","7    78   23.0  0.0  10.835411  117.406122\n","8    93   12.0  0.0  23.850783  568.859872"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"tBXw39zVnKys","colab_type":"code","colab":{}},"source":["df.to_csv(file_test_labels, index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNxwAJ16JzaR","colab_type":"code","colab":{}},"source":["# Sleep for a few seconds.\n","import time\n","time.sleep(2)\n","\n","# Play an audio beep. Any audio URL will do.\n","from google.colab import output\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jTz4HazOA19H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}